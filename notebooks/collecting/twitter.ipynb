{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Crawler\n",
    "\n",
    "This notebook was used to develop the Twitter Crawler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if str(Path(\".\").absolute().parent) not in sys.path:\n",
    "    sys.path.append(str(Path(\".\").absolute().parent.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from src.logs import setup_logger\n",
    "from src.s3 import Uploader\n",
    "from src.anonymize import Anonymizer\n",
    "from src.settings import AppSettings\n",
    "from src.perspective import PerspectiveAPI\n",
    "from src.socials.twitter import TwitterCrawler\n",
    "from src.utils import (\n",
    "    read_yaml,\n",
    "    get_toxic_substrings,\n",
    "    label_studio_fmt\n",
    ")\n",
    "\n",
    "_logger = setup_logger(AppSettings().LOG_LEVEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = AppSettings()\n",
    "params = read_yaml(\"../../properties/application.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = TwitterCrawler(\n",
    "    consumer_key=args.TWITTER_CONSUMER_KEY,\n",
    "    consumer_secret=args.TWITTER_CONSUMER_SECRET,\n",
    "    access_token=args.TWITTER_ACCESS_TOKEN,\n",
    "    access_token_secret=args.TWITTER_ACCESS_TOKEN_SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect tweets and replies\n",
    "\n",
    "### by user\n",
    "\n",
    "In this section, we will collect tweets and replies from a list of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiles count: 61\n"
     ]
    }
   ],
   "source": [
    "profiles = params[\"twitter\"]\n",
    "print(f\"Profiles count: {len(profiles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 20:29:50,291 :: INFO :: 2413634140 :: <module> :: Crawling jairbolsonaro from Twitter.\n",
      "2022-03-26 20:29:54,710 :: DEBUG :: 2413634140 :: <module> :: {'tweets type': <class 'list'>, 'tweets size': 500}\n",
      "2022-03-26 20:29:54,710 :: DEBUG :: 2413634140 :: <module> :: jairbolsonaro - Getting replies for tweet: @rogeriosmarinho üáßüá∑, Ministro!\n",
      "2022-03-26 20:30:01,118 :: DEBUG :: 2413634140 :: <module> :: {'replies type': <class 'list'>, 'replies size': 500}\n",
      "2022-03-26 20:30:01,119 :: DEBUG :: 2413634140 :: <module> :: jairbolsonaro - Getting replies for tweet: - Elas possibilitam a pr√°tica de 13 modalidades ol√≠mpicas e seis paral√≠mpicas, estimulando principalmente os jovens, oferecendo-lhes novos objetivos, al√©m de possibilitar que n√£o caiam em mundos errados e sem futuro.\n",
      "\n",
      "- Detalhes: https://t.co/eVxKAQhS9M\n"
     ]
    }
   ],
   "source": [
    "_logger.info(\"Getting tweets by profiles.\")\n",
    "\n",
    "for profile in profiles:\n",
    "    _logger.info(f\"Crawling {profile.get('name')} from Twitter.\")\n",
    "\n",
    "    try:\n",
    "        tweets = twitter.get_tweets(profile[\"name\"],\n",
    "                                    max_count=args.TWITTER_MAX_TWEETS)\n",
    "\n",
    "        _logger.debug({\"tweets type\": type(tweets),\n",
    "                    \"tweets size\": len(tweets)})\n",
    "\n",
    "        # Add Publisher Category\n",
    "        for tweet in tweets:\n",
    "            tweet.publisher_category = profile.get(\"category\")\n",
    "\n",
    "        data += tweets\n",
    "\n",
    "        for tweet in tweets:\n",
    "            _logger.debug(f\"{profile.get('name')} - Getting replies for tweet: {tweet.text}\")\n",
    "\n",
    "            try:\n",
    "                replies = twitter.get_replies(username=profile[\"name\"],\n",
    "                                            tweet_id=tweet.id,\n",
    "                                            max_count=args.TWITTER_MAX_TWEETS)\n",
    "\n",
    "                _logger.debug({\"replies type\": type(tweets),\n",
    "                            \"replies size\": len(tweets)})\n",
    "\n",
    "                # Add Publisher Category\n",
    "                for reply in replies:\n",
    "                    reply.publisher_category = profile.get(\"category\")\n",
    "\n",
    "                data += replies\n",
    "                \n",
    "            except Exception as e:\n",
    "                _logger.error(f\"Error getting replies from Twitter: {tweet} - Exception: {e}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        _logger.error(f\"Error getting tweets from Twitter: {profile.get('name')} - Exception: {e}\")\n",
    "        continue\n",
    "\n",
    "_logger.info(f\"Twitter crawler finished. {len(data)} tweets found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from Kaggle\n",
      "Shape: (706, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_offensive</th>\n",
       "      <th>is_targeted</th>\n",
       "      <th>targeted_type</th>\n",
       "      <th>toxic_spans</th>\n",
       "      <th>health</th>\n",
       "      <th>ideology</th>\n",
       "      <th>insult</th>\n",
       "      <th>lgbtqphobia</th>\n",
       "      <th>other_lifestyle</th>\n",
       "      <th>physical_aspects</th>\n",
       "      <th>profanity_obscene</th>\n",
       "      <th>racism</th>\n",
       "      <th>religious_intolerance</th>\n",
       "      <th>sexism</th>\n",
       "      <th>xenophobia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6391e3dbb12848ac8ef6131edf2d69f9</td>\n",
       "      <td>USER Canalha URL</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a21508c2afc4c3295137451baf8b981</td>\n",
       "      <td>USER VTNSC FDP</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11, 12, 13]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>060b0390f99041cd8cd38ca5a2b66907</td>\n",
       "      <td>USER O partido do Kim votou √† favor do fund√£o....</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3264fc0b06974c2daf423a9e5998d003</td>\n",
       "      <td>USER Grande homem. Em um pa√≠s de covardes. Ete...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>[34, 35, 36, 37, 38, 39, 40, 41]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002bced1b7444833bbe5e054c5aa6512</td>\n",
       "      <td>USER USER QAnon Brasil √© um bicho estranho. Ob...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 3...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  6391e3dbb12848ac8ef6131edf2d69f9   \n",
       "1  5a21508c2afc4c3295137451baf8b981   \n",
       "2  060b0390f99041cd8cd38ca5a2b66907   \n",
       "3  3264fc0b06974c2daf423a9e5998d003   \n",
       "4  002bced1b7444833bbe5e054c5aa6512   \n",
       "\n",
       "                                                text is_offensive is_targeted  \\\n",
       "0                                   USER Canalha URL          OFF         TIN   \n",
       "1                                     USER VTNSC FDP          OFF         TIN   \n",
       "2  USER O partido do Kim votou √† favor do fund√£o....          OFF         TIN   \n",
       "3  USER Grande homem. Em um pa√≠s de covardes. Ete...          OFF         TIN   \n",
       "4  USER USER QAnon Brasil √© um bicho estranho. Ob...          OFF         TIN   \n",
       "\n",
       "  targeted_type                                        toxic_spans  health  \\\n",
       "0           IND                        [5, 6, 7, 8, 9, 10, 11, 12]   False   \n",
       "1           IND                    [5, 6, 7, 8, 9, 10, 11, 12, 13]   False   \n",
       "2           IND                                                NaN   False   \n",
       "3           GRP                   [34, 35, 36, 37, 38, 39, 40, 41]   False   \n",
       "4           IND  [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 3...   False   \n",
       "\n",
       "   ideology  insult  lgbtqphobia  other_lifestyle  physical_aspects  \\\n",
       "0     False    True        False            False             False   \n",
       "1     False    True        False            False             False   \n",
       "2     False    True        False            False             False   \n",
       "3     False    True        False            False             False   \n",
       "4     False    True        False            False             False   \n",
       "\n",
       "   profanity_obscene  racism  religious_intolerance  sexism  xenophobia  \n",
       "0              False   False                  False   False       False  \n",
       "1               True   False                  False   False       False  \n",
       "2              False   False                  False   False       False  \n",
       "3              False   False                  False   False       False  \n",
       "4               True   False                  False   False       False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Downloading data from Kaggle\")\n",
    "\n",
    "kaggle = KaggleApi()\n",
    "kaggle.authenticate()\n",
    "kaggle.dataset_download_file(dataset=\"olidbr\", file_name=\"olidbr.csv\")\n",
    "\n",
    "olidbr = pd.read_csv(\"olidbr.csv\")\n",
    "\n",
    "olidbr.toxic_spans = olidbr.toxic_spans.apply(lambda x: literal_eval(x) if pd.notnull(x) else x)\n",
    "\n",
    "Path(\"olidbr.csv\").unlink()\n",
    "\n",
    "print(f\"Shape: {olidbr.shape}\")\n",
    "olidbr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "\n",
    "for row in olidbr.to_dict(orient=\"records\"):\n",
    "    if isinstance(row.get(\"toxic_spans\"), list) and len(row.get(\"toxic_spans\")) > 0:\n",
    "        keywords.extend(get_toxic_substrings(row[\"text\"], row[\"toxic_spans\"]))\n",
    "\n",
    "keywords = [w.strip() for w in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['homofobico:viado,veado,viadinho,veadinho,viadao,veadao,bicha,bixa,bichinha,bixinha,bichona,bixona,baitola,sapat√£o,sapatao,traveco,bambi,biba,boiola,marica,gayz√£o,gayzao,flor,florzinha',\n",
       " 'obsceno:vagabundo,vagaba,desgra√ßada,desgra√ßado,desgracado,arrombado,arrombada,foder,fuder,fudido,fodido,c√∫,cu,pinto,pau,pal,caralho,caraio,carai,pica,cacete,rola,porra,escroto,buceta,fdp,pqp,vsf,tnc,vtnc,puto,putinho',\n",
       " 'insulto:ac√©falo,acefalo,burro,idiota,trouxa,est√∫pido,estupido,est√∫pida,canalha,demente,retardado,retardada,verme,maldito,maldita,rid√≠culo,ridiculo,rid√≠cula,ridicula,morf√©tico,morfetico,morf√©tica,morfetica,lazarento,lazarenta,lixo,mongol√≥ide,mongoloide,mongol,asqueroso,asquerosa,cretino,cretina,babaca,pilantra',\n",
       " 'racismo:neguinho,neguinha,pretinho,pretinha,escurinho,escurinha,pretinha,pretinho,crioulo,criolo,crioula,criola,macaco,macaca,gorila',\n",
       " 'misogino:puta,vagabunda,vagaba,mulherzinha,piranha,feminazi,putinha,piriguete,vaca,putinha',\n",
       " 'xenofobia:bahiano,baiano,baianagem,xingling,xing ling,xing-ling,carioca,paulista,sulista,mineiro,gringo',\n",
       " '']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get toxic keywords from GitHub\n",
    "## https://github.com/JAugusto97/ToLD-Br/blob/main/experiments/toxic_keywords.txt\n",
    "import requests\n",
    "\n",
    "told_kwds = requests.get(\"https://raw.githubusercontent.com/JAugusto97/ToLD-Br/main/experiments/toxic_keywords.txt\").text.split(\"\\n\")\n",
    "\n",
    "for line in told_kwds:\n",
    "    # Remove start until ':'\n",
    "    if line != '':\n",
    "        line = line.split(\":\")[1]\n",
    "        line = line.split(\",\")\n",
    "        for word in line:\n",
    "            if word.strip() not in keywords:\n",
    "                keywords.append(word.strip())\n",
    "                \n",
    "told_kwds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic keywords: 471\n"
     ]
    }
   ],
   "source": [
    "print(f\"Toxic keywords: {len(keywords)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kwd = []\n",
    "collected_keywords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 10:29:15,012 :: INFO :: 3671207448 :: <module> :: Crawling tweets from keywords.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 471/471 [00:00<00:00, 231759.41it/s]\n",
      "2022-03-27 10:29:15,019 :: INFO :: 3671207448 :: <module> :: 155968 tweets found.\n"
     ]
    }
   ],
   "source": [
    "def contains_alpha_chars(s):\n",
    "    return any(c.isalpha() for c in s)\n",
    "    \n",
    "_logger.info(f\"Crawling tweets from keywords.\")\n",
    "\n",
    "with tqdm(total=len(keywords)) as pbar:\n",
    "    for keyword in keywords:\n",
    "        if keyword not in collected_keywords and contains_alpha_chars(keyword):\n",
    "            pbar.set_description(f\"Crawling {keyword}\")\n",
    "            try:\n",
    "                tmp = twitter.get_tweets_by_keyword(\n",
    "                    keyword=keyword,\n",
    "                    max_count=args.TWITTER_MAX_TWEETS)\n",
    "                data_kwd += tmp\n",
    "                collected_keywords.append(keyword)\n",
    "            except:\n",
    "                pass\n",
    "        pbar.update(1)\n",
    "\n",
    "_logger.info(f\"{len(data_kwd)} tweets found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:33:41,591 :: INFO :: 859693945 :: <module> :: Total tweets: 155968\n"
     ]
    }
   ],
   "source": [
    "data += data_kwd\n",
    "\n",
    "_logger.info(f\"Total tweets: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:32:20,598 :: INFO :: 3371012580 :: <module> :: Starting toxicity prediction.\n",
      "2022-03-28 11:32:20,599 :: INFO :: 3371012580 :: <module> :: Toxic comments rate: 0.7429\n",
      "2022-03-28 11:32:20,600 :: INFO :: 3371012580 :: <module> :: Total comments: 115871\n"
     ]
    }
   ],
   "source": [
    "if not isinstance(args.PERSPECTIVE_API_KEY, str):\n",
    "    _logger.info(\"Perspective API key not set.\")\n",
    "    raise AttributeError(\"Perspective API key not set.\")\n",
    "\n",
    "_logger.info(\"Starting toxicity prediction.\")\n",
    "\n",
    "perspective = PerspectiveAPI(apikey=args.PERSPECTIVE_API_KEY)\n",
    "\n",
    "with tqdm(total=len(data)) as pbar:\n",
    "    pbar.set_description(\"Toxicity prediction\")\n",
    "    for item in data:\n",
    "        if item.toxicity_score is None:\n",
    "            response = perspective.predict(text=item.text)\n",
    "            if isinstance(response.get(\"TOXICITY\"), float):\n",
    "                item.toxicity_score = response.get(\"TOXICITY\")\n",
    "                if item.toxicity_score > args.PERSPECTIVE_THRESHOLD:\n",
    "                    item.is_toxic = True\n",
    "                else:\n",
    "                    item.is_toxic = False\n",
    "        pbar.update(1)\n",
    "\n",
    "toxic_rate = len([i for i in data if i.is_toxic]) / len(data)\n",
    "\n",
    "_logger.info(f\"Toxic comments rate: {toxic_rate:.4f}\")\n",
    "\n",
    "if args.FILTER_TOXIC_COMMENTS:\n",
    "    data = [item for item in data if item.is_toxic]\n",
    "\n",
    "_logger.info(f\"Total comments: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:33:05,638 :: INFO :: 495907151 :: <module> :: Starting anonymization.\n",
      "2022-03-28 11:33:05,639 :: INFO :: 495907151 :: <module> :: Anonymization finished.\n"
     ]
    }
   ],
   "source": [
    "_logger.info(\"Starting anonymization.\")\n",
    "\n",
    "anonymizer = Anonymizer()\n",
    "\n",
    "for item in data:\n",
    "    item.text = anonymizer.apply_all(item.text)\n",
    "\n",
    "_logger.info(\"Anonymization finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:33:14,789 :: INFO :: 3455279744 :: <module> :: Uploading data to S3.\n",
      "2022-03-28 11:33:14,791 :: INFO :: 3455279744 :: <module> :: Data uploaded to S3.\n"
     ]
    }
   ],
   "source": [
    "_logger.info(\"Uploading data to S3.\")\n",
    "\n",
    "key = datetime.datetime.now().strftime(\"%Y-%m-%d\") + \".json\"\n",
    "\n",
    "# Convert our data to dicts in Label Studio format\n",
    "data = [label_studio_fmt(i) for i in data]\n",
    "\n",
    "uploader = Uploader(bucket=args.AWS_S3_BUCKET,\n",
    "                    bucket_prefix=args.AWS_S3_BUCKET_PREFIX)\n",
    "\n",
    "if isinstance(args.AWS_ROLE_ARN, str):\n",
    "    uploader.upload_sts(role_arn=args.AWS_ROLE_ARN,\n",
    "                        session_name=\"ToxicityDetectionCrawler\",\n",
    "                        key=key, data=data)\n",
    "elif isinstance(args.AWS_ACCESS_KEY_ID, str) and isinstance(args.AWS_SECRET_ACCESS_KEY, str):\n",
    "    uploader.upload_aksk(access_key=args.AWS_ACCESS_KEY_ID,\n",
    "                            secret_key=args.AWS_SECRET_ACCESS_KEY,\n",
    "                            key=key, data=data)\n",
    "else:\n",
    "    _logger.error(\"AWS credentials not set.\")\n",
    "    raise AttributeError(\"AWS credentials not set.\")\n",
    "\n",
    "_logger.info(\"Data uploaded to S3.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
