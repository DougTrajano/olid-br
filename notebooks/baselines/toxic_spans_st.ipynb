{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Spans Detection\n",
    "\n",
    "In this notebook, we will train a model to detect toxic spans in text.\n",
    "\n",
    "We will use [simpletransformers](https://simpletransformers.ai/) that is a wrapper for many popular models available in [Hugging Face](https://huggingface.co/).\n",
    "\n",
    "We will use a pre-trained model ([neuralmind/bert-base-portuguese-cased Â· Hugging Face](https://huggingface.co/neuralmind/bert-base-portuguese-cased)) that is trained on Portuguese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In the first cell, we set the `KAGGLE_USERNAME` and `KAGGLE_KEY` environment variables. We also import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"dougtrajano\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"ce5588a6577391214c6ef22fcb5bd507\"\n",
    "\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from typing import List, Dict, Any\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simpletransformers.question_answering import (\n",
    "    QuestionAnsweringModel,\n",
    "    QuestionAnsweringArgs\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "_logger = logging.getLogger(\"transformers\")\n",
    "_logger.setLevel(logging.WARNING)\n",
    "\n",
    "seed = 1993"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we will remove some folders used by `simpletransformers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folders = [\"cache_dir\", \"outputs\", \"runs\"]\n",
    "\n",
    "for folder in temp_folders:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "In this section, we will define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toxic_substrings(text: str, spans: List[int], verbose=False) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract string words based on a list of spans.\n",
    "\n",
    "    Args:\n",
    "    - text: The text to extract words from.\n",
    "    - spans: A list of spans to extract words from.\n",
    "\n",
    "    Returns:\n",
    "    - A list of words extracted from the text.\n",
    "    \"\"\"\n",
    "    def format_substring(substring: str):\n",
    "        return \" \".join(\"\".join(substring).split())\n",
    "\n",
    "    delimiter = None\n",
    "    words = []\n",
    "    tmp = []\n",
    "    for i in range(len(text)):\n",
    "        if i in spans:\n",
    "            if verbose:\n",
    "                print(f\"Found span at {i} ({text[i]})\")\n",
    "            if delimiter is None:\n",
    "                delimiter = i\n",
    "            else:\n",
    "                delimiter += 1\n",
    "            tmp.append(text[i])\n",
    "        else:\n",
    "            tmp.append(\" \")\n",
    "\n",
    "        if delimiter is not None and i != delimiter:\n",
    "            words.append(format_substring(tmp))\n",
    "            tmp = []\n",
    "            delimiter = None\n",
    "\n",
    "    if len(tmp) > 0:\n",
    "        words.append(format_substring(tmp))\n",
    "        \n",
    "    words = [w for w in words if w not in [\" \", \"\"]]\n",
    "    return words\n",
    "\n",
    "class DataPreprocessing(object):\n",
    "    \"\"\"\n",
    "    Data preprocessing class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.id = 0\n",
    "\n",
    "    def __call__(self, X: List[str], Y: List[List[int]]):\n",
    "        data = []\n",
    "        for x, y in zip(X, Y):\n",
    "            row = {\"context\": x, \"qas\": []}\n",
    "\n",
    "            if y is not None:\n",
    "                y = get_toxic_substrings(x, y)\n",
    "\n",
    "                for i in y:\n",
    "                    tmp = {\n",
    "                        \"id\": self.id,\n",
    "                        \"is_impossible\": False,\n",
    "                        \"question\": \"What's the toxic substring?\",\n",
    "                        \"answers\": [\n",
    "                            {\n",
    "                                \"text\": i,\n",
    "                                \"answer_start\": x.find(i)\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "\n",
    "                    row[\"qas\"].append(tmp)\n",
    "            else:\n",
    "                tmp = {\n",
    "                    \"id\": self.id,\n",
    "                    \"is_impossible\": True,\n",
    "                    \"question\": \"What's the toxic substring?\",\n",
    "                    \"answers\": []\n",
    "                    }\n",
    "\n",
    "                row[\"qas\"].append(tmp)\n",
    "\n",
    "            self.id += 1\n",
    "            data.append(row)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "In this section, we will download the data and load it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"olidbr.csv\"):\n",
    "    print(\"Downloading data from Kaggle\")\n",
    "    kaggle = KaggleApi()\n",
    "    kaggle.authenticate()\n",
    "    kaggle.dataset_download_file(dataset=\"olidbr\", file_name=\"olidbr.csv\")\n",
    "\n",
    "df = pd.read_csv(\"olidbr.csv\")\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Comments with spans assigned: {df[df.toxic_spans.notnull()].shape[0]} ({df[df.toxic_spans.notnull()].shape[0] / df.shape[0] * 100:.2f}%)\")\n",
    "print(f\"Comments without spans assigned: {df[df.toxic_spans.isnull()].shape[0]} ({df[df.toxic_spans.isnull()].shape[0] / df.shape[0] * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to filter out the comments that do not have a toxic span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"toxic_spans\"].notnull()]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df[\"toxic_spans\"] = df[\"toxic_spans\"].apply(lambda x: eval(x))\n",
    "\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative analysis\n",
    "\n",
    "In the second cell, we load the data and perform an exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_substrs = []\n",
    "\n",
    "for row in df.to_dict(orient=\"records\"):\n",
    "    if row.get(\"toxic_spans\") is not None:\n",
    "        toxic_substrs.extend(get_toxic_substrings(row[\"text\"], row[\"toxic_spans\"]))\n",
    "\n",
    "print(f\"toxic_substrs: {len(toxic_substrs)}\")\n",
    "\n",
    "wc = WordCloud(width=1920, height=1024,\n",
    "               max_words=200, max_font_size=100)\n",
    "\n",
    "wc.generate(\" \".join(toxic_substrs))\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "In this section, we will prepare the data in order to train the model.\n",
    "\n",
    "The `simpletransformers` library expects the data in a specific format.\n",
    "\n",
    "More information about the format can be found in the [Question Answering Data Formats - Simple Transformers](https://simpletransformers.ai/docs/qa-data-formats/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"text\", \"toxic_spans\"]]\n",
    "\n",
    "X = df[\"text\"].values\n",
    "y = df[\"toxic_spans\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc = DataPreprocessing()\n",
    "train_data = prc(X_train, y_train)\n",
    "eval_data = prc(X_test, y_test)\n",
    "\n",
    "print(\"Train data\", train_data[0], sep=\"\\n\")\n",
    "print(\"Eval data\", eval_data[0], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "In this section, we will train a baseline model to predict if a toxic comment is targeted or not.\n",
    "\n",
    "We will not perform hyperparameter tuning because it is a simple baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = QuestionAnsweringArgs(\n",
    "    num_train_epochs=6,\n",
    "    evaluate_during_training=True\n",
    ")\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = QuestionAnsweringModel(\n",
    "    model_type=\"bert\",\n",
    "    model_name=\"neuralmind/bert-base-portuguese-cased\",\n",
    "    args=model_args,\n",
    "    use_cuda=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_data, eval_data=eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "In this section, we will evaluate the model with the following metrics:\n",
    "\n",
    "- **Accuracy**: the percentage of correct predictions;\n",
    "- **Precision**: the percentage of predicted targeted comments that are actually targeted;\n",
    "- **Recall**: the percentage of targeted comments that are actually predicted as targeted;\n",
    "- **F1-Score**: the harmonic mean of precision and recall;\n",
    "- **ROC AUC**: the area under the receiver operating characteristic Curve (ROC AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, texts = model.eval_model(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, digits=4,\n",
    "                            target_names=classes.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "In the last section, we will test the model with some comments from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers, probabilities = model.predict(eval_data)\n",
    "\n",
    "print(answers)\n",
    "print(probabilities)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
