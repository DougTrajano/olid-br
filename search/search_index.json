{"config":{"indexing":"full","lang":["en","pt"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"data-pipeline.html","text":"Data Pipeline # In this section, we describe the data pipeline used to generate the dataset. Data Source # We collected comments from different sources, such as Twitter , YouTube , and related datasets. For each social media (Twitter and YouTube), we defined a set of public profiles that we considered relevant to the topic. Additionally, we used Brazilian texts from other datasets, such as: rogersdepelle/OffComBR: Here we provide a data set of web comments which have been annotated for hate speech. paulafortuna/Portuguese-Hate-Speech-Dataset: A Hierarchically-Labeled Portuguese Hate Speech Dataset LaCAfe/Dataset-Hatespeech: Hate Speech Detection Dataset JAugusto97/ToLD-Br: Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis Architecture # The following diagram shows the architecture of the data pipeline . Architecture - Image by author. Filtering # We want to filter out comments that are not relevant to the scope of the dataset. Comments must be in Portuguese. Comments that have one or more related keywords. Privacy # We will apply some privacy policies to the comments collected from each source directly in the ingestion pipeline. User mentions were replaced with the word \"@USER\". URLs were replaced with the word \"URL\".","title":"Data Pipeline"},{"location":"data-pipeline.html#data-pipeline","text":"In this section, we describe the data pipeline used to generate the dataset.","title":"Data Pipeline"},{"location":"data-pipeline.html#data-source","text":"We collected comments from different sources, such as Twitter , YouTube , and related datasets. For each social media (Twitter and YouTube), we defined a set of public profiles that we considered relevant to the topic. Additionally, we used Brazilian texts from other datasets, such as: rogersdepelle/OffComBR: Here we provide a data set of web comments which have been annotated for hate speech. paulafortuna/Portuguese-Hate-Speech-Dataset: A Hierarchically-Labeled Portuguese Hate Speech Dataset LaCAfe/Dataset-Hatespeech: Hate Speech Detection Dataset JAugusto97/ToLD-Br: Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis","title":"Data Source"},{"location":"data-pipeline.html#architecture","text":"The following diagram shows the architecture of the data pipeline . Architecture - Image by author.","title":"Architecture"},{"location":"data-pipeline.html#filtering","text":"We want to filter out comments that are not relevant to the scope of the dataset. Comments must be in Portuguese. Comments that have one or more related keywords.","title":"Filtering"},{"location":"data-pipeline.html#privacy","text":"We will apply some privacy policies to the comments collected from each source directly in the ingestion pipeline. User mentions were replaced with the word \"@USER\". URLs were replaced with the word \"URL\".","title":"Privacy"},{"location":"get-started.html","text":"The dataset will be available on Kaggle and Hugging Face. Kaggle # You can see the dataset on OLID-BR | Kaggle . The snippet below shows how to download the dataset using the Kaggle API. 1 2 3 4 5 from kaggle.api.kaggle_api_extended import KaggleApi kaggle = KaggleApi () kaggle . authenticate () kaggle . dataset_download_files ( dataset = \"olidbr\" , unzip = True ) Hugging Face # You can see the OLID-BR dataset on dougtrajano/olid-br \u00b7 Datasets at Hugging Face . 1 2 from datasets import load_dataset dataset = load_dataset ( \"dougtrajano/olid-br\" ) Dataset Files # The dataset is composed of the following files: train.csv : contains the training. test.csv : contains the test data. train_metadata.csv : contains the metadata of the training data. test_metadata.csv : contains the metadata of the test data. train.json : contains the training data in JSON format. test.json : contains the test data in JSON format. additional_data.json : contains additional data in JSON format. This data was not used in the creation of the dataset. train.csv and test.csv follow the label assignment described in the Label Assignment section. The JSON files ( train.json , test.json , and additional_data.json ) contain all three annotations and the metadata for each instance. Hugging Face only has the train ( train.csv ) and test ( test.csv ) files. Data Format # CSV # The CSV files are encoded in UTF-8 and have the following columns: id (string): Unique identifier of the instance. text (string): The text of the instance. is_offensive (string): Whether the text is offensive ( OFF ) or not ( NOT ). is_targeted (string): Whether the text is targeted ( TIN ) or untargeted ( UNT ). targeted_type (string): Type of the target (individual IND , group GRP , or other OTH ). Only available if is_targeted is True . toxic_spans (string): List of toxic spans. health (boolean): Whether the text contains hate speech based on health conditions such as disability, disease, etc. ideology (boolean): Indicates if the text contains hate speech based on a person's ideas or beliefs. insult (boolean): Whether the text contains insult, inflammatory, or provocative content. lgbtqphobia (boolean): Whether the text contains harmful content related to gender identity or sexual orientation. other_lifestyle (boolean): Whether the text contains hate speech related to life habits (e.g. veganism, vegetarianism, etc.). physical_aspects (boolean): Whether the text contains hate speech related to physical appearance. profanity_obscene (boolean): Whether the text contains profanity or obscene content. racism (boolean): Whether the text contains prejudiced thoughts or discriminatory actions based on differences in race/ethnicity. religious_intolerance (boolean): Whether the text contains religious intolerance. sexism (boolean): Whether the text contains discriminatory content based on differences in sex/gender (e.g. sexism, misogyny, etc.). xenophobia (boolean): Whether the text contains hate speech against foreigners. The CSV files follow our label assignment strategy as described below. is_offensive : majority vote. is_targeted : majority vote. targeted_type : majority vote. toxic_spans : all labeled spans. health : at least one. ideology : at least one. insult : at least one. lgbtqphobia : at least one. other_lifestyle : at least one. physical_aspects : at least one. profanity_obscene : at least one. racism : at least one. religious_intolerance : at least one. sexism : at least one. xenophobia : at least one. JSON # The JSON files are encoded in UTF-8 and have the following schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \"id\" : \"string\" , \"text\" : \"string\" , \"metadata\" : { \"source\" : \"string\" , \"created_at\" : \"string\" , \"collected_at\" : \"string\" , \"toxicity_score\" : \"number\" , }, \"annotations\" : [ { \"annotator_id\" : \"number\" , \"is_offensive\" : \"string\" , \"is_targeted\" : \"string\" , \"targeted_type\" : \"string\" , \"toxic_spans\" : [ \"number\" ], \"health\" : \"boolean\" , \"ideology\" : \"boolean\" , \"insult\" : \"boolean\" , \"lgbtqphobia\" : \"boolean\" , \"other_lifestyle\" : \"boolean\" , \"physical_aspects\" : \"boolean\" , \"profanity_obscene\" : \"boolean\" , \"racism\" : \"boolean\" , \"religious_intolerance\" : \"boolean\" , \"sexism\" : \"boolean\" , \"xenophobia\" : \"boolean\" } ] } Metadata # We provide some metadata for the dataset to help further analysis. Annotators # For each qualified annotator, we asked him/her to provide the following information: annotator_id : The annotator's unique ID. age : The annotator's age. gender The gender of the annotator. Male Female Other education_level : The education level of the annotator. Primary School Secondary School Bachelor's Degree Master's Degree Doctoral Degree annotator_type : The type of the annotator. Volunteer Researcher Contract Worker background : The background of the annotator. Computer Science Social Science This information can be used to provide a better understanding of the annotator profile, maintaining the anonymity of the annotator Comments # For each comment, we collect contextual information based on the social media posts or the dataset that it comes from. source The social media platform where the text was posted. created_at The date and time of the post. collected_at The date and time of the collection. toxicity_score The toxicity score of the comment.","title":"Get Started"},{"location":"get-started.html#kaggle","text":"You can see the dataset on OLID-BR | Kaggle . The snippet below shows how to download the dataset using the Kaggle API. 1 2 3 4 5 from kaggle.api.kaggle_api_extended import KaggleApi kaggle = KaggleApi () kaggle . authenticate () kaggle . dataset_download_files ( dataset = \"olidbr\" , unzip = True )","title":"Kaggle"},{"location":"get-started.html#hugging-face","text":"You can see the OLID-BR dataset on dougtrajano/olid-br \u00b7 Datasets at Hugging Face . 1 2 from datasets import load_dataset dataset = load_dataset ( \"dougtrajano/olid-br\" )","title":"Hugging Face"},{"location":"get-started.html#dataset-files","text":"The dataset is composed of the following files: train.csv : contains the training. test.csv : contains the test data. train_metadata.csv : contains the metadata of the training data. test_metadata.csv : contains the metadata of the test data. train.json : contains the training data in JSON format. test.json : contains the test data in JSON format. additional_data.json : contains additional data in JSON format. This data was not used in the creation of the dataset. train.csv and test.csv follow the label assignment described in the Label Assignment section. The JSON files ( train.json , test.json , and additional_data.json ) contain all three annotations and the metadata for each instance. Hugging Face only has the train ( train.csv ) and test ( test.csv ) files.","title":"Dataset Files"},{"location":"get-started.html#data-format","text":"","title":"Data Format"},{"location":"get-started.html#csv","text":"The CSV files are encoded in UTF-8 and have the following columns: id (string): Unique identifier of the instance. text (string): The text of the instance. is_offensive (string): Whether the text is offensive ( OFF ) or not ( NOT ). is_targeted (string): Whether the text is targeted ( TIN ) or untargeted ( UNT ). targeted_type (string): Type of the target (individual IND , group GRP , or other OTH ). Only available if is_targeted is True . toxic_spans (string): List of toxic spans. health (boolean): Whether the text contains hate speech based on health conditions such as disability, disease, etc. ideology (boolean): Indicates if the text contains hate speech based on a person's ideas or beliefs. insult (boolean): Whether the text contains insult, inflammatory, or provocative content. lgbtqphobia (boolean): Whether the text contains harmful content related to gender identity or sexual orientation. other_lifestyle (boolean): Whether the text contains hate speech related to life habits (e.g. veganism, vegetarianism, etc.). physical_aspects (boolean): Whether the text contains hate speech related to physical appearance. profanity_obscene (boolean): Whether the text contains profanity or obscene content. racism (boolean): Whether the text contains prejudiced thoughts or discriminatory actions based on differences in race/ethnicity. religious_intolerance (boolean): Whether the text contains religious intolerance. sexism (boolean): Whether the text contains discriminatory content based on differences in sex/gender (e.g. sexism, misogyny, etc.). xenophobia (boolean): Whether the text contains hate speech against foreigners. The CSV files follow our label assignment strategy as described below. is_offensive : majority vote. is_targeted : majority vote. targeted_type : majority vote. toxic_spans : all labeled spans. health : at least one. ideology : at least one. insult : at least one. lgbtqphobia : at least one. other_lifestyle : at least one. physical_aspects : at least one. profanity_obscene : at least one. racism : at least one. religious_intolerance : at least one. sexism : at least one. xenophobia : at least one.","title":"CSV"},{"location":"get-started.html#json","text":"The JSON files are encoded in UTF-8 and have the following schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \"id\" : \"string\" , \"text\" : \"string\" , \"metadata\" : { \"source\" : \"string\" , \"created_at\" : \"string\" , \"collected_at\" : \"string\" , \"toxicity_score\" : \"number\" , }, \"annotations\" : [ { \"annotator_id\" : \"number\" , \"is_offensive\" : \"string\" , \"is_targeted\" : \"string\" , \"targeted_type\" : \"string\" , \"toxic_spans\" : [ \"number\" ], \"health\" : \"boolean\" , \"ideology\" : \"boolean\" , \"insult\" : \"boolean\" , \"lgbtqphobia\" : \"boolean\" , \"other_lifestyle\" : \"boolean\" , \"physical_aspects\" : \"boolean\" , \"profanity_obscene\" : \"boolean\" , \"racism\" : \"boolean\" , \"religious_intolerance\" : \"boolean\" , \"sexism\" : \"boolean\" , \"xenophobia\" : \"boolean\" } ] }","title":"JSON"},{"location":"get-started.html#metadata","text":"We provide some metadata for the dataset to help further analysis.","title":"Metadata"},{"location":"get-started.html#annotators","text":"For each qualified annotator, we asked him/her to provide the following information: annotator_id : The annotator's unique ID. age : The annotator's age. gender The gender of the annotator. Male Female Other education_level : The education level of the annotator. Primary School Secondary School Bachelor's Degree Master's Degree Doctoral Degree annotator_type : The type of the annotator. Volunteer Researcher Contract Worker background : The background of the annotator. Computer Science Social Science This information can be used to provide a better understanding of the annotator profile, maintaining the anonymity of the annotator","title":"Annotators"},{"location":"get-started.html#comments","text":"For each comment, we collect contextual information based on the social media posts or the dataset that it comes from. source The social media platform where the text was posted. created_at The date and time of the post. collected_at The date and time of the collection. toxicity_score The toxicity score of the comment.","title":"Comments"},{"location":"glossary.html","text":"In this page, we have a collection of terms definitions that are used in the OLID-BR and Toxicity Detection project. Kinds of Offensive Language # Hate Speech # A type of speech that is used to attack a group of people. 1 Cyberbullying # A type of speech that is used to attack an individual directly. 1 Categories # Health # Hate speech based on health conditions, such as against disabled people. 4 Ideology # Hate speech based on a person's ideas, such as feminist or left wing ideology. 4 Insult # Insulting, inflammatory, or negative comment towards a person or a group of people. 2 LGBTQphobia # Negative or hateful comments targeting someone because of their gender identity, sexual orientation. 2 Other-Lifestyle # Hate speech based on life habits, such as vegetarian, vegan, etc. 4 Physical aspects # Hate speech based on physical aspects, such as fat, thin, tail or short people, etc. 4 Profanity/Obscene # Hateful comments with swear words, or other obscene or profane language. 2 Racism # Prejudiced thoughts and discriminatory actions based on difference in race/ethnicity. 3 Religious intolerance # Prejudiced thoughts and discriminatory actions based on the religion, cult or religious practice. 4 Sexism # Prejudiced thoughts and discriminatory actions based on difference in sex/gender, usually by men against women (a.k.a misogyny). 3 Xenophobia # The fear or hatred of foreigners. 3 Zampieri et al. \"Predicting the type and target of offensive posts in social media.\" NAACL 2019. \u21a9 \u21a9 \"Perspective | Developers\", Developers.perspectiveapi.com, 2021. [Online]. Available: https://developers.perspectiveapi.com/s/about-the-api-attributes-and-languages . [Accessed: 21- Aug- 2021] \u21a9 \u21a9 \u21a9 Washington University - Student Affairs. (2020, August 12). Glossary of bias terms. Students. https://students.wustl.edu/glossary-bias-terms/ . \u21a9 \u21a9 \u21a9 Fortuna, Paula, et al. \"A hierarchically-labeled portuguese hate speech dataset.\" Proceedings of the Third Workshop on Abusive Language Online. 2019. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9","title":"Glossary"},{"location":"glossary.html#kinds-of-offensive-language","text":"","title":"Kinds of Offensive Language"},{"location":"glossary.html#hate-speech","text":"A type of speech that is used to attack a group of people. 1","title":"Hate Speech"},{"location":"glossary.html#cyberbullying","text":"A type of speech that is used to attack an individual directly. 1","title":"Cyberbullying"},{"location":"glossary.html#categories","text":"","title":"Categories"},{"location":"glossary.html#health","text":"Hate speech based on health conditions, such as against disabled people. 4","title":"Health"},{"location":"glossary.html#ideology","text":"Hate speech based on a person's ideas, such as feminist or left wing ideology. 4","title":"Ideology"},{"location":"glossary.html#insult","text":"Insulting, inflammatory, or negative comment towards a person or a group of people. 2","title":"Insult"},{"location":"glossary.html#lgbtqphobia","text":"Negative or hateful comments targeting someone because of their gender identity, sexual orientation. 2","title":"LGBTQphobia"},{"location":"glossary.html#other-lifestyle","text":"Hate speech based on life habits, such as vegetarian, vegan, etc. 4","title":"Other-Lifestyle"},{"location":"glossary.html#physical-aspects","text":"Hate speech based on physical aspects, such as fat, thin, tail or short people, etc. 4","title":"Physical aspects"},{"location":"glossary.html#profanityobscene","text":"Hateful comments with swear words, or other obscene or profane language. 2","title":"Profanity/Obscene"},{"location":"glossary.html#racism","text":"Prejudiced thoughts and discriminatory actions based on difference in race/ethnicity. 3","title":"Racism"},{"location":"glossary.html#religious-intolerance","text":"Prejudiced thoughts and discriminatory actions based on the religion, cult or religious practice. 4","title":"Religious intolerance"},{"location":"glossary.html#sexism","text":"Prejudiced thoughts and discriminatory actions based on difference in sex/gender, usually by men against women (a.k.a misogyny). 3","title":"Sexism"},{"location":"glossary.html#xenophobia","text":"The fear or hatred of foreigners. 3 Zampieri et al. \"Predicting the type and target of offensive posts in social media.\" NAACL 2019. \u21a9 \u21a9 \"Perspective | Developers\", Developers.perspectiveapi.com, 2021. [Online]. Available: https://developers.perspectiveapi.com/s/about-the-api-attributes-and-languages . [Accessed: 21- Aug- 2021] \u21a9 \u21a9 \u21a9 Washington University - Student Affairs. (2020, August 12). Glossary of bias terms. Students. https://students.wustl.edu/glossary-bias-terms/ . \u21a9 \u21a9 \u21a9 Fortuna, Paula, et al. \"A hierarchically-labeled portuguese hate speech dataset.\" Proceedings of the Third Workshop on Abusive Language Online. 2019. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9","title":"Xenophobia"},{"location":"index.html","text":"OLID-BR # Offensive Language Identification Dataset for Brazilian Portuguese (OLID-BR) is a dataset with multi-task annotations for the detection of offensive language. The current version (v1.0) contains 7,943 (extendable to 13,538) comments from different sources, including social media (YouTube and Twitter) and related datasets. OLID-BR contains a collection of annotated sentences in Brazilian Portuguese using an annotation model that encompasses the following levels: Offensive content detection Offense target identification Offensive spans identification Hierarchical taxonomy for categorizing offensive language. Proposed by author, adapted from Zampieri et al. (2019) . Categorization # Offensive Content Detection # This level is used to detect offensive content in the sentence. Is this text offensive? We use the Perspective API to detect if the sentence contains offensive content with double-checking by our qualified annotators . OFF Offensive: Inappropriate language, insults, or threats. NOT Not offensive: No offense or profanity. Which kind of offense does it contain? The following labels were tagged by our annotators: Health , Ideology , Insult , LGBTQphobia , Other-Lifestyle , Physical Aspects , Profanity/Obscene , Racism , Religious Intolerance , Sexism , and Xenophobia . See the Glossary for further information. Offense Target Identification # This level is used to detect if an offensive sentence is targeted to a person or group of people. Is the offensive text targeted? TIN Targeted Insult: Targeted insult or threat towards an individual, a group or other. UNT Untargeted: Non-targeted profanity and swearing. What is the target of the offense? IND The offense targets an individual, often defined as \u201ccyberbullying\u201d. GRP The offense targets a group of people based on ethnicity, gender, sexual OTH The target can belong to other categories, such as an organization, an event, an issue, etc. Offensive Spans Identification # As toxic spans, we define a sequence of words that attribute to the text's toxicity. For example, let's consider the following text: \"USER Canalha URL\" The toxic spans are: 1 [ 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 ] Dataset Structure # Data Instances # Each instance is a social media comment with a corresponding ID and annotations for all the tasks described below. Data Fields # The simplified configuration includes: id (string): Unique identifier of the instance. text (string): The text of the instance. is_offensive (string): Whether the text is offensive ( OFF ) or not ( NOT ). is_targeted (string): Whether the text is targeted ( TIN ) or untargeted ( UNT ). targeted_type (string): Type of the target (individual IND , group GRP , or other OTH ). Only available if is_targeted is True . toxic_spans (string): List of toxic spans. health (boolean): Whether the text contains hate speech based on health conditions such as disability, disease, etc. ideology (boolean): Indicates if the text contains hate speech based on a person's ideas or beliefs. insult (boolean): Whether the text contains insult, inflammatory, or provocative content. lgbtqphobia (boolean): Whether the text contains harmful content related to gender identity or sexual orientation. other_lifestyle (boolean): Whether the text contains hate speech related to life habits (e.g. veganism, vegetarianism, etc.). physical_aspects (boolean): Whether the text contains hate speech related to physical appearance. profanity_obscene (boolean): Whether the text contains profanity or obscene content. racism (boolean): Whether the text contains prejudiced thoughts or discriminatory actions based on differences in race/ethnicity. religious_intolerance (boolean): Whether the text contains religious intolerance. sexism (boolean): Whether the text contains discriminatory content based on differences in sex/gender (e.g. sexism, misogyny, etc.). xenophobia (boolean): Whether the text contains hate speech against foreigners. See the Get Started page for more information. Considerations for Using the Data # Social Impact of Dataset # Toxicity detection is a worthwhile problem that can ensure a safer online environment for everyone. However, toxicity detection algorithms have focused on English and do not consider the specificities of other languages. This is a problem because the toxicity of a comment can be different in different languages. Additionally, the toxicity detection algorithms focus on the binary classification of a comment as toxic or not toxic. Therefore, we believe that the OLID-BR dataset can help to improve the performance of toxicity detection algorithms in Brazilian Portuguese. Discussion of Biases # We are aware that the dataset contains biases and is not representative of global diversity. We are aware that the language used in the dataset could not represent the language used in different contexts. Potential biases in the data include: Inherent biases in the social media and user base biases, the offensive/vulgar word lists used for data filtering, and inherent or unconscious bias in the assessment of offensive identity labels. All these likely affect labeling, precision, and recall for a trained model. Citation # Pending References # The OLID-BR dataset is based on the OLID dataset proposed by Zampieri et al. (2019) 1 and other related works. Zampieri et al. \"Predicting the type and target of offensive posts in social media.\" NAACL 2019. \u21a9 Jo\u00e3o A. Leite, Diego F. Silva, Kalina Bontcheva, Carolina Scarton (2020): Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis. Published at AACL-IJCNLP 2020. \u21a9 S. Malmasi, \"Offensive Language Identification Dataset - OLID\", Scholar.harvard.edu, 2021. [Online]. Available: https://scholar.harvard.edu/malmasi/olid . [Accessed: 28- Aug- 2021]. \u21a9 Weng, L. (2021, March 21). Reducing toxicity in language models. Lil'Log. https://lilianweng.github.io/lil-log/2021/03/21/reducing-toxicity-in-language-models.html . \u21a9","title":"Overview"},{"location":"index.html#olid-br","text":"Offensive Language Identification Dataset for Brazilian Portuguese (OLID-BR) is a dataset with multi-task annotations for the detection of offensive language. The current version (v1.0) contains 7,943 (extendable to 13,538) comments from different sources, including social media (YouTube and Twitter) and related datasets. OLID-BR contains a collection of annotated sentences in Brazilian Portuguese using an annotation model that encompasses the following levels: Offensive content detection Offense target identification Offensive spans identification Hierarchical taxonomy for categorizing offensive language. Proposed by author, adapted from Zampieri et al. (2019) .","title":"OLID-BR"},{"location":"index.html#categorization","text":"","title":"Categorization"},{"location":"index.html#offensive-content-detection","text":"This level is used to detect offensive content in the sentence. Is this text offensive? We use the Perspective API to detect if the sentence contains offensive content with double-checking by our qualified annotators . OFF Offensive: Inappropriate language, insults, or threats. NOT Not offensive: No offense or profanity. Which kind of offense does it contain? The following labels were tagged by our annotators: Health , Ideology , Insult , LGBTQphobia , Other-Lifestyle , Physical Aspects , Profanity/Obscene , Racism , Religious Intolerance , Sexism , and Xenophobia . See the Glossary for further information.","title":"Offensive Content Detection"},{"location":"index.html#offense-target-identification","text":"This level is used to detect if an offensive sentence is targeted to a person or group of people. Is the offensive text targeted? TIN Targeted Insult: Targeted insult or threat towards an individual, a group or other. UNT Untargeted: Non-targeted profanity and swearing. What is the target of the offense? IND The offense targets an individual, often defined as \u201ccyberbullying\u201d. GRP The offense targets a group of people based on ethnicity, gender, sexual OTH The target can belong to other categories, such as an organization, an event, an issue, etc.","title":"Offense Target Identification"},{"location":"index.html#offensive-spans-identification","text":"As toxic spans, we define a sequence of words that attribute to the text's toxicity. For example, let's consider the following text: \"USER Canalha URL\" The toxic spans are: 1 [ 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 ]","title":"Offensive Spans Identification"},{"location":"index.html#dataset-structure","text":"","title":"Dataset Structure"},{"location":"index.html#data-instances","text":"Each instance is a social media comment with a corresponding ID and annotations for all the tasks described below.","title":"Data Instances"},{"location":"index.html#data-fields","text":"The simplified configuration includes: id (string): Unique identifier of the instance. text (string): The text of the instance. is_offensive (string): Whether the text is offensive ( OFF ) or not ( NOT ). is_targeted (string): Whether the text is targeted ( TIN ) or untargeted ( UNT ). targeted_type (string): Type of the target (individual IND , group GRP , or other OTH ). Only available if is_targeted is True . toxic_spans (string): List of toxic spans. health (boolean): Whether the text contains hate speech based on health conditions such as disability, disease, etc. ideology (boolean): Indicates if the text contains hate speech based on a person's ideas or beliefs. insult (boolean): Whether the text contains insult, inflammatory, or provocative content. lgbtqphobia (boolean): Whether the text contains harmful content related to gender identity or sexual orientation. other_lifestyle (boolean): Whether the text contains hate speech related to life habits (e.g. veganism, vegetarianism, etc.). physical_aspects (boolean): Whether the text contains hate speech related to physical appearance. profanity_obscene (boolean): Whether the text contains profanity or obscene content. racism (boolean): Whether the text contains prejudiced thoughts or discriminatory actions based on differences in race/ethnicity. religious_intolerance (boolean): Whether the text contains religious intolerance. sexism (boolean): Whether the text contains discriminatory content based on differences in sex/gender (e.g. sexism, misogyny, etc.). xenophobia (boolean): Whether the text contains hate speech against foreigners. See the Get Started page for more information.","title":"Data Fields"},{"location":"index.html#considerations-for-using-the-data","text":"","title":"Considerations for Using the Data"},{"location":"index.html#social-impact-of-dataset","text":"Toxicity detection is a worthwhile problem that can ensure a safer online environment for everyone. However, toxicity detection algorithms have focused on English and do not consider the specificities of other languages. This is a problem because the toxicity of a comment can be different in different languages. Additionally, the toxicity detection algorithms focus on the binary classification of a comment as toxic or not toxic. Therefore, we believe that the OLID-BR dataset can help to improve the performance of toxicity detection algorithms in Brazilian Portuguese.","title":"Social Impact of Dataset"},{"location":"index.html#discussion-of-biases","text":"We are aware that the dataset contains biases and is not representative of global diversity. We are aware that the language used in the dataset could not represent the language used in different contexts. Potential biases in the data include: Inherent biases in the social media and user base biases, the offensive/vulgar word lists used for data filtering, and inherent or unconscious bias in the assessment of offensive identity labels. All these likely affect labeling, precision, and recall for a trained model.","title":"Discussion of Biases"},{"location":"index.html#citation","text":"Pending","title":"Citation"},{"location":"index.html#references","text":"The OLID-BR dataset is based on the OLID dataset proposed by Zampieri et al. (2019) 1 and other related works. Zampieri et al. \"Predicting the type and target of offensive posts in social media.\" NAACL 2019. \u21a9 Jo\u00e3o A. Leite, Diego F. Silva, Kalina Bontcheva, Carolina Scarton (2020): Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis. Published at AACL-IJCNLP 2020. \u21a9 S. Malmasi, \"Offensive Language Identification Dataset - OLID\", Scholar.harvard.edu, 2021. [Online]. Available: https://scholar.harvard.edu/malmasi/olid . [Accessed: 28- Aug- 2021]. \u21a9 Weng, L. (2021, March 21). Reducing toxicity in language models. Lil'Log. https://lilianweng.github.io/lil-log/2021/03/21/reducing-toxicity-in-language-models.html . \u21a9","title":"References"},{"location":"annotation/guidelines.html","text":"Annotation Guidelines # On this page, we will detail the guidelines followed by our annotators in the data labeling process in the OLID-BR. In the figure below, you can see the annotation schema for the OLID-BR dataset. Hierarchical taxonomy for categorizing offensive language, proposed by author. What task are you doing? # You will see comments with offensive/toxic content and you will need to answer some questions about that, these questions will help us identify offensive comments and/or better understand the behavior of haters . In the image below, you can see an example of the labeling interface that our annotators will see. Labeling Interface - Label Studio What questions should you answer? # For each comment, you must answer the following questions: Is this text toxic? # The first question identifies if a given text contains toxic language or not. It's comes pre-filled with \"Yes\", because the comment was filtered by a text classifier previously. You action is to evaluate if the text is really toxic, if not, you can choose the option \"No\". When selecting the \"No\" option, the next questions will be hidden. Which kind of toxicity it has? # In this question, we will try to identify the toxicity type within some pre-defined categories. You can see the categories, their definitions and examples of comments that have each one of them in the blocks below. Health Offensive comment based on health, physical disabilities, age discrimination, characteristics caused by illness, etc. Examples: USER velho broxa Me desculpem gente mulher nenhuma \u00e9 Feliz com esse corpo? Ela precisa de tratamento isso \u00e9 uma doen\u00e7a rt USER esse curso eh coisa de gente retardada mental vsf q porra USER IMBECIL PROMOVENDO A AGLOMERA\u00c7\u00c3O DO POVO USER E A PROPAGA\u00c7\u00c3O DA DOEN\u00c7A. QUANTA USER !!!!!!!!!!!!!!!!!!!!! parece legenda pra cego surdo e mudo Ideology Hate speech based on ideologies such as feminist, political left, etc. Examples: esse partido chamado P T e esse P Sol sao uma doenca pra nossa nacao um enfermo USER A Folha desde sempre apoiando a DITADURA e apoiando FASCISTAS que at\u00e9 se esquece de falar sobre seus ESC\u00c2NDALOS como EMPRESTAR CARROS para a DITADURA ir TORTURAR PESSOAS. A Folha GOLPISTA nunca faz uma \u201cautocr\u00edtica\u201d URL USER Aqui na minha fam\u00edlia fechado com o MITO PT LADR\u00c3O NUNCA VOLTAMOS NESSA RA\u00c7A IMUNDA FDP DE LADR\u00d5ES \u2705\ud83c\udde7\ud83c\uddf7\ud83c\udde7\ud83c\uddf7 URL USER USER USER O Bolsonaro \u00e9 corrupto mlk, para de ser retardado, seu c\u00e9rebro t\u00e1 atrofiando A juiza \u00e9 pilantra igual a Sergio USER quer impor a lei da morda\u00e7a amea\u00e7ando e obrigado o r\u00e9l o expresidente Lula a ficar calado Arma\u00e7\u00e3o geral do judiciario partidario de Curitiba de Sergio USER Bolsonaro: \u201cComo \u00e9 duro ser patr\u00e3o no Brasil\". 19 milh\u00f5es de brasileiros passam fome e a grande preocupa\u00e7\u00e3o do cretino \u00e9 com os patr\u00f5es. Insult Hate speech that contains insult, injury, swearing. Its purpose is to ignite an argument, irritate a party, hit a victim's weak point, etc. Examples: USER USER Fodase denovo tmc para de aoarecer pra min desgra\u00e7a USER Kkkkkkkk \u00e9 mesmo q ano de bosta vai toma no c uuuuuuuu USER Voc\u00ea \u00e9 um lixo! USER Depois que acaba os campeonatos VC vem falar em liberar p\u00fablico nos est\u00e1dios seu bosta calca apertada LGBTQphobia Hate speech based on gender identity or sexual orientation. The comment attacks sexual orientation or gender identity. It includes aphobia, biphobia, homophobia, lesbophobia, transphobia and other phobias related to sexuality. Warning Be careful to don't confuse it with sexism. Examples: Que vergonha esse pais s\u00f3 tem gay USER voce so gosta d sapatao caminhoeira de cabelo rapado USER baitola lixo USER USER lament\u00e1vel acredita que existe pessoas que ap\u00f3ia o LGBT USER O problema n\u00e3o \u00e9 sexualidade e sim compet\u00eancia. \u00c9 diferente ferrar s\u00f3 um rabo ou ferrar de milhares. USER E quando n\u00e3o consegue espa\u00e7o e relev\u00e2ncia no meio, mente que \u00e9 bi. USER Voc\u00ea \u00e9 uma vergonha para os gays pq tu \u00e9 um gay ladr\u00e3o de dinheiro da Pandemia. Other-Lifestyle Hate speech based on lifestyle habits such as vegetarian, vegan, smoker, etc. Examples: Povo da ra\u00e7\u00e3o com milho he he Povinho irritante e desinformado esses veganos chatos. Com certeza nao convencem nem suas familias. USER crackudo voz de fumante Coisa brega esse piercing no nariz. Muito feio para uma jornalista. USER USER seu c\u00e9rebro derreteu por causa da maconha????????? Como ser feminista: Ser feia e gorda Pagar peitinho em passeata Ser peluda Odiar homens E achar q isso far\u00e1 diferen\u00e7a Aula de como comer um maconheiro! Hahaha Ai aonde a tua maconha te levou KKKkKkkK Physical Aspects Hate speech based on physical characteristics such as fatphobia, size, etc. Examples: Pr\u00f3ximo major j\u00e1 sabem, galera: ca\u00e7ar o gordo e extermina-lo. Deveriam ter escolhido uma modelo menos gordinha, ela parece que n\u00e3o est\u00e1 passando fome !! USER pode achar seu principe encantado,mas sempre vai acabar: Gorda,feia,virgem,cheia de poster de crep\u00fasculo a parede!! Me desculpem gente mulher nenhuma \u00e9 Feliz com esse corpo? Ela precisa de tratamento isso \u00e9 uma doen\u00e7a USER nao \u00e9 gorda nao,USER esta obesa.vai se tratar \u00e9 o melhor que USER faz. RT USER: e olha pra cara gorda e feia de Isabelle .. sem contar da voz irritante dela URL A obesidade est\u00e1 acabando com essa mulher. Rid\u00edcula EU N\u00c3O AGUENTO MAIS ESSE ALEIJADO SEM UMA PERNA DO CARALHO VAI TOMAR NO CU, O MALUCO NN SABE ANDAR COM A PERNA DIREITA FUDIDO HORR\u00cdVEL URL Profanity/Obscene Hate speech has obscene, vulgar, pornographic, etc. Examples: USER Comer cu de curioso USER Mas que grande fdp. USER Passar porte de vacina \u00e9 o meu pau USER Cada filho da puta que apertou 17 tem as mas sujas de sangue USER Com a PF na tua casa tu ficou bravinho n\u00e9 vagabundo? USER Toma no cu \u00e9 vitamina como tu e tua prima. fudeu minha m\u00e3e acabou de chegar em casa e eu acabei de acordar tomei no cu Racism The comment is biased or discriminatory based on the race, color or ethnicity of a person or group of people. Examples: Essas filhas de pedreiro africano e foda N\u00e3o tenho tv colorida pra ficar olhando essa preta nao USER E quantos desses negros s\u00e3o inocentes e quantos s\u00e3o criminosos e bandidos? Te dou absoluta certeza que a maioria dos negros mortos n\u00e3o s\u00e3o inocentes, infelizmente muitas vezes inocentes acabam sendo mortos pela corrup\u00e7\u00e3o na pol\u00edcia USER Sai macaco Essa nega do c\u00e3o quer ser a dona da raz\u00e3o e da situa\u00e7\u00e3o smp \ud83d\ude02\ud83d\ude02\ud83d\ude02 Religious Intolerance The comment is biased or discriminatory based on religion, cult or religious practice. Examples: USER Um governo de Evangelicos. Um governo de Corruptos. Um governo de Criminosos. Uma macumbeira a menos Que diabo de Ogum, por isso que n\u00e3o vai pra frente Sexism The comment is biased or discriminatory based on the gender or sex of a person or group of people. Examples: Se eu fosse o Temer criava o Minist\u00e9rio da Cozinha e da Limpeza e colocava uma mulher, s\u00f3 pro pessoal chorar menos. hahahaha USER Uma calcinha dessa fio-dental dentro da bunda n\u00e3o tem que resistir uma tenta\u00e7\u00e3o dessa? Homem \u00e9 um bicho estranho ao mesmo tmp rid\u00edculo \ud83e\udd23 Resumindo\" Meteu gostoso na safada\" fim da historia! N\u00e3o tem dinheiro q essa mulher,ela \u00e9 terr\u00edvel n\u00e3o vai ter homem q a suporte D\u00e1 uma rola pras feminazi.quem sabe elas param de falar bosta. Xenophobia Hate speech against foreigners or people from other cultures. Examples: Quem liga pra judeu kkkk odeio goiano e mineiro rt USER USER nao sei . pra mim todo japones que \u00e9 comunista \u00e9 burro... uma coisa q meu pai ensinou kk esse chinezinho falsificado e um pilantra. N\u00e3o se deixa enganar como ele enganou os que votaram nele. Esse tipo de jumento s\u00f3 se elege uma vez. USER O brasileiro merece o que t\u00e1 passando povo ignorante e sem a menor consci\u00eancia bando de fudido do caralho USER USER PUTAQUEPARIUUUUUU........ESSAS PORCARIAS S\u00d3 ACONTECE NO BRASIL.... RA\u00c7A MALDITA ESSES BRASILEIROS....EXTIN\u00c7AO Nordestino \u00e9 uma desgra\u00e7a cambada de dem\u00f4nio There's a specific target? # In this question, we want to know if the toxic comment is targeted or not, and if it is, the type of target. Important Check only if there is a clear target for the toxic comment. Options: Individual : The comment is targeted to a specific person. Group : The comment is targeted to a group of people. Other : The comment is targeted, but it is not targeted to a specific person or group of people. e.g. companies, events, etc. Which words make this text toxic/offensive? # The toxic spans are the parts of the text that are identified as offensive, profane, insulting, etc. Example: Vai tomar no c@, seu arr0mb@d0 In the above example, we have two toxic spans: vai tomar no c@ e arr0mb@d0 . Another example: \"Que exemplo idiota! Voc\u00ea \u00e9 burro demais.\" In this example, the words idiota and burro are toxic spans. We also consider set of words as toxic spans, for example: vai a merda . Warning Don't select words that are too generic, like \"que\", \"o\", \"a\", etc. Frequently asked questions # What's the difference between a toxic comment and a negative opinion? # It's important to understand the difference between a negative opinion and a toxic comment. A negative opinion is a text that exposes an unpleasant opinion or fact with uncomfortable words, usually criticizing someone's work or action, but without hurting the dignity or honor of a person or group. Examples: USER Agora \u00e9 \"estupro\" mesmo com a mulher dizendo que quis e gostou. Eu avisei que esse dia ia chegar. Moro conseguiu o que queria: eleger Bolsonaro em troca de um minist\u00e9rio. O que aconteceu depois foi \"briga de quadrilha\", na opini\u00e3o do advogado Kakay. Por tudo isso, ele considera o ex-juiz \"a pr\u00f3pria fake news\". Veja na \u00faltima HASHTAG do ano! HASHTAG URL USER Crime \u00e9 invadir a casa dos outros. USER perder faz parte do esporte. Agora insultar e trazer o racismo pra nossas vidas n\u00e3o, eu n\u00e3o estou de acordo. A toxic comment goes beyond freedom of expression, usually contains offensive or insulting words. It seeks to denigrate the dignity or honor of a person or group. Examples: O presidente da empresa USER \u00e9 um idiota e n\u00e3o entende o que \u00e9 importante para a empresa. Como se d\u00e1 m\u00eddia pra um safado desses...merece cadeia... A mulher estava vuneravel...em surto... Ficam dando cartaz pra esse canalha... que mundo \u00e9 esse????? Esse cara n\u00e3o sabe jogar pqp Should we consider misspellings words as toxic? # Users may misspell words or change some characters to avoid toxicity detection systems. In this case, you must interpret the words as if they were spelled correctly. Examples: arr0mb@d0 > arrombado vai tomar no c@ > vai tomar no cu About the toxic spans , you should mark the words in the same way, as if they were spelled correctly. The text is unreadable, what should I do? # If you cannot understand the text, you can click the Skip button and go to the next comment. Can I go back to the previous comment? # It's not possible to go back during the annotation task, but it's possible to filter comments in the table present in the project page. If you are in doubt, ask for help. Be careful when submitting a comment if you are not sure, click the \"Skip\" button when in doubt.","title":"Guidelines"},{"location":"annotation/guidelines.html#annotation-guidelines","text":"On this page, we will detail the guidelines followed by our annotators in the data labeling process in the OLID-BR. In the figure below, you can see the annotation schema for the OLID-BR dataset. Hierarchical taxonomy for categorizing offensive language, proposed by author.","title":"Annotation Guidelines"},{"location":"annotation/guidelines.html#what-task-are-you-doing","text":"You will see comments with offensive/toxic content and you will need to answer some questions about that, these questions will help us identify offensive comments and/or better understand the behavior of haters . In the image below, you can see an example of the labeling interface that our annotators will see. Labeling Interface - Label Studio","title":"What task are you doing?"},{"location":"annotation/guidelines.html#what-questions-should-you-answer","text":"For each comment, you must answer the following questions:","title":"What questions should you answer?"},{"location":"annotation/guidelines.html#is-this-text-toxic","text":"The first question identifies if a given text contains toxic language or not. It's comes pre-filled with \"Yes\", because the comment was filtered by a text classifier previously. You action is to evaluate if the text is really toxic, if not, you can choose the option \"No\". When selecting the \"No\" option, the next questions will be hidden.","title":"Is this text toxic?"},{"location":"annotation/guidelines.html#which-kind-of-toxicity-it-has","text":"In this question, we will try to identify the toxicity type within some pre-defined categories. You can see the categories, their definitions and examples of comments that have each one of them in the blocks below. Health Offensive comment based on health, physical disabilities, age discrimination, characteristics caused by illness, etc. Examples: USER velho broxa Me desculpem gente mulher nenhuma \u00e9 Feliz com esse corpo? Ela precisa de tratamento isso \u00e9 uma doen\u00e7a rt USER esse curso eh coisa de gente retardada mental vsf q porra USER IMBECIL PROMOVENDO A AGLOMERA\u00c7\u00c3O DO POVO USER E A PROPAGA\u00c7\u00c3O DA DOEN\u00c7A. QUANTA USER !!!!!!!!!!!!!!!!!!!!! parece legenda pra cego surdo e mudo Ideology Hate speech based on ideologies such as feminist, political left, etc. Examples: esse partido chamado P T e esse P Sol sao uma doenca pra nossa nacao um enfermo USER A Folha desde sempre apoiando a DITADURA e apoiando FASCISTAS que at\u00e9 se esquece de falar sobre seus ESC\u00c2NDALOS como EMPRESTAR CARROS para a DITADURA ir TORTURAR PESSOAS. A Folha GOLPISTA nunca faz uma \u201cautocr\u00edtica\u201d URL USER Aqui na minha fam\u00edlia fechado com o MITO PT LADR\u00c3O NUNCA VOLTAMOS NESSA RA\u00c7A IMUNDA FDP DE LADR\u00d5ES \u2705\ud83c\udde7\ud83c\uddf7\ud83c\udde7\ud83c\uddf7 URL USER USER USER O Bolsonaro \u00e9 corrupto mlk, para de ser retardado, seu c\u00e9rebro t\u00e1 atrofiando A juiza \u00e9 pilantra igual a Sergio USER quer impor a lei da morda\u00e7a amea\u00e7ando e obrigado o r\u00e9l o expresidente Lula a ficar calado Arma\u00e7\u00e3o geral do judiciario partidario de Curitiba de Sergio USER Bolsonaro: \u201cComo \u00e9 duro ser patr\u00e3o no Brasil\". 19 milh\u00f5es de brasileiros passam fome e a grande preocupa\u00e7\u00e3o do cretino \u00e9 com os patr\u00f5es. Insult Hate speech that contains insult, injury, swearing. Its purpose is to ignite an argument, irritate a party, hit a victim's weak point, etc. Examples: USER USER Fodase denovo tmc para de aoarecer pra min desgra\u00e7a USER Kkkkkkkk \u00e9 mesmo q ano de bosta vai toma no c uuuuuuuu USER Voc\u00ea \u00e9 um lixo! USER Depois que acaba os campeonatos VC vem falar em liberar p\u00fablico nos est\u00e1dios seu bosta calca apertada LGBTQphobia Hate speech based on gender identity or sexual orientation. The comment attacks sexual orientation or gender identity. It includes aphobia, biphobia, homophobia, lesbophobia, transphobia and other phobias related to sexuality. Warning Be careful to don't confuse it with sexism. Examples: Que vergonha esse pais s\u00f3 tem gay USER voce so gosta d sapatao caminhoeira de cabelo rapado USER baitola lixo USER USER lament\u00e1vel acredita que existe pessoas que ap\u00f3ia o LGBT USER O problema n\u00e3o \u00e9 sexualidade e sim compet\u00eancia. \u00c9 diferente ferrar s\u00f3 um rabo ou ferrar de milhares. USER E quando n\u00e3o consegue espa\u00e7o e relev\u00e2ncia no meio, mente que \u00e9 bi. USER Voc\u00ea \u00e9 uma vergonha para os gays pq tu \u00e9 um gay ladr\u00e3o de dinheiro da Pandemia. Other-Lifestyle Hate speech based on lifestyle habits such as vegetarian, vegan, smoker, etc. Examples: Povo da ra\u00e7\u00e3o com milho he he Povinho irritante e desinformado esses veganos chatos. Com certeza nao convencem nem suas familias. USER crackudo voz de fumante Coisa brega esse piercing no nariz. Muito feio para uma jornalista. USER USER seu c\u00e9rebro derreteu por causa da maconha????????? Como ser feminista: Ser feia e gorda Pagar peitinho em passeata Ser peluda Odiar homens E achar q isso far\u00e1 diferen\u00e7a Aula de como comer um maconheiro! Hahaha Ai aonde a tua maconha te levou KKKkKkkK Physical Aspects Hate speech based on physical characteristics such as fatphobia, size, etc. Examples: Pr\u00f3ximo major j\u00e1 sabem, galera: ca\u00e7ar o gordo e extermina-lo. Deveriam ter escolhido uma modelo menos gordinha, ela parece que n\u00e3o est\u00e1 passando fome !! USER pode achar seu principe encantado,mas sempre vai acabar: Gorda,feia,virgem,cheia de poster de crep\u00fasculo a parede!! Me desculpem gente mulher nenhuma \u00e9 Feliz com esse corpo? Ela precisa de tratamento isso \u00e9 uma doen\u00e7a USER nao \u00e9 gorda nao,USER esta obesa.vai se tratar \u00e9 o melhor que USER faz. RT USER: e olha pra cara gorda e feia de Isabelle .. sem contar da voz irritante dela URL A obesidade est\u00e1 acabando com essa mulher. Rid\u00edcula EU N\u00c3O AGUENTO MAIS ESSE ALEIJADO SEM UMA PERNA DO CARALHO VAI TOMAR NO CU, O MALUCO NN SABE ANDAR COM A PERNA DIREITA FUDIDO HORR\u00cdVEL URL Profanity/Obscene Hate speech has obscene, vulgar, pornographic, etc. Examples: USER Comer cu de curioso USER Mas que grande fdp. USER Passar porte de vacina \u00e9 o meu pau USER Cada filho da puta que apertou 17 tem as mas sujas de sangue USER Com a PF na tua casa tu ficou bravinho n\u00e9 vagabundo? USER Toma no cu \u00e9 vitamina como tu e tua prima. fudeu minha m\u00e3e acabou de chegar em casa e eu acabei de acordar tomei no cu Racism The comment is biased or discriminatory based on the race, color or ethnicity of a person or group of people. Examples: Essas filhas de pedreiro africano e foda N\u00e3o tenho tv colorida pra ficar olhando essa preta nao USER E quantos desses negros s\u00e3o inocentes e quantos s\u00e3o criminosos e bandidos? Te dou absoluta certeza que a maioria dos negros mortos n\u00e3o s\u00e3o inocentes, infelizmente muitas vezes inocentes acabam sendo mortos pela corrup\u00e7\u00e3o na pol\u00edcia USER Sai macaco Essa nega do c\u00e3o quer ser a dona da raz\u00e3o e da situa\u00e7\u00e3o smp \ud83d\ude02\ud83d\ude02\ud83d\ude02 Religious Intolerance The comment is biased or discriminatory based on religion, cult or religious practice. Examples: USER Um governo de Evangelicos. Um governo de Corruptos. Um governo de Criminosos. Uma macumbeira a menos Que diabo de Ogum, por isso que n\u00e3o vai pra frente Sexism The comment is biased or discriminatory based on the gender or sex of a person or group of people. Examples: Se eu fosse o Temer criava o Minist\u00e9rio da Cozinha e da Limpeza e colocava uma mulher, s\u00f3 pro pessoal chorar menos. hahahaha USER Uma calcinha dessa fio-dental dentro da bunda n\u00e3o tem que resistir uma tenta\u00e7\u00e3o dessa? Homem \u00e9 um bicho estranho ao mesmo tmp rid\u00edculo \ud83e\udd23 Resumindo\" Meteu gostoso na safada\" fim da historia! N\u00e3o tem dinheiro q essa mulher,ela \u00e9 terr\u00edvel n\u00e3o vai ter homem q a suporte D\u00e1 uma rola pras feminazi.quem sabe elas param de falar bosta. Xenophobia Hate speech against foreigners or people from other cultures. Examples: Quem liga pra judeu kkkk odeio goiano e mineiro rt USER USER nao sei . pra mim todo japones que \u00e9 comunista \u00e9 burro... uma coisa q meu pai ensinou kk esse chinezinho falsificado e um pilantra. N\u00e3o se deixa enganar como ele enganou os que votaram nele. Esse tipo de jumento s\u00f3 se elege uma vez. USER O brasileiro merece o que t\u00e1 passando povo ignorante e sem a menor consci\u00eancia bando de fudido do caralho USER USER PUTAQUEPARIUUUUUU........ESSAS PORCARIAS S\u00d3 ACONTECE NO BRASIL.... RA\u00c7A MALDITA ESSES BRASILEIROS....EXTIN\u00c7AO Nordestino \u00e9 uma desgra\u00e7a cambada de dem\u00f4nio","title":"Which kind of toxicity it has?"},{"location":"annotation/guidelines.html#theres-a-specific-target","text":"In this question, we want to know if the toxic comment is targeted or not, and if it is, the type of target. Important Check only if there is a clear target for the toxic comment. Options: Individual : The comment is targeted to a specific person. Group : The comment is targeted to a group of people. Other : The comment is targeted, but it is not targeted to a specific person or group of people. e.g. companies, events, etc.","title":"There's a specific target?"},{"location":"annotation/guidelines.html#which-words-make-this-text-toxicoffensive","text":"The toxic spans are the parts of the text that are identified as offensive, profane, insulting, etc. Example: Vai tomar no c@, seu arr0mb@d0 In the above example, we have two toxic spans: vai tomar no c@ e arr0mb@d0 . Another example: \"Que exemplo idiota! Voc\u00ea \u00e9 burro demais.\" In this example, the words idiota and burro are toxic spans. We also consider set of words as toxic spans, for example: vai a merda . Warning Don't select words that are too generic, like \"que\", \"o\", \"a\", etc.","title":"Which words make this text toxic/offensive?"},{"location":"annotation/guidelines.html#frequently-asked-questions","text":"","title":"Frequently asked questions"},{"location":"annotation/guidelines.html#whats-the-difference-between-a-toxic-comment-and-a-negative-opinion","text":"It's important to understand the difference between a negative opinion and a toxic comment. A negative opinion is a text that exposes an unpleasant opinion or fact with uncomfortable words, usually criticizing someone's work or action, but without hurting the dignity or honor of a person or group. Examples: USER Agora \u00e9 \"estupro\" mesmo com a mulher dizendo que quis e gostou. Eu avisei que esse dia ia chegar. Moro conseguiu o que queria: eleger Bolsonaro em troca de um minist\u00e9rio. O que aconteceu depois foi \"briga de quadrilha\", na opini\u00e3o do advogado Kakay. Por tudo isso, ele considera o ex-juiz \"a pr\u00f3pria fake news\". Veja na \u00faltima HASHTAG do ano! HASHTAG URL USER Crime \u00e9 invadir a casa dos outros. USER perder faz parte do esporte. Agora insultar e trazer o racismo pra nossas vidas n\u00e3o, eu n\u00e3o estou de acordo. A toxic comment goes beyond freedom of expression, usually contains offensive or insulting words. It seeks to denigrate the dignity or honor of a person or group. Examples: O presidente da empresa USER \u00e9 um idiota e n\u00e3o entende o que \u00e9 importante para a empresa. Como se d\u00e1 m\u00eddia pra um safado desses...merece cadeia... A mulher estava vuneravel...em surto... Ficam dando cartaz pra esse canalha... que mundo \u00e9 esse????? Esse cara n\u00e3o sabe jogar pqp","title":"What's the difference between a toxic comment and a negative opinion?"},{"location":"annotation/guidelines.html#should-we-consider-misspellings-words-as-toxic","text":"Users may misspell words or change some characters to avoid toxicity detection systems. In this case, you must interpret the words as if they were spelled correctly. Examples: arr0mb@d0 > arrombado vai tomar no c@ > vai tomar no cu About the toxic spans , you should mark the words in the same way, as if they were spelled correctly.","title":"Should we consider misspellings words as toxic?"},{"location":"annotation/guidelines.html#the-text-is-unreadable-what-should-i-do","text":"If you cannot understand the text, you can click the Skip button and go to the next comment.","title":"The text is unreadable, what should I do?"},{"location":"annotation/guidelines.html#can-i-go-back-to-the-previous-comment","text":"It's not possible to go back during the annotation task, but it's possible to filter comments in the table present in the project page. If you are in doubt, ask for help. Be careful when submitting a comment if you are not sure, click the \"Skip\" button when in doubt.","title":"Can I go back to the previous comment?"},{"location":"annotation/index.html","text":"Annotation Overview # In this section, we will describe in detail the annotation process developed for the OLID-BR dataset. What is data labeling? # Data labeling, or data annotation, is the process of identifying raw data (images, text files, videos, etc.) when developing a machine learning (ML) model. It requires the identification of raw data with one or more meaningful and informative labels that provides context so that a machine learning model can learn from it. For example, labels might indicate whether a photo contains a bird or car, which words were uttered in an audio recording, or if an x-ray contains a tumor. Data labeling is required for a variety of use cases including computer vision, natural language processing, and speech recognition. 1 2 Data labeling approaches # The literature presents several approaches to data labeling. In the OLID-BR project, we used the following approach: Internal labeling : Using in-house data science experts simplifies tracking, provides greater accuracy, and increases quality. However, this approach typically requires more time and favors large companies with extensive resources. Outsourcing : This can be an optimal choice for high-level temporary projects, but developing and managing a freelance-oriented workflow can also be time-consuming. Though freelancing platforms provide comprehensive candidate information to ease the vetting process, hiring managed data labeling teams provides pre-vetted staff and pre-built data labeling tools. In the first iteration of the annotation process, we will use the internal labeling approach, in other words, the author of the dataset labeled the data. We also had a volunteer who helped us label the data. In the next iterations, we will use the outsourcing approach, three contract workers will label the data. What is data labeling? - AWS \u21a9 What is data labeling? - IBM \u21a9","title":"Overview"},{"location":"annotation/index.html#annotation-overview","text":"In this section, we will describe in detail the annotation process developed for the OLID-BR dataset.","title":"Annotation Overview"},{"location":"annotation/index.html#what-is-data-labeling","text":"Data labeling, or data annotation, is the process of identifying raw data (images, text files, videos, etc.) when developing a machine learning (ML) model. It requires the identification of raw data with one or more meaningful and informative labels that provides context so that a machine learning model can learn from it. For example, labels might indicate whether a photo contains a bird or car, which words were uttered in an audio recording, or if an x-ray contains a tumor. Data labeling is required for a variety of use cases including computer vision, natural language processing, and speech recognition. 1 2","title":"What is data labeling?"},{"location":"annotation/index.html#data-labeling-approaches","text":"The literature presents several approaches to data labeling. In the OLID-BR project, we used the following approach: Internal labeling : Using in-house data science experts simplifies tracking, provides greater accuracy, and increases quality. However, this approach typically requires more time and favors large companies with extensive resources. Outsourcing : This can be an optimal choice for high-level temporary projects, but developing and managing a freelance-oriented workflow can also be time-consuming. Though freelancing platforms provide comprehensive candidate information to ease the vetting process, hiring managed data labeling teams provides pre-vetted staff and pre-built data labeling tools. In the first iteration of the annotation process, we will use the internal labeling approach, in other words, the author of the dataset labeled the data. We also had a volunteer who helped us label the data. In the next iterations, we will use the outsourcing approach, three contract workers will label the data. What is data labeling? - AWS \u21a9 What is data labeling? - IBM \u21a9","title":"Data labeling approaches"},{"location":"annotation/inter-rater-reliability.html","text":"Inter-Rater Reliability # The Inter-Rater Reliability is an important part of the process of evaluating the quality of the annotations. In this section, we will present the metrics and the methodology used in this process. Each comment was tagged by three different raters. So, we need to consider metrics that supports more than two raters. How we selected the coefficients? # In the Handbook of Inter-Rater Reliability 1 , Gwet, K.L. proposed a diagram that helps to choose the correct agreement coefficient for each study. graph TD A[Which Agreement Coefficient Should you use?] --> B{Nominal Ratings?} B -->|No| D{Ratio Ratings?} B -->|Yes| C[Use Unweighted Coefficients] D -->|Yes| E{Predetermined<br>Rating Values?} D -->|No| F{Interval Ratings?} F -->|\"No (these are ordinal ratings)\"| H[Use Weighted Coefficients.<br>Ordinal Weights Only.] F -->|Yes| G{Predetermined<br>Rating Values?} E -->|Yes| I[Use Weighted Coefficients.<br>All Weights Can be Used.] E -->|No| J[Use Intraclass Correlation Coefficients] G -->|Yes| K[Use Weighted Coefficients.<br>Quadratic, Linear, and Radical Weights can be used] G -->|No| J[Use Intraclass Correlation Coefficients] All our ratings are nominal , then we will see Unweighted Coefficients proposed by Gwet, K.L. in the book. Percent Agreement ( \\(p_a\\) ): Not corrected for chance-agreement. Fleiss' Generalized Kappa ( \\(\\hat{K}_F\\) ): Good sometimes - Exposed to severe paradoxes. Conger's Generalized Kappa ( \\(\\hat{K}_C\\) ): Good sometimes - Exposed to severe paradoxes. Gwet's AC 1 ( \\(\\hat{K}_G\\) ): More paradox-resistant than alternative coefficients. Brennan-Prediger ( \\(\\hat{K}_{BP}\\) ): More paradox-resistant than alternative coefficients. Krippendorff's Alpha ( \\(\\hat{\\alpha}_K\\) ) Similar to Fleiss' Generalized Kappa - Minor differences. Di Eugenio & Glass (2004) 7 argue that using multiple reliability metrics with different methods for computing \\(p_{(A_e)}\\) can be more revealing of than a single metric. So, we will select a range of metrics to use in our analysis. The Simplicity of the Percent Agreement # Because percent agreement is figured as an average across observations it can hide important disagreements. \"Averages over all categories of a variable\u2026 hide unreliable categories behind reliable ones\u201d - Krippendorff 5 \"when all coders use only one category, there is no variation and hence no evidence of reliability\" - Krippendorff 6 To remedy this he suggests that in some cases it is appropriate to conduct multiple tests within a single variable. \"All distinctions that matter should be tested for their reliability\" - Krippendorff 6 The Kappa paradoxes # Kappa often yields coefficients that are unexpectedly low when compared to the percent agreement. This problem has been referred to in the literatura as the Kappa paradoxes. Feinstein and Cicchetti (1990) 4 provides a detailed explanation about two such paradoxes. These authors made the following two statements: \"The first paradox of \\(k\\) (Kappa) is that if \\(p_e\\) (the percent chance agreement) is large, the correction process can convert a relatively high value of \\(p_0\\) to a relatively low value of \\(k\\) \" (Feinstein & Cicchetti, (1990, p. 544) 4 \"The second paradox occurs when unbalanced marginal totals produce higher values of \\(k\\) than more balanced totals.\" (Feinstein & Cicchetti, (1990, p. 545) 4 So, we will use the Percent Agreement , Gwet's AC 1 , and Krippendorff's Alpha as the coefficients to evaluate the quality of the annotations. Selected coefficients # Percent agreement # The Percent Agreement is a measure of the agreement between the raters. It's calculated by dividing the number of agreeing comments by the total number of comments as follows: \\[ p_a = \\frac{n_{\\text{agreeing}}}{n_{\\text{total}}} \\] Interpretation Slight Fair Moderate Substantial Almost perfect 0.01 - 0.20 0.21 - 0.40 0.41 - 0.60 0.61 - 0.80 0.81 - 0.99 Gwet\u2019s AC 1 # Gwet 2 recommended an agreement coefficient named AC 1 , which was developed to overcome many of the limitations associated with Kappa-based agreement coefficients. Gwet's AC 1 is based on the same percent agreement equation than Kappa, and on a new percent chance agreement as \\(p_e\\) . The Gwet's AC 1 coefficient, denoted here by \\(\\hat{K}_G\\) is formally defined as follows: \\[ \\widehat{\\kappa}_{\\mathrm{G}}=\\frac{p_{a}-p_{e}}{1-p_{e}}, \\text { where } p_{e}=\\frac{1}{q(q-1)} \\sum_{k=1}^{q} \\hat{\\pi}_{k}\\left(1-\\hat{\\pi}_{k}\\right) \\] where \\(\\hat{\\pi}_{k}\\) is given by the following equation: \\[ \\hat{\\pi}_{k}=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{r_{i k}}{r_{i}} \\] Interpretation Poor Fair Moderate Substantial Almost perfect < 0.20 0.21 - 0.40 0.41 - 0.60 0.61 - 0.80 0.81 - 0.99 Krippendorff's Alpha # Krippendorff's Alpha 3 is a versatile statistic that assesses the agreement achieved among observers who categorize, evaluate, or measure a given set of objects in terms of the values of a variable. It generalizes several specialized agreement coefficients by accepting any number of observers, being applicable to nominal, ordinal, interval, and ratio levels of measurement, being able to handle missing data, and being corrected for small sample sizes. Krippendorff's coefficient is calculated as follows: \\[ \\widehat{\\alpha}_{\\mathrm{K}}=\\frac{p_{a}^{\\prime}-p_{e}}{1-p_{e}}, \\text { where } p_{e}=\\sum_{k=1}^{q} \\hat{\\pi}_{k}^{2} \\] where \\(p_{a}\\) is given by: \\[ p_{a}=\\frac{1}{n^{\\prime}} \\sum_{i=1}^{n^{\\prime}} \\sum_{k=1}^{q} \\frac{r_{i k}\\left(r_{i k}-1\\right)}{r_{i}\\left(r_{i}-1\\right)} \\] and \\(p_{a}^{\\prime}\\) is given by: \\[ p_{a}^{\\prime}=\\left(1-\\varepsilon_{n}\\right) p_{a}+\\varepsilon_{n} \\] Interpretation Poor Slight Fair Moderate Substantial Almost perfect < 0 0.01 - 0.20 0.21 - 0.40 0.41 - 0.60 0.61 - 0.80 0.81 - 0.99 Gwet, Kilem L. Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among raters. Advanced Analytics, LLC, 2014. \u21a9 Gwet, Kilem Li. \"Computing inter\u2010rater reliability and its variance in the presence of high agreement.\" British Journal of Mathematical and Statistical Psychology 61.1 (2008): 29-48. \u21a9 Hayes, Andrew F., and Klaus Krippendorff. \"Answering the call for a standard reliability measure for coding data.\" Communication methods and measures 1.1 (2007): 77-89. \u21a9 Feinstein, Alvan R., and Domenic V. Cicchetti. \"High agreement but low kappa: I. The problems of two paradoxes.\" Journal of clinical epidemiology 43.6 (1990): 543-549. \u21a9 \u21a9 \u21a9 Krippendorff, Klaus. Content analysis: An introduction to its methodology. Sage publications, 2018. \u21a9 Krippendorff, K. \"Some Common Misconceptions and Recommendations.\" Human Communication Research 30 (2004): 411-433. \u21a9 \u21a9 Eugenio, Barbara Di, and Michael Glass. \"The kappa statistic: A second look.\" Computational linguistics 30.1 (2004): 95-101. \u21a9","title":"Inter-Rater Reliability"},{"location":"annotation/inter-rater-reliability.html#inter-rater-reliability","text":"The Inter-Rater Reliability is an important part of the process of evaluating the quality of the annotations. In this section, we will present the metrics and the methodology used in this process. Each comment was tagged by three different raters. So, we need to consider metrics that supports more than two raters.","title":"Inter-Rater Reliability"},{"location":"annotation/inter-rater-reliability.html#how-we-selected-the-coefficients","text":"In the Handbook of Inter-Rater Reliability 1 , Gwet, K.L. proposed a diagram that helps to choose the correct agreement coefficient for each study. graph TD A[Which Agreement Coefficient Should you use?] --> B{Nominal Ratings?} B -->|No| D{Ratio Ratings?} B -->|Yes| C[Use Unweighted Coefficients] D -->|Yes| E{Predetermined<br>Rating Values?} D -->|No| F{Interval Ratings?} F -->|\"No (these are ordinal ratings)\"| H[Use Weighted Coefficients.<br>Ordinal Weights Only.] F -->|Yes| G{Predetermined<br>Rating Values?} E -->|Yes| I[Use Weighted Coefficients.<br>All Weights Can be Used.] E -->|No| J[Use Intraclass Correlation Coefficients] G -->|Yes| K[Use Weighted Coefficients.<br>Quadratic, Linear, and Radical Weights can be used] G -->|No| J[Use Intraclass Correlation Coefficients] All our ratings are nominal , then we will see Unweighted Coefficients proposed by Gwet, K.L. in the book. Percent Agreement ( \\(p_a\\) ): Not corrected for chance-agreement. Fleiss' Generalized Kappa ( \\(\\hat{K}_F\\) ): Good sometimes - Exposed to severe paradoxes. Conger's Generalized Kappa ( \\(\\hat{K}_C\\) ): Good sometimes - Exposed to severe paradoxes. Gwet's AC 1 ( \\(\\hat{K}_G\\) ): More paradox-resistant than alternative coefficients. Brennan-Prediger ( \\(\\hat{K}_{BP}\\) ): More paradox-resistant than alternative coefficients. Krippendorff's Alpha ( \\(\\hat{\\alpha}_K\\) ) Similar to Fleiss' Generalized Kappa - Minor differences. Di Eugenio & Glass (2004) 7 argue that using multiple reliability metrics with different methods for computing \\(p_{(A_e)}\\) can be more revealing of than a single metric. So, we will select a range of metrics to use in our analysis.","title":"How we selected the coefficients?"},{"location":"annotation/inter-rater-reliability.html#the-simplicity-of-the-percent-agreement","text":"Because percent agreement is figured as an average across observations it can hide important disagreements. \"Averages over all categories of a variable\u2026 hide unreliable categories behind reliable ones\u201d - Krippendorff 5 \"when all coders use only one category, there is no variation and hence no evidence of reliability\" - Krippendorff 6 To remedy this he suggests that in some cases it is appropriate to conduct multiple tests within a single variable. \"All distinctions that matter should be tested for their reliability\" - Krippendorff 6","title":"The Simplicity of the Percent Agreement"},{"location":"annotation/inter-rater-reliability.html#the-kappa-paradoxes","text":"Kappa often yields coefficients that are unexpectedly low when compared to the percent agreement. This problem has been referred to in the literatura as the Kappa paradoxes. Feinstein and Cicchetti (1990) 4 provides a detailed explanation about two such paradoxes. These authors made the following two statements: \"The first paradox of \\(k\\) (Kappa) is that if \\(p_e\\) (the percent chance agreement) is large, the correction process can convert a relatively high value of \\(p_0\\) to a relatively low value of \\(k\\) \" (Feinstein & Cicchetti, (1990, p. 544) 4 \"The second paradox occurs when unbalanced marginal totals produce higher values of \\(k\\) than more balanced totals.\" (Feinstein & Cicchetti, (1990, p. 545) 4 So, we will use the Percent Agreement , Gwet's AC 1 , and Krippendorff's Alpha as the coefficients to evaluate the quality of the annotations.","title":"The Kappa paradoxes"},{"location":"annotation/inter-rater-reliability.html#selected-coefficients","text":"","title":"Selected coefficients"},{"location":"annotation/inter-rater-reliability.html#percent-agreement","text":"The Percent Agreement is a measure of the agreement between the raters. It's calculated by dividing the number of agreeing comments by the total number of comments as follows: \\[ p_a = \\frac{n_{\\text{agreeing}}}{n_{\\text{total}}} \\] Interpretation Slight Fair Moderate Substantial Almost perfect 0.01 - 0.20 0.21 - 0.40 0.41 - 0.60 0.61 - 0.80 0.81 - 0.99","title":"Percent agreement"},{"location":"annotation/inter-rater-reliability.html#gwets-ac1","text":"Gwet 2 recommended an agreement coefficient named AC 1 , which was developed to overcome many of the limitations associated with Kappa-based agreement coefficients. Gwet's AC 1 is based on the same percent agreement equation than Kappa, and on a new percent chance agreement as \\(p_e\\) . The Gwet's AC 1 coefficient, denoted here by \\(\\hat{K}_G\\) is formally defined as follows: \\[ \\widehat{\\kappa}_{\\mathrm{G}}=\\frac{p_{a}-p_{e}}{1-p_{e}}, \\text { where } p_{e}=\\frac{1}{q(q-1)} \\sum_{k=1}^{q} \\hat{\\pi}_{k}\\left(1-\\hat{\\pi}_{k}\\right) \\] where \\(\\hat{\\pi}_{k}\\) is given by the following equation: \\[ \\hat{\\pi}_{k}=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{r_{i k}}{r_{i}} \\] Interpretation Poor Fair Moderate Substantial Almost perfect < 0.20 0.21 - 0.40 0.41 - 0.60 0.61 - 0.80 0.81 - 0.99","title":"Gwet\u2019s AC1"},{"location":"annotation/inter-rater-reliability.html#krippendorffs-alpha","text":"Krippendorff's Alpha 3 is a versatile statistic that assesses the agreement achieved among observers who categorize, evaluate, or measure a given set of objects in terms of the values of a variable. It generalizes several specialized agreement coefficients by accepting any number of observers, being applicable to nominal, ordinal, interval, and ratio levels of measurement, being able to handle missing data, and being corrected for small sample sizes. Krippendorff's coefficient is calculated as follows: \\[ \\widehat{\\alpha}_{\\mathrm{K}}=\\frac{p_{a}^{\\prime}-p_{e}}{1-p_{e}}, \\text { where } p_{e}=\\sum_{k=1}^{q} \\hat{\\pi}_{k}^{2} \\] where \\(p_{a}\\) is given by: \\[ p_{a}=\\frac{1}{n^{\\prime}} \\sum_{i=1}^{n^{\\prime}} \\sum_{k=1}^{q} \\frac{r_{i k}\\left(r_{i k}-1\\right)}{r_{i}\\left(r_{i}-1\\right)} \\] and \\(p_{a}^{\\prime}\\) is given by: \\[ p_{a}^{\\prime}=\\left(1-\\varepsilon_{n}\\right) p_{a}+\\varepsilon_{n} \\] Interpretation Poor Slight Fair Moderate Substantial Almost perfect < 0 0.01 - 0.20 0.21 - 0.40 0.41 - 0.60 0.61 - 0.80 0.81 - 0.99 Gwet, Kilem L. Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among raters. Advanced Analytics, LLC, 2014. \u21a9 Gwet, Kilem Li. \"Computing inter\u2010rater reliability and its variance in the presence of high agreement.\" British Journal of Mathematical and Statistical Psychology 61.1 (2008): 29-48. \u21a9 Hayes, Andrew F., and Klaus Krippendorff. \"Answering the call for a standard reliability measure for coding data.\" Communication methods and measures 1.1 (2007): 77-89. \u21a9 Feinstein, Alvan R., and Domenic V. Cicchetti. \"High agreement but low kappa: I. The problems of two paradoxes.\" Journal of clinical epidemiology 43.6 (1990): 543-549. \u21a9 \u21a9 \u21a9 Krippendorff, Klaus. Content analysis: An introduction to its methodology. Sage publications, 2018. \u21a9 Krippendorff, K. \"Some Common Misconceptions and Recommendations.\" Human Communication Research 30 (2004): 411-433. \u21a9 \u21a9 Eugenio, Barbara Di, and Michael Glass. \"The kappa statistic: A second look.\" Computational linguistics 30.1 (2004): 95-101. \u21a9","title":"Krippendorff's Alpha"},{"location":"annotation/iterations.html","text":"Iterations # We decided to work in iterations because it allows us to validate and improve the annotation process and guidelines. Each iteration has its own goals and objectives. Iteration 1 # In this iteration, our goal was to validate and refine our annotation process. It was the first time that we applied the annotation process. Two annotators labeled the data. The first annotator was a volunteer, the second was the author of the dataset. The volunteer provided useful feedback to adjust the annotation process. The data labeled by the researcher was predominated under the volunteer's labels as the researcher fixed some mistakes in the annotation process. Inter-Rater Reliability # In this iteration, we didn't generate the inter-rater reliability analysis because we did some changes and alignments during the iteration. Profiling Report Iteration 2 # In the second iteration, we introduced contract workers to do the annotations. The annotators were trained by the author of the dataset as described in Qualified annotators . Inter-Rater Reliability # As described in the Inter-Rater Reliability section, we evaluate the reliability of the annotators using several coefficients. We also address the analysis by considering it as a multi-label problem or several binary problems. Multi-Label Problem For all our toxicity labels we calculate the Krippendorff's alpha (using the MASI distance) and the Percent Agreement. Krippendorff's alpha : 0.1962 (slight agreement) Percent Agreement : 0.1877 Binary Problem Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0.7277 0.0595 0.7750 is_targeted 0.1610 -0.1348 -0.1029 [1] targeted_type 0.0641 0.2461 0.4978 [1] toxic_spans 0.1220 0.2709 N/A health 0.9760 0.0447 0.9837 ideology 0.7647 0.3019 0.7976 [3] insult 0.4713 0.0895 0.425 [3] lgbtqphobia 0.9453 0.5583 0.9603 other_lifestyle 0.9860 0.0824 0.9906 physical_aspects 0.9463 0.3272 0.9622 profanity_obscene 0.6837 0.0850 0.726 [3] racism 0.9750 0.2564 0.9829 religious_intolerance 1.0 1.0 1.0 [2] sexism 0.8753 0.1721 0.9076 xenophobia 0.9673 0.0732 0.9777 Comments # [1] The question that originated features is_targeted and targeted_type are optional, it must be marked only if the text is targeted. Looks like annotator 126 didn't understand it and marked everything as targeted. [2] We don't have any text tagged with religious_intolerance by our annotators. [3] We have more inconsistent annotations in labels idelogy , insult , and profanity_obscene (disregarding [1] [2]) Conclusions # We had a misunderstanding of the annotation guidelines by one of the annotators, which resulted in an inconsistency in the is_targeted and targeted_type labels. Regarding toxicity labels, we noticed that there are rare cases in which all annotators agree with the annotation, leading to a high rate of disagreement and consequently to a low value of Krippendorff's alpha. The labels with the highest disagreement are insult , ideology , and profanity_obscene . We will pass along the annotation guidelines with the annotators for the next iteration. Profiling Report Iteration 3 # In the third iteration, we retrained the annotators using the output of the previous iteration. One of the annotators was replaced, and another one was trained by the author of the dataset. Inter-Rater Reliability # As described in the Inter-Rater Reliability section, we evaluate the reliability of the annotators using several coefficients. We also address the analysis by considering it as a multi-label problem or several binary problems. Multi-Label Problem For all our toxicity labels we calculate the Krippendorff's alpha (using the MASI distance) and the Percent Agreement. Krippendorff's alpha : 0.4653 (moderate agreement) Percent Agreement : 0.2758 Binary Problem Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0.6509 0.1777 0.6754 is_targeted 0.3551 0.1072 0.1709 targeted_type 0.1975 0.4887 0.6300 toxic_spans 0.1757 0.4427 N/A health 0.9700 0.2641 0.9794 ideology 0.8670 0.4728 0.8934 insult 0.5488 0.3317 0.4531 lgbtqphobia 0.9613 0.6393 0.9722 other_lifestyle 0.9787 0.4683 0.9854 physical_aspects 0.9560 0.4160 0.9691 profanity_obscene 0.7089 0.4894 0.6870 racism 0.9913 0.3781 0.9942 religious_intolerance 1.0 1.0 1.0 1 sexism 0.9550 0.1566 0.9689 xenophobia 0.9847 0.2980 0.9896 Comments # [1] We don't have any text tagged with religious_intolerance by our annotators. Conclusions # In this iteration, we had more consistent annotations which led to a better agreement between the annotators. Krippendorff's alpha for toxicity labels increased from 0.1962 to 0.4653 . Profiling Report Iteration 4 # In the fourth iteration, we asked the annotators to label a higher number of texts following the same guidelines of the previous iterations. We fixed the deadline to Oct 4th, 2022 (+- one month). Inter-Rater Reliability # As described in the Inter-Rater Reliability section, we evaluate the reliability of the annotators using several coefficients. We also address the analysis by considering it as a multi-label problem or several binary problems. Multi-Label Problem For all our toxicity labels we calculate the Krippendorff's alpha (using the MASI distance) and the Percent Agreement. Krippendorff's alpha : 0.4424 (moderate agreement) Percent Agreement : 0.2769 Binary Problem Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0.5847 0.2174 0.5716 is_targeted 0.4253 0.1825 0.2790 targeted_type 0.2223 0.4840 0.5756 toxic_spans 0.2249 0.4760 (MASI distance) N/A health 0.9800 0.1424 0.9865 ideology 0.8531 0.2909 0.8863 insult 0.4938 0.2923 0.3549 lgbtqphobia 0.9550 0.4901 0.9681 other_lifestyle 0.9705 0.2239 0.9798 physical_aspects 0.9570 0.3623 0.9700 profanity_obscene 0.7436 0.5530 0.7233 racism 0.9940 0.2481 0.9960 religious_intolerance 1.0 1.0 1.0 1 sexism 0.9640 0.1880 0.9753 xenophobia 0.9905 0.3840 0.9936 Comments # [1] We don't have any text tagged with religious_intolerance by our annotators in this iteration. Conclusions # As in the previous iteration, we had more consistent annotations which led to a better agreement between the annotators. Profiling Report","title":"Iterations"},{"location":"annotation/iterations.html#iterations","text":"We decided to work in iterations because it allows us to validate and improve the annotation process and guidelines. Each iteration has its own goals and objectives.","title":"Iterations"},{"location":"annotation/iterations.html#iteration-1","text":"In this iteration, our goal was to validate and refine our annotation process. It was the first time that we applied the annotation process. Two annotators labeled the data. The first annotator was a volunteer, the second was the author of the dataset. The volunteer provided useful feedback to adjust the annotation process. The data labeled by the researcher was predominated under the volunteer's labels as the researcher fixed some mistakes in the annotation process.","title":"Iteration 1"},{"location":"annotation/iterations.html#inter-rater-reliability","text":"In this iteration, we didn't generate the inter-rater reliability analysis because we did some changes and alignments during the iteration. Profiling Report","title":"Inter-Rater Reliability"},{"location":"annotation/iterations.html#iteration-2","text":"In the second iteration, we introduced contract workers to do the annotations. The annotators were trained by the author of the dataset as described in Qualified annotators .","title":"Iteration 2"},{"location":"annotation/iterations.html#inter-rater-reliability_1","text":"As described in the Inter-Rater Reliability section, we evaluate the reliability of the annotators using several coefficients. We also address the analysis by considering it as a multi-label problem or several binary problems. Multi-Label Problem For all our toxicity labels we calculate the Krippendorff's alpha (using the MASI distance) and the Percent Agreement. Krippendorff's alpha : 0.1962 (slight agreement) Percent Agreement : 0.1877 Binary Problem Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0.7277 0.0595 0.7750 is_targeted 0.1610 -0.1348 -0.1029 [1] targeted_type 0.0641 0.2461 0.4978 [1] toxic_spans 0.1220 0.2709 N/A health 0.9760 0.0447 0.9837 ideology 0.7647 0.3019 0.7976 [3] insult 0.4713 0.0895 0.425 [3] lgbtqphobia 0.9453 0.5583 0.9603 other_lifestyle 0.9860 0.0824 0.9906 physical_aspects 0.9463 0.3272 0.9622 profanity_obscene 0.6837 0.0850 0.726 [3] racism 0.9750 0.2564 0.9829 religious_intolerance 1.0 1.0 1.0 [2] sexism 0.8753 0.1721 0.9076 xenophobia 0.9673 0.0732 0.9777","title":"Inter-Rater Reliability"},{"location":"annotation/iterations.html#comments","text":"[1] The question that originated features is_targeted and targeted_type are optional, it must be marked only if the text is targeted. Looks like annotator 126 didn't understand it and marked everything as targeted. [2] We don't have any text tagged with religious_intolerance by our annotators. [3] We have more inconsistent annotations in labels idelogy , insult , and profanity_obscene (disregarding [1] [2])","title":"Comments"},{"location":"annotation/iterations.html#conclusions","text":"We had a misunderstanding of the annotation guidelines by one of the annotators, which resulted in an inconsistency in the is_targeted and targeted_type labels. Regarding toxicity labels, we noticed that there are rare cases in which all annotators agree with the annotation, leading to a high rate of disagreement and consequently to a low value of Krippendorff's alpha. The labels with the highest disagreement are insult , ideology , and profanity_obscene . We will pass along the annotation guidelines with the annotators for the next iteration. Profiling Report","title":"Conclusions"},{"location":"annotation/iterations.html#iteration-3","text":"In the third iteration, we retrained the annotators using the output of the previous iteration. One of the annotators was replaced, and another one was trained by the author of the dataset.","title":"Iteration 3"},{"location":"annotation/iterations.html#inter-rater-reliability_2","text":"As described in the Inter-Rater Reliability section, we evaluate the reliability of the annotators using several coefficients. We also address the analysis by considering it as a multi-label problem or several binary problems. Multi-Label Problem For all our toxicity labels we calculate the Krippendorff's alpha (using the MASI distance) and the Percent Agreement. Krippendorff's alpha : 0.4653 (moderate agreement) Percent Agreement : 0.2758 Binary Problem Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0.6509 0.1777 0.6754 is_targeted 0.3551 0.1072 0.1709 targeted_type 0.1975 0.4887 0.6300 toxic_spans 0.1757 0.4427 N/A health 0.9700 0.2641 0.9794 ideology 0.8670 0.4728 0.8934 insult 0.5488 0.3317 0.4531 lgbtqphobia 0.9613 0.6393 0.9722 other_lifestyle 0.9787 0.4683 0.9854 physical_aspects 0.9560 0.4160 0.9691 profanity_obscene 0.7089 0.4894 0.6870 racism 0.9913 0.3781 0.9942 religious_intolerance 1.0 1.0 1.0 1 sexism 0.9550 0.1566 0.9689 xenophobia 0.9847 0.2980 0.9896","title":"Inter-Rater Reliability"},{"location":"annotation/iterations.html#comments_1","text":"[1] We don't have any text tagged with religious_intolerance by our annotators.","title":"Comments"},{"location":"annotation/iterations.html#conclusions_1","text":"In this iteration, we had more consistent annotations which led to a better agreement between the annotators. Krippendorff's alpha for toxicity labels increased from 0.1962 to 0.4653 . Profiling Report","title":"Conclusions"},{"location":"annotation/iterations.html#iteration-4","text":"In the fourth iteration, we asked the annotators to label a higher number of texts following the same guidelines of the previous iterations. We fixed the deadline to Oct 4th, 2022 (+- one month).","title":"Iteration 4"},{"location":"annotation/iterations.html#inter-rater-reliability_3","text":"As described in the Inter-Rater Reliability section, we evaluate the reliability of the annotators using several coefficients. We also address the analysis by considering it as a multi-label problem or several binary problems. Multi-Label Problem For all our toxicity labels we calculate the Krippendorff's alpha (using the MASI distance) and the Percent Agreement. Krippendorff's alpha : 0.4424 (moderate agreement) Percent Agreement : 0.2769 Binary Problem Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0.5847 0.2174 0.5716 is_targeted 0.4253 0.1825 0.2790 targeted_type 0.2223 0.4840 0.5756 toxic_spans 0.2249 0.4760 (MASI distance) N/A health 0.9800 0.1424 0.9865 ideology 0.8531 0.2909 0.8863 insult 0.4938 0.2923 0.3549 lgbtqphobia 0.9550 0.4901 0.9681 other_lifestyle 0.9705 0.2239 0.9798 physical_aspects 0.9570 0.3623 0.9700 profanity_obscene 0.7436 0.5530 0.7233 racism 0.9940 0.2481 0.9960 religious_intolerance 1.0 1.0 1.0 1 sexism 0.9640 0.1880 0.9753 xenophobia 0.9905 0.3840 0.9936","title":"Inter-Rater Reliability"},{"location":"annotation/iterations.html#comments_2","text":"[1] We don't have any text tagged with religious_intolerance by our annotators in this iteration.","title":"Comments"},{"location":"annotation/iterations.html#conclusions_2","text":"As in the previous iteration, we had more consistent annotations which led to a better agreement between the annotators. Profiling Report","title":"Conclusions"},{"location":"annotation/qualified-annotators.html","text":"Qualified annotators # During our research, we identified several related works that described the disagreements between annotators as the most difficult part of the annotation process. To mitigate this problem, we introduced a training process that will be used to train our annotators. A qualified annotator must have the following skills: Basic English because the tool used to annotate the text is written in English. Native Portuguese as the texts presented in the dataset are in Brazilian Portuguese. A good understanding of offensive language (in Portuguese) and how to detect it. The concepts will be explained in Annotation Guidelines . Additionally, the annotators will be trained by the course Comunica\u00e7\u00e3o N\u00e3o Violenta - FECAP with the following content program: Differences between negativity and toxicity in communication and behavior; Toxic people and behavior; Assertive behavior and communication; Non-violent communication, awareness and non-judgment.","title":"Qualified Annotators"},{"location":"annotation/qualified-annotators.html#qualified-annotators","text":"During our research, we identified several related works that described the disagreements between annotators as the most difficult part of the annotation process. To mitigate this problem, we introduced a training process that will be used to train our annotators. A qualified annotator must have the following skills: Basic English because the tool used to annotate the text is written in English. Native Portuguese as the texts presented in the dataset are in Brazilian Portuguese. A good understanding of offensive language (in Portuguese) and how to detect it. The concepts will be explained in Annotation Guidelines . Additionally, the annotators will be trained by the course Comunica\u00e7\u00e3o N\u00e3o Violenta - FECAP with the following content program: Differences between negativity and toxicity in communication and behavior; Toxic people and behavior; Assertive behavior and communication; Non-violent communication, awareness and non-judgment.","title":"Qualified annotators"},{"location":"annotation/schema.html","text":"Schema # We developed the annotation schema to maximize the annotator's efficiency. OLID-BR contains a collection of annotated sentences in Brazilian Portuguese using an annotation model that encompasses the following levels: Offensive content detection Offense target identification Offensive spans identification Hierarchical taxonomy for categorizing offensive language, proposed by author. To achieve this, we defined 4 questions that our qualified annotators will answer to each sentence. Is this text toxic? Which kind of toxicity it has? There's a specific target? Which words make this text toxic/offensive? The following image shows the annotation screen that our annotators will see. Labeling Interface - Label Studio","title":"Schema"},{"location":"annotation/schema.html#schema","text":"We developed the annotation schema to maximize the annotator's efficiency. OLID-BR contains a collection of annotated sentences in Brazilian Portuguese using an annotation model that encompasses the following levels: Offensive content detection Offense target identification Offensive spans identification Hierarchical taxonomy for categorizing offensive language, proposed by author. To achieve this, we defined 4 questions that our qualified annotators will answer to each sentence. Is this text toxic? Which kind of toxicity it has? There's a specific target? Which words make this text toxic/offensive? The following image shows the annotation screen that our annotators will see. Labeling Interface - Label Studio","title":"Schema"},{"location":"pt/data-pipeline.html","text":"Data Pipeline # Nessa p\u00e1gina, n\u00f3s vamos descrever a pipeline de dados usados para gerar o dataset. Fonte de dados # Coletamos coment\u00e1rios de diferentes fontes, como Twitter , YouTube e conjuntos de dados relacionados. Para cada rede social (Twitter e YouTube), definimos um conjunto de perfis p\u00fablicos que consideramos relevantes para o tema. Al\u00e9m disso, usamos textos em Portugu\u00eas do Brasil de outros conjuntos de dados, como: rogersdepelle/OffComBR: Here we provide a data set of web comments which have been annotated for hate speech. paulafortuna/Portuguese-Hate-Speech-Dataset: A Hierarchically-Labeled Portuguese Hate Speech Dataset LaCAfe/Dataset-Hatespeech: Hate Speech Detection Dataset JAugusto97/ToLD-Br: Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis Arquitetura # O seguinte diagrama mostra a arquitetura da pipeline de dados . Arquitetura - Fonte: Elaborada pelo autor. Filtragem # N\u00f3s queremos filtrar coment\u00e1rios que n\u00e3o sejam relevantes para o escopo do dataset. Para isso, definimos alguns crit\u00e9rios que cada coment\u00e1rio deve possuir. Coment\u00e1rios devem ser em portugu\u00eas. Coment\u00e1rios devem ter um n\u00edvel de toxicidade (medido pela Perspective API) maior que 0.5. Privacidade # Para garantir a privacidade dos usu\u00e1rios, n\u00f3s aplicaremos algumas regras de anonimiza\u00e7\u00e3o dos dados diretamente na pipeline de dados. Usu\u00e1rios mencionados foram substitu\u00eddos pelo texto \"@USER\". URLs foram substitu\u00eddos pelo texto \"URL\".","title":"Data Pipeline"},{"location":"pt/data-pipeline.html#data-pipeline","text":"Nessa p\u00e1gina, n\u00f3s vamos descrever a pipeline de dados usados para gerar o dataset.","title":"Data Pipeline"},{"location":"pt/data-pipeline.html#fonte-de-dados","text":"Coletamos coment\u00e1rios de diferentes fontes, como Twitter , YouTube e conjuntos de dados relacionados. Para cada rede social (Twitter e YouTube), definimos um conjunto de perfis p\u00fablicos que consideramos relevantes para o tema. Al\u00e9m disso, usamos textos em Portugu\u00eas do Brasil de outros conjuntos de dados, como: rogersdepelle/OffComBR: Here we provide a data set of web comments which have been annotated for hate speech. paulafortuna/Portuguese-Hate-Speech-Dataset: A Hierarchically-Labeled Portuguese Hate Speech Dataset LaCAfe/Dataset-Hatespeech: Hate Speech Detection Dataset JAugusto97/ToLD-Br: Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis","title":"Fonte de dados"},{"location":"pt/data-pipeline.html#arquitetura","text":"O seguinte diagrama mostra a arquitetura da pipeline de dados . Arquitetura - Fonte: Elaborada pelo autor.","title":"Arquitetura"},{"location":"pt/data-pipeline.html#filtragem","text":"N\u00f3s queremos filtrar coment\u00e1rios que n\u00e3o sejam relevantes para o escopo do dataset. Para isso, definimos alguns crit\u00e9rios que cada coment\u00e1rio deve possuir. Coment\u00e1rios devem ser em portugu\u00eas. Coment\u00e1rios devem ter um n\u00edvel de toxicidade (medido pela Perspective API) maior que 0.5.","title":"Filtragem"},{"location":"pt/data-pipeline.html#privacidade","text":"Para garantir a privacidade dos usu\u00e1rios, n\u00f3s aplicaremos algumas regras de anonimiza\u00e7\u00e3o dos dados diretamente na pipeline de dados. Usu\u00e1rios mencionados foram substitu\u00eddos pelo texto \"@USER\". URLs foram substitu\u00eddos pelo texto \"URL\".","title":"Privacidade"},{"location":"pt/get-started.html","text":"O dataset est\u00e1 dispon\u00edvel no Kaggle e no Hugging Face. Kaggle # Voc\u00ea pode ver o conjunto de dados em OLID-BR | Kaggle . O c\u00f3digo abaixo mostra como baixar o conjunto de dados usando a API Kaggle. 1 2 3 4 5 from kaggle.api.kaggle_api_extended import KaggleApi kaggle = KaggleApi () kaggle . authenticate () kaggle . dataset_download_files ( dataset = \"olidbr\" , unzip = True ) Hugging Face # Voc\u00ea pode ver o dataset OLID-BR em dougtrajano/olid-br \u00b7 Datasets at Hugging Face . 1 2 from datasets import load_dataset dataset = load_dataset ( \"dougtrajano/olid-br\" ) Arquivos do conjunto de dados # O conjunto de dados \u00e9 composto pelos seguintes arquivos: train.csv : cont\u00e9m o treinamento. test.csv : cont\u00e9m os dados de teste. train_metadata.csv : cont\u00e9m os metadados dos dados de treinamento. test_metadata.csv : cont\u00e9m os metadados dos dados de teste. train.json : cont\u00e9m os dados de treinamento no formato JSON. test.json : cont\u00e9m os dados de teste no formato JSON. additional_data.json : cont\u00e9m dados adicionais no formato JSON. Esses dados n\u00e3o foram usados na cria\u00e7\u00e3o do conjunto de dados. train.csv e test.csv seguem a atribui\u00e7\u00e3o de r\u00f3tulo descrita na se\u00e7\u00e3o Label Assignment . Os arquivos JSON ( train.json , test.json e additional_data.json ) cont\u00eam todas as tr\u00eas anota\u00e7\u00f5es e os metadados de cada inst\u00e2ncia. Hugging Face tem apenas os arquivos train ( train.csv ) e test ( test.csv ). Formato de dados # CSV # Os arquivos CSV s\u00e3o codificados em UTF-8 e possuem as seguintes colunas: id (string): Identificador \u00fanico da inst\u00e2ncia. text (string): O texto da inst\u00e2ncia. is_offensive (string): Se o texto \u00e9 ofensivo ( OFF ) ou n\u00e3o ( NOT ). is_targeted (string): Se o texto \u00e9 direcionado ( TIN ) ou n\u00e3o direcionado ( UNT ). targeted_type (string): Tipo de destino (individual IND , grupo GRP ou outro OTH ). Dispon\u00edvel apenas se is_targeted for True . toxic_spans (string): Lista de spans t\u00f3xicos. sa\u00fade (booleano): Se o texto cont\u00e9m discurso de \u00f3dio com base em condi\u00e7\u00f5es de sa\u00fade, como defici\u00eancia, doen\u00e7a, etc. ideologia (boolean): Indica se o texto cont\u00e9m discurso de \u00f3dio baseado nas ideias ou cren\u00e7as de uma pessoa. insult (boolean): se o texto cont\u00e9m conte\u00fado insultuoso, inflamat\u00f3rio ou provocativo. lgbtqphobia (booleano): se o texto cont\u00e9m conte\u00fado nocivo relacionado \u00e0 identidade de g\u00eanero ou orienta\u00e7\u00e3o sexual. other_lifestyle (boolean): Se o texto cont\u00e9m discurso de \u00f3dio relacionado a h\u00e1bitos de vida (por exemplo, veganismo, vegetarianismo, etc.). physical_aspects (boolean): Se o texto cont\u00e9m discurso de \u00f3dio relacionado \u00e0 apar\u00eancia f\u00edsica. profanity_obscene (boolean): Se o texto cont\u00e9m palavr\u00f5es ou conte\u00fado obsceno. racism (boolean): Se o texto cont\u00e9m pensamentos preconceituosos ou a\u00e7\u00f5es discriminat\u00f3rias baseadas em diferen\u00e7as de ra\u00e7a/etnia. religious_intolerance (boolean): Se o texto cont\u00e9m intoler\u00e2ncia religiosa. sexism (booleano): se o texto cont\u00e9m conte\u00fado discriminat\u00f3rio com base em diferen\u00e7as de sexo/g\u00eanero (por exemplo, sexismo, misoginia, etc.). xenophobia (boolean): Se o texto cont\u00e9m discurso de \u00f3dio contra estrangeiros. Os arquivos CSV seguem nossa estrat\u00e9gia de atribui\u00e7\u00e3o de r\u00f3tulos conforme descrito abaixo. is_offensive : voto majorit\u00e1rio. is_targeted : voto majorit\u00e1rio. targeted_type : voto majorit\u00e1rio. toxic_spans : todos os spans rotulados. health : pelo menos um. ideology : pelo menos um. insult : pelo menos um. lgbtqphobia : pelo menos um. other_lifestyle : pelo menos um. physical_aspects : pelo menos um. profanity_obscene : pelo menos um. racism : pelo menos um. religious_intolerance : pelo menos um. sexism : pelo menos um. xenophobia : pelo menos um. JSON # Os arquivos JSON s\u00e3o codificados em UTF-8 e possuem o seguinte esquema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \"id\" : \"string\" , \"text\" : \"string\" , \"metadata\" : { \"source\" : \"string\" , \"created_at\" : \"string\" , \"collected_at\" : \"string\" , \"toxicity_score\" : \"number\" , }, \"annotations\" : [ { \"annotator_id\" : \"number\" , \"is_offensive\" : \"string\" , \"is_targeted\" : \"string\" , \"targeted_type\" : \"string\" , \"toxic_spans\" : [ \"number\" ], \"health\" : \"boolean\" , \"ideology\" : \"boolean\" , \"insult\" : \"boolean\" , \"lgbtqphobia\" : \"boolean\" , \"other_lifestyle\" : \"boolean\" , \"physical_aspects\" : \"boolean\" , \"profanity_obscene\" : \"boolean\" , \"racism\" : \"boolean\" , \"religious_intolerance\" : \"boolean\" , \"sexism\" : \"boolean\" , \"xenophobia\" : \"boolean\" } ] } Metadados # N\u00f3s forneceremos alguns metadados do dataset para auxiliar em futuras an\u00e1lises. Anotadores # Para cada anotador qualificado, n\u00f3s coletamos as seguintes informa\u00e7\u00f5es: annotator_id O ID do anotador. gender O g\u00eanero do anotador. Male Female Other year_of_birth O ano de nascimento do anotador. education_level O n\u00edvel de educa\u00e7\u00e3o do anotador. Primary School Secondary School Bachelor's Degree Master's Degree Doctoral Degree annotator_ type O tipo do anotador. Volunteer Researcher Contract Worker background A \u00e1rea de estudo do anotador. Computer Science Social Science Essas informa\u00e7\u00f5es podem ser usadas para ajudar a entender o perfil dos anotadores, mantendo a anonimidade dos mesmos. Coment\u00e1rios # Para cada coment\u00e1rio, coletamos informa\u00e7\u00f5es contextuais baseadas nas postagens em redes sociais. source A rede social ou dataset onde o coment\u00e1rio foi coletado. created_at A data e hora da postagem do coment\u00e1rio. collected_at A data e hora da coleta do coment\u00e1rio. toxicity_score A pontua\u00e7\u00e3o de toxicidade do coment\u00e1rio.","title":"Get Started"},{"location":"pt/get-started.html#kaggle","text":"Voc\u00ea pode ver o conjunto de dados em OLID-BR | Kaggle . O c\u00f3digo abaixo mostra como baixar o conjunto de dados usando a API Kaggle. 1 2 3 4 5 from kaggle.api.kaggle_api_extended import KaggleApi kaggle = KaggleApi () kaggle . authenticate () kaggle . dataset_download_files ( dataset = \"olidbr\" , unzip = True )","title":"Kaggle"},{"location":"pt/get-started.html#hugging-face","text":"Voc\u00ea pode ver o dataset OLID-BR em dougtrajano/olid-br \u00b7 Datasets at Hugging Face . 1 2 from datasets import load_dataset dataset = load_dataset ( \"dougtrajano/olid-br\" )","title":"Hugging Face"},{"location":"pt/get-started.html#arquivos-do-conjunto-de-dados","text":"O conjunto de dados \u00e9 composto pelos seguintes arquivos: train.csv : cont\u00e9m o treinamento. test.csv : cont\u00e9m os dados de teste. train_metadata.csv : cont\u00e9m os metadados dos dados de treinamento. test_metadata.csv : cont\u00e9m os metadados dos dados de teste. train.json : cont\u00e9m os dados de treinamento no formato JSON. test.json : cont\u00e9m os dados de teste no formato JSON. additional_data.json : cont\u00e9m dados adicionais no formato JSON. Esses dados n\u00e3o foram usados na cria\u00e7\u00e3o do conjunto de dados. train.csv e test.csv seguem a atribui\u00e7\u00e3o de r\u00f3tulo descrita na se\u00e7\u00e3o Label Assignment . Os arquivos JSON ( train.json , test.json e additional_data.json ) cont\u00eam todas as tr\u00eas anota\u00e7\u00f5es e os metadados de cada inst\u00e2ncia. Hugging Face tem apenas os arquivos train ( train.csv ) e test ( test.csv ).","title":"Arquivos do conjunto de dados"},{"location":"pt/get-started.html#formato-de-dados","text":"","title":"Formato de dados"},{"location":"pt/get-started.html#csv","text":"Os arquivos CSV s\u00e3o codificados em UTF-8 e possuem as seguintes colunas: id (string): Identificador \u00fanico da inst\u00e2ncia. text (string): O texto da inst\u00e2ncia. is_offensive (string): Se o texto \u00e9 ofensivo ( OFF ) ou n\u00e3o ( NOT ). is_targeted (string): Se o texto \u00e9 direcionado ( TIN ) ou n\u00e3o direcionado ( UNT ). targeted_type (string): Tipo de destino (individual IND , grupo GRP ou outro OTH ). Dispon\u00edvel apenas se is_targeted for True . toxic_spans (string): Lista de spans t\u00f3xicos. sa\u00fade (booleano): Se o texto cont\u00e9m discurso de \u00f3dio com base em condi\u00e7\u00f5es de sa\u00fade, como defici\u00eancia, doen\u00e7a, etc. ideologia (boolean): Indica se o texto cont\u00e9m discurso de \u00f3dio baseado nas ideias ou cren\u00e7as de uma pessoa. insult (boolean): se o texto cont\u00e9m conte\u00fado insultuoso, inflamat\u00f3rio ou provocativo. lgbtqphobia (booleano): se o texto cont\u00e9m conte\u00fado nocivo relacionado \u00e0 identidade de g\u00eanero ou orienta\u00e7\u00e3o sexual. other_lifestyle (boolean): Se o texto cont\u00e9m discurso de \u00f3dio relacionado a h\u00e1bitos de vida (por exemplo, veganismo, vegetarianismo, etc.). physical_aspects (boolean): Se o texto cont\u00e9m discurso de \u00f3dio relacionado \u00e0 apar\u00eancia f\u00edsica. profanity_obscene (boolean): Se o texto cont\u00e9m palavr\u00f5es ou conte\u00fado obsceno. racism (boolean): Se o texto cont\u00e9m pensamentos preconceituosos ou a\u00e7\u00f5es discriminat\u00f3rias baseadas em diferen\u00e7as de ra\u00e7a/etnia. religious_intolerance (boolean): Se o texto cont\u00e9m intoler\u00e2ncia religiosa. sexism (booleano): se o texto cont\u00e9m conte\u00fado discriminat\u00f3rio com base em diferen\u00e7as de sexo/g\u00eanero (por exemplo, sexismo, misoginia, etc.). xenophobia (boolean): Se o texto cont\u00e9m discurso de \u00f3dio contra estrangeiros. Os arquivos CSV seguem nossa estrat\u00e9gia de atribui\u00e7\u00e3o de r\u00f3tulos conforme descrito abaixo. is_offensive : voto majorit\u00e1rio. is_targeted : voto majorit\u00e1rio. targeted_type : voto majorit\u00e1rio. toxic_spans : todos os spans rotulados. health : pelo menos um. ideology : pelo menos um. insult : pelo menos um. lgbtqphobia : pelo menos um. other_lifestyle : pelo menos um. physical_aspects : pelo menos um. profanity_obscene : pelo menos um. racism : pelo menos um. religious_intolerance : pelo menos um. sexism : pelo menos um. xenophobia : pelo menos um.","title":"CSV"},{"location":"pt/get-started.html#json","text":"Os arquivos JSON s\u00e3o codificados em UTF-8 e possuem o seguinte esquema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \"id\" : \"string\" , \"text\" : \"string\" , \"metadata\" : { \"source\" : \"string\" , \"created_at\" : \"string\" , \"collected_at\" : \"string\" , \"toxicity_score\" : \"number\" , }, \"annotations\" : [ { \"annotator_id\" : \"number\" , \"is_offensive\" : \"string\" , \"is_targeted\" : \"string\" , \"targeted_type\" : \"string\" , \"toxic_spans\" : [ \"number\" ], \"health\" : \"boolean\" , \"ideology\" : \"boolean\" , \"insult\" : \"boolean\" , \"lgbtqphobia\" : \"boolean\" , \"other_lifestyle\" : \"boolean\" , \"physical_aspects\" : \"boolean\" , \"profanity_obscene\" : \"boolean\" , \"racism\" : \"boolean\" , \"religious_intolerance\" : \"boolean\" , \"sexism\" : \"boolean\" , \"xenophobia\" : \"boolean\" } ] }","title":"JSON"},{"location":"pt/get-started.html#metadados","text":"N\u00f3s forneceremos alguns metadados do dataset para auxiliar em futuras an\u00e1lises.","title":"Metadados"},{"location":"pt/get-started.html#anotadores","text":"Para cada anotador qualificado, n\u00f3s coletamos as seguintes informa\u00e7\u00f5es: annotator_id O ID do anotador. gender O g\u00eanero do anotador. Male Female Other year_of_birth O ano de nascimento do anotador. education_level O n\u00edvel de educa\u00e7\u00e3o do anotador. Primary School Secondary School Bachelor's Degree Master's Degree Doctoral Degree annotator_ type O tipo do anotador. Volunteer Researcher Contract Worker background A \u00e1rea de estudo do anotador. Computer Science Social Science Essas informa\u00e7\u00f5es podem ser usadas para ajudar a entender o perfil dos anotadores, mantendo a anonimidade dos mesmos.","title":"Anotadores"},{"location":"pt/get-started.html#coment\u00e1rios","text":"Para cada coment\u00e1rio, coletamos informa\u00e7\u00f5es contextuais baseadas nas postagens em redes sociais. source A rede social ou dataset onde o coment\u00e1rio foi coletado. created_at A data e hora da postagem do coment\u00e1rio. collected_at A data e hora da coleta do coment\u00e1rio. toxicity_score A pontua\u00e7\u00e3o de toxicidade do coment\u00e1rio.","title":"Coment\u00e1rios"},{"location":"pt/glossary.html","text":"Nesta p\u00e1gina, voc\u00ea encontra um gloss\u00e1rio de termos usados no projeto de detec\u00e7\u00e3o de toxidade e no OLID-BR. Tipos de linguagem ofensiva # Hate Speech # Um tipo de linguagem que \u00e9 usado para atacar uma grupo de pessoas. 1 Cyberbullying # Um tipo de linguagem que \u00e9 usado para atacar um indiv\u00edduo diretamente. 1 Categorias # Health # Discurso de \u00f3dio com base em condi\u00e7\u00f5es de sa\u00fade, como defici\u00eancia f\u00edsica, discrimina\u00e7\u00e3o por idade, etc. 4 Ideology # Discurso de \u00f3dio com base em ideologias, como feminismo, esquerda pol\u00edtica, etc. 4 Insult # Coment\u00e1rio que insulta ou irrita algu\u00e9m ou algum grupo de pessoas. 2 LGBTQphobia # Coment\u00e1rios negativos ou de incita\u00e7\u00e3o ao \u00f3dio por causa de sua identidade de g\u00eanero ou orienta\u00e7\u00e3o sexual. 2 Other-Lifestyle # Coment\u00e1rios ofensivos com base em h\u00e1bitos de vida, como vegetariano, vegano, fumante, etc. 4 Physical Aspects # Discurso de \u00f3dio com base em caracter\u00edsticas f\u00edsicas, como gordofobia, tamanhismo, etc. 4 Profanity (a.k.a obscene) # Palavr\u00f5es, palavras de baixo cal\u00e3o, ou outra linguagem obscena ou profana. 2 Racism # Pensamentos preconceituosos e a\u00e7\u00f5es discriminat\u00f3rias baseadas na diferen\u00e7a de ra\u00e7a/etnia. 3 Religious Intolerance # Pensamentos preconceituosos e a\u00e7\u00f5es discriminat\u00f3rias baseadas na religi\u00e3o, cultos ou pr\u00e1tica religiosa. 4 Sexism # Pensamentos preconceituosos e a\u00e7\u00f5es discriminat\u00f3rias com base na diferen\u00e7a de sexo/g\u00eanero, geralmente por homens contra mulheres (tamb\u00e9m conhecido como misoginia). 3 Xenophobia # M\u00e9do ou \u00f3dio de estrangeiros ou de pessoas que n\u00e3o s\u00e3o do mesmo povo ou cultura. 3 Zampieri et al. \"Predicting the type and target of offensive posts in social media.\" NAACL 2019. \u21a9 \u21a9 \"Perspective | Developers\", Developers.perspectiveapi.com, 2021. [Online]. Available: https://developers.perspectiveapi.com/s/about-the-api-attributes-and-languages . [Accessed: 21- Aug- 2021] \u21a9 \u21a9 \u21a9 Washington University - Student Affairs. (2020, August 12). Glossary of bias terms. Students. https://students.wustl.edu/glossary-bias-terms/ . \u21a9 \u21a9 \u21a9 Fortuna, Paula, et al. \"A hierarchically-labeled portuguese hate speech dataset.\" Proceedings of the Third Workshop on Abusive Language Online. 2019. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9","title":"Glossary"},{"location":"pt/glossary.html#tipos-de-linguagem-ofensiva","text":"","title":"Tipos de linguagem ofensiva"},{"location":"pt/glossary.html#hate-speech","text":"Um tipo de linguagem que \u00e9 usado para atacar uma grupo de pessoas. 1","title":"Hate Speech"},{"location":"pt/glossary.html#cyberbullying","text":"Um tipo de linguagem que \u00e9 usado para atacar um indiv\u00edduo diretamente. 1","title":"Cyberbullying"},{"location":"pt/glossary.html#categorias","text":"","title":"Categorias"},{"location":"pt/glossary.html#health","text":"Discurso de \u00f3dio com base em condi\u00e7\u00f5es de sa\u00fade, como defici\u00eancia f\u00edsica, discrimina\u00e7\u00e3o por idade, etc. 4","title":"Health"},{"location":"pt/glossary.html#ideology","text":"Discurso de \u00f3dio com base em ideologias, como feminismo, esquerda pol\u00edtica, etc. 4","title":"Ideology"},{"location":"pt/glossary.html#insult","text":"Coment\u00e1rio que insulta ou irrita algu\u00e9m ou algum grupo de pessoas. 2","title":"Insult"},{"location":"pt/glossary.html#lgbtqphobia","text":"Coment\u00e1rios negativos ou de incita\u00e7\u00e3o ao \u00f3dio por causa de sua identidade de g\u00eanero ou orienta\u00e7\u00e3o sexual. 2","title":"LGBTQphobia"},{"location":"pt/glossary.html#other-lifestyle","text":"Coment\u00e1rios ofensivos com base em h\u00e1bitos de vida, como vegetariano, vegano, fumante, etc. 4","title":"Other-Lifestyle"},{"location":"pt/glossary.html#physical-aspects","text":"Discurso de \u00f3dio com base em caracter\u00edsticas f\u00edsicas, como gordofobia, tamanhismo, etc. 4","title":"Physical Aspects"},{"location":"pt/glossary.html#profanity-aka-obscene","text":"Palavr\u00f5es, palavras de baixo cal\u00e3o, ou outra linguagem obscena ou profana. 2","title":"Profanity (a.k.a obscene)"},{"location":"pt/glossary.html#racism","text":"Pensamentos preconceituosos e a\u00e7\u00f5es discriminat\u00f3rias baseadas na diferen\u00e7a de ra\u00e7a/etnia. 3","title":"Racism"},{"location":"pt/glossary.html#religious-intolerance","text":"Pensamentos preconceituosos e a\u00e7\u00f5es discriminat\u00f3rias baseadas na religi\u00e3o, cultos ou pr\u00e1tica religiosa. 4","title":"Religious Intolerance"},{"location":"pt/glossary.html#sexism","text":"Pensamentos preconceituosos e a\u00e7\u00f5es discriminat\u00f3rias com base na diferen\u00e7a de sexo/g\u00eanero, geralmente por homens contra mulheres (tamb\u00e9m conhecido como misoginia). 3","title":"Sexism"},{"location":"pt/glossary.html#xenophobia","text":"M\u00e9do ou \u00f3dio de estrangeiros ou de pessoas que n\u00e3o s\u00e3o do mesmo povo ou cultura. 3 Zampieri et al. \"Predicting the type and target of offensive posts in social media.\" NAACL 2019. \u21a9 \u21a9 \"Perspective | Developers\", Developers.perspectiveapi.com, 2021. [Online]. Available: https://developers.perspectiveapi.com/s/about-the-api-attributes-and-languages . [Accessed: 21- Aug- 2021] \u21a9 \u21a9 \u21a9 Washington University - Student Affairs. (2020, August 12). Glossary of bias terms. Students. https://students.wustl.edu/glossary-bias-terms/ . \u21a9 \u21a9 \u21a9 Fortuna, Paula, et al. \"A hierarchically-labeled portuguese hate speech dataset.\" Proceedings of the Third Workshop on Abusive Language Online. 2019. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9","title":"Xenophobia"},{"location":"pt/index.html","text":"OLID-BR # O Offensive Language Identification Dataset for Brazilian Portuguese (OLID-BR) \u00e9 um conjunto de dados com anota\u00e7\u00f5es multiplas tarefas para a detec\u00e7\u00e3o de linguagem ofensiva. A vers\u00e3o atual (v1.0) cont\u00e9m 7.943 (extens\u00edvel para 13,538) coment\u00e1rios de diferentes fontes, incluindo m\u00eddias sociais (YouTube e Twitter) e conjuntos de dados relacionados. OLID-BR cont\u00e9m uma cole\u00e7\u00e3o de coment\u00e1rios em Portugu\u00eas do Brasil anotados que abrangem os seguintes n\u00edveis: Offensive content detection Offense target identification Offensive spans identification Taxonomia hier\u00e1rquica para categorizar linguagem ofensiva, proposta pelo autor. Categoriza\u00e7\u00e3o # Offensive content detection # Este n\u00edvel \u00e9 usado para detectar conte\u00fado ofensivo em uma frase. Este texto \u00e9 ofensivo? # N\u00f3s utilizamos a Perspective API para detectar se um coment\u00e1rio \u00e9 ofensivo ou n\u00e3o. Adicionalmente, nossos anotadores reclassificaram coment\u00e1rios identificados como ofensivos incorretamente. OFF : O coment\u00e1rio \u00e9 ofensivo. NOT : O coment\u00e1rio n\u00e3o \u00e9 ofensivo. Qual tipo de ofensa o texto cont\u00e9m? # Os r\u00f3tulos abaixo foram anotados pelos nossos anotadores. Health , Ideology , Insult , LGBTQphobia , Other-Lifestyle , Physical Aspects , Profanity/Obscene , Racism , Religious Intolerance , Sexism e Xenophobia . Veja Glossary para maiores informa\u00e7\u00f5es. Offense target identification # Este n\u00edvel \u00e9 usado para detectar se um coment\u00e1rio ofensivo \u00e9 direcionado a um indiv\u00edduo, grupo de pessoas ou outros. Este coment\u00e1rio ofensivo \u00e9 direcionado a algu\u00e9m? # TIN : O coment\u00e1rio \u00e9 direcionado a um indiv\u00edduo, grupo de pessoas ou outros. UNT : O coment\u00e1rio n\u00e3o \u00e9 direcionado. Qual o alvo do coment\u00e1rio ofensivo? # IND : O coment\u00e1rio \u00e9 direcionado a um indiv\u00edduo. Tamb\u00e9m conhecido como Cyberbullying . GRP : O coment\u00e1rio \u00e9 direcionado a um grupo de pessoas. Tamb\u00e9m conhecido como Hate Speech . OTH : O coment\u00e1rio \u00e9 direcionado a outras categorias, como uma organiza\u00e7\u00e3o, um evento, etc. Offensive spans identification # Os toxic spans fornecem uma lista com os caracteres de um determinado coment\u00e1rio que s\u00e3o considerados ofensivos. Por exemplo, vamos considerar o coment\u00e1rio: \"USER Canalha URL\" Os toxic spans s\u00e3o: 1 [ 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 ] Estrutura do conjunto de dados # Inst\u00e2ncias de dados # Cada inst\u00e2ncia \u00e9 um coment\u00e1rio de m\u00eddia social com um ID e anota\u00e7\u00f5es correspondentes para todas as tarefas descritas abaixo. Campos de dados # A configura\u00e7\u00e3o simplificada inclui: id (string): Identificador \u00fanico da inst\u00e2ncia. text (string): O texto da inst\u00e2ncia. is_offensive (string): Se o texto \u00e9 ofensivo ( OFF ) ou n\u00e3o ( NOT ). is_targeted (string): Se o texto \u00e9 direcionado ( TIN ) ou n\u00e3o direcionado ( UNT ). targeted_type (string): Tipo de destino (individual IND , grupo GRP ou outro OTH ). Dispon\u00edvel apenas se is_targeted for True . toxic_spans (string): Lista de spans t\u00f3xicos. sa\u00fade (booleano): Se o texto cont\u00e9m discurso de \u00f3dio com base em condi\u00e7\u00f5es de sa\u00fade, como defici\u00eancia, doen\u00e7a, etc. ideologia (boolean): Indica se o texto cont\u00e9m discurso de \u00f3dio baseado nas ideias ou cren\u00e7as de uma pessoa. insult (boolean): se o texto cont\u00e9m conte\u00fado insultuoso, inflamat\u00f3rio ou provocativo. lgbtqphobia (booleano): se o texto cont\u00e9m conte\u00fado nocivo relacionado \u00e0 identidade de g\u00eanero ou orienta\u00e7\u00e3o sexual. other_lifestyle (boolean): Se o texto cont\u00e9m discurso de \u00f3dio relacionado a h\u00e1bitos de vida (por exemplo, veganismo, vegetarianismo, etc.). physical_aspects (boolean): Se o texto cont\u00e9m discurso de \u00f3dio relacionado \u00e0 apar\u00eancia f\u00edsica. profanity_obscene (boolean): Se o texto cont\u00e9m palavr\u00f5es ou conte\u00fado obsceno. racism (boolean): Se o texto cont\u00e9m pensamentos preconceituosos ou a\u00e7\u00f5es discriminat\u00f3rias baseadas em diferen\u00e7as de ra\u00e7a/etnia. religious_intolerance (boolean): Se o texto cont\u00e9m intoler\u00e2ncia religiosa. sexism (booleano): se o texto cont\u00e9m conte\u00fado discriminat\u00f3rio com base em diferen\u00e7as de sexo/g\u00eanero (por exemplo, sexismo, misoginia, etc.). xenophobia (boolean): Se o texto cont\u00e9m discurso de \u00f3dio contra estrangeiros. Consulte a p\u00e1gina Get Started para obter mais informa\u00e7\u00f5es. Considera\u00e7\u00f5es para usar os dados # Impacto social do conjunto de dados # A detec\u00e7\u00e3o de toxicidade \u00e9 um valioso problema para ser estudado que pode garantir um ambiente online mais seguro para todos. No entanto, os algoritmos de detec\u00e7\u00e3o de toxicidade t\u00eam se concentrado no ingl\u00eas e n\u00e3o consideram as especificidades de outros idiomas. Isso \u00e9 um problema porque a toxicidade de um coment\u00e1rio pode ser diferente em diferentes idiomas. Al\u00e9m disso, os algoritmos de detec\u00e7\u00e3o de toxicidade focam na classifica\u00e7\u00e3o bin\u00e1ria de um coment\u00e1rio como t\u00f3xico ou n\u00e3o t\u00f3xico. Portanto, acreditamos que o conjunto de dados OLID-BR pode ajudar a melhorar o desempenho dos algoritmos de detec\u00e7\u00e3o de toxicidade em portugu\u00eas brasileiro. Discuss\u00e3o de preconceitos # Estamos cientes de que o conjunto de dados cont\u00e9m vieses e n\u00e3o \u00e9 representativo da diversidade global. Estamos cientes de que a linguagem usada no conjunto de dados pode n\u00e3o representar a linguagem usada em diferentes contextos. Poss\u00edveis vieses nos dados incluem: Preconceitos inerentes nas m\u00eddias sociais e vieses da base de usu\u00e1rios, as listas de palavras ofensivas/vulgares usadas para filtragem de dados e vieses inerentes ou inconscientes na avalia\u00e7\u00e3o de r\u00f3tulos de identidade ofensivos. Tudo isso provavelmente afeta a rotulagem, a precis\u00e3o e a recupera\u00e7\u00e3o de um modelo treinado. Cita\u00e7\u00e3o # Pending Refer\u00eancias # O conjunto de dados OLID-BR \u00e9 baseado no conjunto de dados OLID proposto por Zampieri et al. (2019) 1 e outros trabalhos relacionados. Zampieri et al. \"Predicting the type and target of offensive posts in social media.\" NAACL 2019. \u21a9 Jo\u00e3o A. Leite, Diego F. Silva, Kalina Bontcheva, Carolina Scarton (2020): Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis. Published at AACL-IJCNLP 2020. \u21a9 S. Malmasi, \"Offensive Language Identification Dataset - OLID\", Scholar.harvard.edu, 2021. [Online]. Available: https://scholar.harvard.edu/malmasi/olid . [Accessed: 28- Aug- 2021]. \u21a9 Weng, L. (2021, March 21). Reducing toxicity in language models. Lil'Log. https://lilianweng.github.io/lil-log/2021/03/21/reducing-toxicity-in-language-models.html . \u21a9","title":"Overview"},{"location":"pt/index.html#olid-br","text":"O Offensive Language Identification Dataset for Brazilian Portuguese (OLID-BR) \u00e9 um conjunto de dados com anota\u00e7\u00f5es multiplas tarefas para a detec\u00e7\u00e3o de linguagem ofensiva. A vers\u00e3o atual (v1.0) cont\u00e9m 7.943 (extens\u00edvel para 13,538) coment\u00e1rios de diferentes fontes, incluindo m\u00eddias sociais (YouTube e Twitter) e conjuntos de dados relacionados. OLID-BR cont\u00e9m uma cole\u00e7\u00e3o de coment\u00e1rios em Portugu\u00eas do Brasil anotados que abrangem os seguintes n\u00edveis: Offensive content detection Offense target identification Offensive spans identification Taxonomia hier\u00e1rquica para categorizar linguagem ofensiva, proposta pelo autor.","title":"OLID-BR"},{"location":"pt/index.html#categoriza\u00e7\u00e3o","text":"","title":"Categoriza\u00e7\u00e3o"},{"location":"pt/index.html#offensive-content-detection","text":"Este n\u00edvel \u00e9 usado para detectar conte\u00fado ofensivo em uma frase.","title":"Offensive content detection"},{"location":"pt/index.html#este-texto-\u00e9-ofensivo","text":"N\u00f3s utilizamos a Perspective API para detectar se um coment\u00e1rio \u00e9 ofensivo ou n\u00e3o. Adicionalmente, nossos anotadores reclassificaram coment\u00e1rios identificados como ofensivos incorretamente. OFF : O coment\u00e1rio \u00e9 ofensivo. NOT : O coment\u00e1rio n\u00e3o \u00e9 ofensivo.","title":"Este texto \u00e9 ofensivo?"},{"location":"pt/index.html#qual-tipo-de-ofensa-o-texto-cont\u00e9m","text":"Os r\u00f3tulos abaixo foram anotados pelos nossos anotadores. Health , Ideology , Insult , LGBTQphobia , Other-Lifestyle , Physical Aspects , Profanity/Obscene , Racism , Religious Intolerance , Sexism e Xenophobia . Veja Glossary para maiores informa\u00e7\u00f5es.","title":"Qual tipo de ofensa o texto cont\u00e9m?"},{"location":"pt/index.html#offense-target-identification","text":"Este n\u00edvel \u00e9 usado para detectar se um coment\u00e1rio ofensivo \u00e9 direcionado a um indiv\u00edduo, grupo de pessoas ou outros.","title":"Offense target identification"},{"location":"pt/index.html#este-coment\u00e1rio-ofensivo-\u00e9-direcionado-a-algu\u00e9m","text":"TIN : O coment\u00e1rio \u00e9 direcionado a um indiv\u00edduo, grupo de pessoas ou outros. UNT : O coment\u00e1rio n\u00e3o \u00e9 direcionado.","title":"Este coment\u00e1rio ofensivo \u00e9 direcionado a algu\u00e9m?"},{"location":"pt/index.html#qual-o-alvo-do-coment\u00e1rio-ofensivo","text":"IND : O coment\u00e1rio \u00e9 direcionado a um indiv\u00edduo. Tamb\u00e9m conhecido como Cyberbullying . GRP : O coment\u00e1rio \u00e9 direcionado a um grupo de pessoas. Tamb\u00e9m conhecido como Hate Speech . OTH : O coment\u00e1rio \u00e9 direcionado a outras categorias, como uma organiza\u00e7\u00e3o, um evento, etc.","title":"Qual o alvo do coment\u00e1rio ofensivo?"},{"location":"pt/index.html#offensive-spans-identification","text":"Os toxic spans fornecem uma lista com os caracteres de um determinado coment\u00e1rio que s\u00e3o considerados ofensivos. Por exemplo, vamos considerar o coment\u00e1rio: \"USER Canalha URL\" Os toxic spans s\u00e3o: 1 [ 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 ]","title":"Offensive spans identification"},{"location":"pt/index.html#estrutura-do-conjunto-de-dados","text":"","title":"Estrutura do conjunto de dados"},{"location":"pt/index.html#inst\u00e2ncias-de-dados","text":"Cada inst\u00e2ncia \u00e9 um coment\u00e1rio de m\u00eddia social com um ID e anota\u00e7\u00f5es correspondentes para todas as tarefas descritas abaixo.","title":"Inst\u00e2ncias de dados"},{"location":"pt/index.html#campos-de-dados","text":"A configura\u00e7\u00e3o simplificada inclui: id (string): Identificador \u00fanico da inst\u00e2ncia. text (string): O texto da inst\u00e2ncia. is_offensive (string): Se o texto \u00e9 ofensivo ( OFF ) ou n\u00e3o ( NOT ). is_targeted (string): Se o texto \u00e9 direcionado ( TIN ) ou n\u00e3o direcionado ( UNT ). targeted_type (string): Tipo de destino (individual IND , grupo GRP ou outro OTH ). Dispon\u00edvel apenas se is_targeted for True . toxic_spans (string): Lista de spans t\u00f3xicos. sa\u00fade (booleano): Se o texto cont\u00e9m discurso de \u00f3dio com base em condi\u00e7\u00f5es de sa\u00fade, como defici\u00eancia, doen\u00e7a, etc. ideologia (boolean): Indica se o texto cont\u00e9m discurso de \u00f3dio baseado nas ideias ou cren\u00e7as de uma pessoa. insult (boolean): se o texto cont\u00e9m conte\u00fado insultuoso, inflamat\u00f3rio ou provocativo. lgbtqphobia (booleano): se o texto cont\u00e9m conte\u00fado nocivo relacionado \u00e0 identidade de g\u00eanero ou orienta\u00e7\u00e3o sexual. other_lifestyle (boolean): Se o texto cont\u00e9m discurso de \u00f3dio relacionado a h\u00e1bitos de vida (por exemplo, veganismo, vegetarianismo, etc.). physical_aspects (boolean): Se o texto cont\u00e9m discurso de \u00f3dio relacionado \u00e0 apar\u00eancia f\u00edsica. profanity_obscene (boolean): Se o texto cont\u00e9m palavr\u00f5es ou conte\u00fado obsceno. racism (boolean): Se o texto cont\u00e9m pensamentos preconceituosos ou a\u00e7\u00f5es discriminat\u00f3rias baseadas em diferen\u00e7as de ra\u00e7a/etnia. religious_intolerance (boolean): Se o texto cont\u00e9m intoler\u00e2ncia religiosa. sexism (booleano): se o texto cont\u00e9m conte\u00fado discriminat\u00f3rio com base em diferen\u00e7as de sexo/g\u00eanero (por exemplo, sexismo, misoginia, etc.). xenophobia (boolean): Se o texto cont\u00e9m discurso de \u00f3dio contra estrangeiros. Consulte a p\u00e1gina Get Started para obter mais informa\u00e7\u00f5es.","title":"Campos de dados"},{"location":"pt/index.html#considera\u00e7\u00f5es-para-usar-os-dados","text":"","title":"Considera\u00e7\u00f5es para usar os dados"},{"location":"pt/index.html#impacto-social-do-conjunto-de-dados","text":"A detec\u00e7\u00e3o de toxicidade \u00e9 um valioso problema para ser estudado que pode garantir um ambiente online mais seguro para todos. No entanto, os algoritmos de detec\u00e7\u00e3o de toxicidade t\u00eam se concentrado no ingl\u00eas e n\u00e3o consideram as especificidades de outros idiomas. Isso \u00e9 um problema porque a toxicidade de um coment\u00e1rio pode ser diferente em diferentes idiomas. Al\u00e9m disso, os algoritmos de detec\u00e7\u00e3o de toxicidade focam na classifica\u00e7\u00e3o bin\u00e1ria de um coment\u00e1rio como t\u00f3xico ou n\u00e3o t\u00f3xico. Portanto, acreditamos que o conjunto de dados OLID-BR pode ajudar a melhorar o desempenho dos algoritmos de detec\u00e7\u00e3o de toxicidade em portugu\u00eas brasileiro.","title":"Impacto social do conjunto de dados"},{"location":"pt/index.html#discuss\u00e3o-de-preconceitos","text":"Estamos cientes de que o conjunto de dados cont\u00e9m vieses e n\u00e3o \u00e9 representativo da diversidade global. Estamos cientes de que a linguagem usada no conjunto de dados pode n\u00e3o representar a linguagem usada em diferentes contextos. Poss\u00edveis vieses nos dados incluem: Preconceitos inerentes nas m\u00eddias sociais e vieses da base de usu\u00e1rios, as listas de palavras ofensivas/vulgares usadas para filtragem de dados e vieses inerentes ou inconscientes na avalia\u00e7\u00e3o de r\u00f3tulos de identidade ofensivos. Tudo isso provavelmente afeta a rotulagem, a precis\u00e3o e a recupera\u00e7\u00e3o de um modelo treinado.","title":"Discuss\u00e3o de preconceitos"},{"location":"pt/index.html#cita\u00e7\u00e3o","text":"Pending","title":"Cita\u00e7\u00e3o"},{"location":"pt/index.html#refer\u00eancias","text":"O conjunto de dados OLID-BR \u00e9 baseado no conjunto de dados OLID proposto por Zampieri et al. (2019) 1 e outros trabalhos relacionados. Zampieri et al. \"Predicting the type and target of offensive posts in social media.\" NAACL 2019. \u21a9 Jo\u00e3o A. Leite, Diego F. Silva, Kalina Bontcheva, Carolina Scarton (2020): Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis. Published at AACL-IJCNLP 2020. \u21a9 S. Malmasi, \"Offensive Language Identification Dataset - OLID\", Scholar.harvard.edu, 2021. [Online]. Available: https://scholar.harvard.edu/malmasi/olid . [Accessed: 28- Aug- 2021]. \u21a9 Weng, L. (2021, March 21). Reducing toxicity in language models. Lil'Log. https://lilianweng.github.io/lil-log/2021/03/21/reducing-toxicity-in-language-models.html . \u21a9","title":"Refer\u00eancias"},{"location":"pt/annotation/guidelines.html","text":"Diretrizes de anota\u00e7\u00e3o # Nessa p\u00e1gina detalhamos as diretrizes seguidas pelos anotadores durante o processo de anota\u00e7\u00e3o dos textos presentes no OLID-BR. Na figura abaixo, voc\u00ea pode ver o esquema de anota\u00e7\u00e3o para o conjunto de dados OLID-BR. Taxonomia hier\u00e1rquica para categorizar linguagem ofensiva, proposta pelo autor. Qual a tarefa que voc\u00ea est\u00e1 fazendo? # Voc\u00ea visualizar\u00e1 coment\u00e1rios com conte\u00fado ofensivo/t\u00f3xico e precisar\u00e1 responder algumas perguntas sobre isso, essas perguntas ajudar\u00e3o a identificar coment\u00e1rios ofensivos e/ou entender melhor o comportamento dos haters . Na imagem abaixo, voc\u00ea pode ver um exemplo da tela de anota\u00e7\u00e3o visualizada pelo anotador. Annotation - Label Studio Quais perguntas voc\u00ea dever\u00e1 responder? # Para cada coment\u00e1rio, voc\u00ea deve responder as seguintes perguntas: Is this text toxic? # A primeira pergunta identifica se o texto \u00e9 ofensivo ou n\u00e3o. Ela j\u00e1 vem preenchida como \"Yes\", visto que o coment\u00e1rio foi pr\u00e9-filtrado por um classificador de textos ofensivos. Avalie se o texto \u00e9 de fato ofensivo, caso contr\u00e1rio, escolha a op\u00e7\u00e3o \"No\". Ao selecionar a op\u00e7\u00e3o \"No\", as perguntas seguintes n\u00e3o ser\u00e3o exibidas. Which kind of toxicity it has? # Essa pergunta procura identificar o(s) tipo(s) de toxicidade que o coment\u00e1rio possui dentro de algumas categorias pr\u00e9-definidas. Abaixo \u00e9 poss\u00edvel ver as categorias, suas defini\u00e7\u00f5es e exemplos de coment\u00e1rios que possuem cada uma dessas categorias. Health Coment\u00e1rio ofensivo com base na sa\u00fade, defici\u00eancias f\u00edsicas, discrimina\u00e7\u00e3o por idade, caracter\u00edsticas causadas por doen\u00e7as, etc. Exemplos: USER velho broxa Me desculpem gente mulher nenhuma \u00e9 Feliz com esse corpo? Ela precisa de tratamento isso \u00e9 uma doen\u00e7a rt USER esse curso eh coisa de gente retardada mental vsf q porra USER IMBECIL PROMOVENDO A AGLOMERA\u00c7\u00c3O DO POVO USER E A PROPAGA\u00c7\u00c3O DA DOEN\u00c7A. QUANTA USER !!!!!!!!!!!!!!!!!!!!! parece legenda pra cego surdo e mudo Ideology Discurso de \u00f3dio com base nas ideologias, como feminista, esquerda pol\u00edtica, etc. Exemplos: esse partido chamado P T e esse P Sol sao uma doenca pra nossa nacao um enfermo USER A Folha desde sempre apoiando a DITADURA e apoiando FASCISTAS que at\u00e9 se esquece de falar sobre seus ESC\u00c2NDALOS como EMPRESTAR CARROS para a DITADURA ir TORTURAR PESSOAS. A Folha GOLPISTA nunca faz uma \u201cautocr\u00edtica\u201d URL USER Aqui na minha fam\u00edlia fechado com o MITO PT LADR\u00c3O NUNCA VOLTAMOS NESSA RA\u00c7A IMUNDA FDP DE LADR\u00d5ES \u2705\ud83c\udde7\ud83c\uddf7\ud83c\udde7\ud83c\uddf7 URL USER USER USER O Bolsonaro \u00e9 corrupto mlk, para de ser retardado, seu c\u00e9rebro t\u00e1 atrofiando A juiza \u00e9 pilantra igual a Sergio USER quer impor a lei da morda\u00e7a amea\u00e7ando e obrigado o r\u00e9l o expresidente Lula a ficar calado Arma\u00e7\u00e3o geral do judiciario partidario de Curitiba de Sergio USER Bolsonaro: \u201cComo \u00e9 duro ser patr\u00e3o no Brasil\". 19 milh\u00f5es de brasileiros passam fome e a grande preocupa\u00e7\u00e3o do cretino \u00e9 com os patr\u00f5es. Insult Discurso de \u00f3dio que possui insulto, inj\u00faria, xingamento. Tem o objetivo de inflamar uma discuss\u00e3o, irritar uma parte, atingir um ponto fraco da v\u00edtima, etc. Exemplos: USER USER Fodase denovo tmc para de aoarecer pra min desgra\u00e7a USER Kkkkkkkk \u00e9 mesmo q ano de bosta vai toma no c uuuuuuuu USER Voc\u00ea \u00e9 um lixo! USER Depois que acaba os campeonatos VC vem falar em liberar p\u00fablico nos est\u00e1dios seu bosta calca apertada LGBTQphobia Discurso de \u00f3dio com base na identidade de g\u00eanero ou orienta\u00e7\u00e3o sexual. O coment\u00e1rio possui ataque a orienta\u00e7\u00e3o sexual ou a identidade de g\u00eanero. Inclui afobia, bifobia, homofobia, lesbofobia, transfobia e outras fobias relacionadas \u00e0 sexualidade. Warning Cuidado para n\u00e3o confundir com sexismo. Exemplos: Que vergonha esse pais s\u00f3 tem gay USER voce so gosta d sapatao caminhoeira de cabelo rapado USER baitola lixo USER USER lament\u00e1vel acredita que existe pessoas que ap\u00f3ia o LGBT USER O problema n\u00e3o \u00e9 sexualidade e sim compet\u00eancia. \u00c9 diferente ferrar s\u00f3 um rabo ou ferrar de milhares. USER E quando n\u00e3o consegue espa\u00e7o e relev\u00e2ncia no meio, mente que \u00e9 bi. USER Voc\u00ea \u00e9 uma vergonha para os gays pq tu \u00e9 um gay ladr\u00e3o de dinheiro da Pandemia. Other-Lifestyle Discurso de \u00f3dio com base em h\u00e1bitos de vida, como vegetariano, vegano, fumante, etc. Exemplos: Povo da ra\u00e7\u00e3o com milho he he Povinho irritante e desinformado esses veganos chatos. Com certeza nao convencem nem suas familias. USER crackudo voz de fumante Coisa brega esse piercing no nariz. Muito feio para uma jornalista. USER USER seu c\u00e9rebro derreteu por causa da maconha????????? Como ser feminista: Ser feia e gorda Pagar peitinho em passeata Ser peluda Odiar homens E achar q isso far\u00e1 diferen\u00e7a Aula de como comer um maconheiro! Hahaha Ai aonde a tua maconha te levou KKKkKkkK Physical Aspects Discurso de \u00f3dio com base em caracter\u00edsticas f\u00edsicas, como gordofobia, tamanhismo, etc. Exemplos: Pr\u00f3ximo major j\u00e1 sabem, galera: ca\u00e7ar o gordo e extermina-lo. Deveriam ter escolhido uma modelo menos gordinha, ela parece que n\u00e3o est\u00e1 passando fome !! USER pode achar seu principe encantado,mas sempre vai acabar: Gorda,feia,virgem,cheia de poster de crep\u00fasculo a parede!! Me desculpem gente mulher nenhuma \u00e9 Feliz com esse corpo? Ela precisa de tratamento isso \u00e9 uma doen\u00e7a USER nao \u00e9 gorda nao,USER esta obesa.vai se tratar \u00e9 o melhor que USER faz. RT USER: e olha pra cara gorda e feia de Isabelle .. sem contar da voz irritante dela URL A obesidade est\u00e1 acabando com essa mulher. Rid\u00edcula EU N\u00c3O AGUENTO MAIS ESSE ALEIJADO SEM UMA PERNA DO CARALHO VAI TOMAR NO CU, O MALUCO NN SABE ANDAR COM A PERNA DIREITA FUDIDO HORR\u00cdVEL URL Profanity/Obscene Discurso de \u00f3dio possui palavras obscenas, vulgar, pornogr\u00e1ficas, etc. Exemplos: USER Comer cu de curioso USER Mas que grande fdp. USER Passar porte de vacina \u00e9 o meu pau USER Cada filho da puta que apertou 17 tem as mas sujas de sangue USER Com a PF na tua casa tu ficou bravinho n\u00e9 vagabundo? USER Toma no cu \u00e9 vitamina como tu e tua prima. fudeu minha m\u00e3e acabou de chegar em casa e eu acabei de acordar tomei no cu Racism O coment\u00e1rio \u00e9 preconceituoso ou discriminat\u00f3rio com base na ra\u00e7a, cor ou etnia de uma pessoa ou grupo de pessoas. Exemplos: Essas filhas de pedreiro africano e foda N\u00e3o tenho tv colorida pra ficar olhando essa preta nao USER E quantos desses negros s\u00e3o inocentes e quantos s\u00e3o criminosos e bandidos? Te dou absoluta certeza que a maioria dos negros mortos n\u00e3o s\u00e3o inocentes, infelizmente muitas vezes inocentes acabam sendo mortos pela corrup\u00e7\u00e3o na pol\u00edcia USER Sai macaco Essa nega do c\u00e3o quer ser a dona da raz\u00e3o e da situa\u00e7\u00e3o smp \ud83d\ude02\ud83d\ude02\ud83d\ude02 Religious Intolerance O coment\u00e1rio \u00e9 preconceituoso ou discriminat\u00f3rio com base na religi\u00e3o, culto ou pr\u00e1tica religiosa. Exemplos: USER Um governo de Evangelicos. Um governo de Corruptos. Um governo de Criminosos. Uma macumbeira a menos Que diabo de Ogum, por isso que n\u00e3o vai pra frente Sexism O coment\u00e1rio \u00e9 preconceituoso ou discriminat\u00f3rio com base no g\u00eanero ou sexo de uma pessoa ou grupo de pessoas. Exemplos: Se eu fosse o Temer criava o Minist\u00e9rio da Cozinha e da Limpeza e colocava uma mulher, s\u00f3 pro pessoal chorar menos. hahahaha USER Uma calcinha dessa fio-dental dentro da bunda n\u00e3o tem que resistir uma tenta\u00e7\u00e3o dessa? Homem \u00e9 um bicho estranho ao mesmo tmp rid\u00edculo \ud83e\udd23 Resumindo\" Meteu gostoso na safada\" fim da historia! N\u00e3o tem dinheiro q essa mulher,ela \u00e9 terr\u00edvel n\u00e3o vai ter homem q a suporte D\u00e1 uma rola pras feminazi.quem sabe elas param de falar bosta. Xenophobia Discurso de \u00f3dio contra pessoas estrangeiras ou de outras culturas. Exemplos: Quem liga pra judeu kkkk odeio goiano e mineiro rt USER USER nao sei . pra mim todo japones que \u00e9 comunista \u00e9 burro... uma coisa q meu pai ensinou kk esse chinezinho falsificado e um pilantra. N\u00e3o se deixa enganar como ele enganou os que votaram nele. Esse tipo de jumento s\u00f3 se elege uma vez. USER O brasileiro merece o que t\u00e1 passando povo ignorante e sem a menor consci\u00eancia bando de fudido do caralho USER USER PUTAQUEPARIUUUUUU........ESSAS PORCARIAS S\u00d3 ACONTECE NO BRASIL.... RA\u00c7A MALDITA ESSES BRASILEIROS....EXTIN\u00c7AO Nordestino \u00e9 uma desgra\u00e7a cambada de dem\u00f4nio There's a specific target? # Essa pergunta procura identificar se o coment\u00e1rio t\u00f3xico \u00e9 direcionado a um indiv\u00edduo, um grupo ou a outros. Marque apenas se existir um alvo claro do coment\u00e1rio t\u00f3xico. Op\u00e7\u00f5es: Individual : O coment\u00e1rio t\u00f3xico \u00e9 direcionado a um indiv\u00edduo, uma pessoa espec\u00edfica. Group : O coment\u00e1rio t\u00f3xico \u00e9 direcionado a um grupo, uma comunidade. Other : O coment\u00e1rio t\u00f3xico \u00e9 direcionado, por\u00e9m n\u00e3o a um indiv\u00edduo ou grupo espec\u00edficos. Ex.: empresas, eventos, natureza, etc. Which words make this text toxic/offensive? # Os toxic spans s\u00e3o os trechos do texto que s\u00e3o identificados como ofensivas, profanas, insultantes, etc. Exemplo: Vai tomar no c@, seu arr0mb@d0 Na frase acima, temos dois grupos de toxic spans que devem ser marcados: vai tomar no c@ e arr0mb@d0 . Um outro exemplo: \"Que exemplo idiota! Voc\u00ea \u00e9 burro demais.\" Na frase acima, a palavra idiota e burro s\u00e3o exemplos de toxic spans . Tamb\u00e9m s\u00e3o consideradas toxic spans conjunto de palavras, por exemplo: vai a merda . Warning N\u00e3o selecione palavras como \"seu\", \"sua\", \"\u00e9\", etc. Perguntas frequentes # Diferen\u00e7a entre uma opini\u00e3o negativa e um coment\u00e1rio t\u00f3xico # \u00c9 importante entender a diferen\u00e7a entre uma opini\u00e3o negativa e um coment\u00e1rio t\u00f3xico. Uma opini\u00e3o negativa \u00e9 um texto que exp\u00f5em uma opini\u00e3o ou fato desagrad\u00e1vel com duras palavras, normalmente criticam o trabalho ou a\u00e7\u00e3o de algu\u00e9m, mas sem ferir a dignidade ou a honra de uma pessoa ou grupo. Exemplos: USER Agora \u00e9 \"estupro\" mesmo com a mulher dizendo que quis e gostou. Eu avisei que esse dia ia chegar. Moro conseguiu o que queria: eleger Bolsonaro em troca de um minist\u00e9rio. O que aconteceu depois foi \"briga de quadrilha\", na opini\u00e3o do advogado Kakay. Por tudo isso, ele considera o ex-juiz \"a pr\u00f3pria fake news\". Veja na \u00faltima HASHTAG do ano! HASHTAG URL USER Crime \u00e9 invadir a casa dos outros. USER perder faz parte do esporte. Agora insultar e trazer o racismo pra nossas vidas n\u00e3o, eu n\u00e3o estou de acordo. Um coment\u00e1rio t\u00f3xico extrapola a liberdade de express\u00e3o, normalmente cont\u00e9m palavras ofensivas ou insultantes. Procura denegrir a dignidade ou a honra de uma pessoa ou grupo. Exemplos: O presidente da empresa USER \u00e9 um idiota e n\u00e3o entende o que \u00e9 importante para a empresa. Como se d\u00e1 m\u00eddia pra um safado desses...merece cadeia... A mulher estava vuneravel...em surto... Ficam dando cartaz pra esse canalha... que mundo \u00e9 esse????? Esse cara n\u00e3o sabe jogar pqp Erros ortogr\u00e1ficos e formas de evitar a detec\u00e7\u00e3o de toxicidade # Os usu\u00e1rios podem digitar palavras err\u00f4neamente ou substituir caracteres para evitar a detec\u00e7\u00e3o de toxicidade. Neste caso, voc\u00ea deve interpretar as palavras como se fossem escritas corretamente. Exemplos: arr0mb@d0 > arrombado vai tomar no c@ > vai tomar no cu Sobre os toxic spans , voc\u00ea deve seguir com a marca\u00e7\u00e3o da mesma forma, como se estivessem corretas. O texto \u00e9 ileg\u00edvel, o que fazer? # Se voc\u00ea n\u00e3o conseguir compreender o texto, voc\u00ea pode clicar no bot\u00e3o Skip e pular para o pr\u00f3ximo texto. \u00c9 poss\u00edvel voltar em um coment\u00e1rio j\u00e1 anotado? # N\u00e3o \u00e9 poss\u00edvel voltar durante o processo de anota\u00e7\u00e3o, mas \u00e9 poss\u00edvel filtr\u00e1-lo na tabela inicial. Em caso de d\u00favidas, consulte a ajuda. Tenha cuidado ao submeter um coment\u00e1rio caso n\u00e3o tenha certeza, na d\u00favida clique no bot\u00e3o \"Skip\".","title":"Guidelines"},{"location":"pt/annotation/guidelines.html#diretrizes-de-anota\u00e7\u00e3o","text":"Nessa p\u00e1gina detalhamos as diretrizes seguidas pelos anotadores durante o processo de anota\u00e7\u00e3o dos textos presentes no OLID-BR. Na figura abaixo, voc\u00ea pode ver o esquema de anota\u00e7\u00e3o para o conjunto de dados OLID-BR. Taxonomia hier\u00e1rquica para categorizar linguagem ofensiva, proposta pelo autor.","title":"Diretrizes de anota\u00e7\u00e3o"},{"location":"pt/annotation/guidelines.html#qual-a-tarefa-que-voc\u00ea-est\u00e1-fazendo","text":"Voc\u00ea visualizar\u00e1 coment\u00e1rios com conte\u00fado ofensivo/t\u00f3xico e precisar\u00e1 responder algumas perguntas sobre isso, essas perguntas ajudar\u00e3o a identificar coment\u00e1rios ofensivos e/ou entender melhor o comportamento dos haters . Na imagem abaixo, voc\u00ea pode ver um exemplo da tela de anota\u00e7\u00e3o visualizada pelo anotador. Annotation - Label Studio","title":"Qual a tarefa que voc\u00ea est\u00e1 fazendo?"},{"location":"pt/annotation/guidelines.html#quais-perguntas-voc\u00ea-dever\u00e1-responder","text":"Para cada coment\u00e1rio, voc\u00ea deve responder as seguintes perguntas:","title":"Quais perguntas voc\u00ea dever\u00e1 responder?"},{"location":"pt/annotation/guidelines.html#is-this-text-toxic","text":"A primeira pergunta identifica se o texto \u00e9 ofensivo ou n\u00e3o. Ela j\u00e1 vem preenchida como \"Yes\", visto que o coment\u00e1rio foi pr\u00e9-filtrado por um classificador de textos ofensivos. Avalie se o texto \u00e9 de fato ofensivo, caso contr\u00e1rio, escolha a op\u00e7\u00e3o \"No\". Ao selecionar a op\u00e7\u00e3o \"No\", as perguntas seguintes n\u00e3o ser\u00e3o exibidas.","title":"Is this text toxic?"},{"location":"pt/annotation/guidelines.html#which-kind-of-toxicity-it-has","text":"Essa pergunta procura identificar o(s) tipo(s) de toxicidade que o coment\u00e1rio possui dentro de algumas categorias pr\u00e9-definidas. Abaixo \u00e9 poss\u00edvel ver as categorias, suas defini\u00e7\u00f5es e exemplos de coment\u00e1rios que possuem cada uma dessas categorias. Health Coment\u00e1rio ofensivo com base na sa\u00fade, defici\u00eancias f\u00edsicas, discrimina\u00e7\u00e3o por idade, caracter\u00edsticas causadas por doen\u00e7as, etc. Exemplos: USER velho broxa Me desculpem gente mulher nenhuma \u00e9 Feliz com esse corpo? Ela precisa de tratamento isso \u00e9 uma doen\u00e7a rt USER esse curso eh coisa de gente retardada mental vsf q porra USER IMBECIL PROMOVENDO A AGLOMERA\u00c7\u00c3O DO POVO USER E A PROPAGA\u00c7\u00c3O DA DOEN\u00c7A. QUANTA USER !!!!!!!!!!!!!!!!!!!!! parece legenda pra cego surdo e mudo Ideology Discurso de \u00f3dio com base nas ideologias, como feminista, esquerda pol\u00edtica, etc. Exemplos: esse partido chamado P T e esse P Sol sao uma doenca pra nossa nacao um enfermo USER A Folha desde sempre apoiando a DITADURA e apoiando FASCISTAS que at\u00e9 se esquece de falar sobre seus ESC\u00c2NDALOS como EMPRESTAR CARROS para a DITADURA ir TORTURAR PESSOAS. A Folha GOLPISTA nunca faz uma \u201cautocr\u00edtica\u201d URL USER Aqui na minha fam\u00edlia fechado com o MITO PT LADR\u00c3O NUNCA VOLTAMOS NESSA RA\u00c7A IMUNDA FDP DE LADR\u00d5ES \u2705\ud83c\udde7\ud83c\uddf7\ud83c\udde7\ud83c\uddf7 URL USER USER USER O Bolsonaro \u00e9 corrupto mlk, para de ser retardado, seu c\u00e9rebro t\u00e1 atrofiando A juiza \u00e9 pilantra igual a Sergio USER quer impor a lei da morda\u00e7a amea\u00e7ando e obrigado o r\u00e9l o expresidente Lula a ficar calado Arma\u00e7\u00e3o geral do judiciario partidario de Curitiba de Sergio USER Bolsonaro: \u201cComo \u00e9 duro ser patr\u00e3o no Brasil\". 19 milh\u00f5es de brasileiros passam fome e a grande preocupa\u00e7\u00e3o do cretino \u00e9 com os patr\u00f5es. Insult Discurso de \u00f3dio que possui insulto, inj\u00faria, xingamento. Tem o objetivo de inflamar uma discuss\u00e3o, irritar uma parte, atingir um ponto fraco da v\u00edtima, etc. Exemplos: USER USER Fodase denovo tmc para de aoarecer pra min desgra\u00e7a USER Kkkkkkkk \u00e9 mesmo q ano de bosta vai toma no c uuuuuuuu USER Voc\u00ea \u00e9 um lixo! USER Depois que acaba os campeonatos VC vem falar em liberar p\u00fablico nos est\u00e1dios seu bosta calca apertada LGBTQphobia Discurso de \u00f3dio com base na identidade de g\u00eanero ou orienta\u00e7\u00e3o sexual. O coment\u00e1rio possui ataque a orienta\u00e7\u00e3o sexual ou a identidade de g\u00eanero. Inclui afobia, bifobia, homofobia, lesbofobia, transfobia e outras fobias relacionadas \u00e0 sexualidade. Warning Cuidado para n\u00e3o confundir com sexismo. Exemplos: Que vergonha esse pais s\u00f3 tem gay USER voce so gosta d sapatao caminhoeira de cabelo rapado USER baitola lixo USER USER lament\u00e1vel acredita que existe pessoas que ap\u00f3ia o LGBT USER O problema n\u00e3o \u00e9 sexualidade e sim compet\u00eancia. \u00c9 diferente ferrar s\u00f3 um rabo ou ferrar de milhares. USER E quando n\u00e3o consegue espa\u00e7o e relev\u00e2ncia no meio, mente que \u00e9 bi. USER Voc\u00ea \u00e9 uma vergonha para os gays pq tu \u00e9 um gay ladr\u00e3o de dinheiro da Pandemia. Other-Lifestyle Discurso de \u00f3dio com base em h\u00e1bitos de vida, como vegetariano, vegano, fumante, etc. Exemplos: Povo da ra\u00e7\u00e3o com milho he he Povinho irritante e desinformado esses veganos chatos. Com certeza nao convencem nem suas familias. USER crackudo voz de fumante Coisa brega esse piercing no nariz. Muito feio para uma jornalista. USER USER seu c\u00e9rebro derreteu por causa da maconha????????? Como ser feminista: Ser feia e gorda Pagar peitinho em passeata Ser peluda Odiar homens E achar q isso far\u00e1 diferen\u00e7a Aula de como comer um maconheiro! Hahaha Ai aonde a tua maconha te levou KKKkKkkK Physical Aspects Discurso de \u00f3dio com base em caracter\u00edsticas f\u00edsicas, como gordofobia, tamanhismo, etc. Exemplos: Pr\u00f3ximo major j\u00e1 sabem, galera: ca\u00e7ar o gordo e extermina-lo. Deveriam ter escolhido uma modelo menos gordinha, ela parece que n\u00e3o est\u00e1 passando fome !! USER pode achar seu principe encantado,mas sempre vai acabar: Gorda,feia,virgem,cheia de poster de crep\u00fasculo a parede!! Me desculpem gente mulher nenhuma \u00e9 Feliz com esse corpo? Ela precisa de tratamento isso \u00e9 uma doen\u00e7a USER nao \u00e9 gorda nao,USER esta obesa.vai se tratar \u00e9 o melhor que USER faz. RT USER: e olha pra cara gorda e feia de Isabelle .. sem contar da voz irritante dela URL A obesidade est\u00e1 acabando com essa mulher. Rid\u00edcula EU N\u00c3O AGUENTO MAIS ESSE ALEIJADO SEM UMA PERNA DO CARALHO VAI TOMAR NO CU, O MALUCO NN SABE ANDAR COM A PERNA DIREITA FUDIDO HORR\u00cdVEL URL Profanity/Obscene Discurso de \u00f3dio possui palavras obscenas, vulgar, pornogr\u00e1ficas, etc. Exemplos: USER Comer cu de curioso USER Mas que grande fdp. USER Passar porte de vacina \u00e9 o meu pau USER Cada filho da puta que apertou 17 tem as mas sujas de sangue USER Com a PF na tua casa tu ficou bravinho n\u00e9 vagabundo? USER Toma no cu \u00e9 vitamina como tu e tua prima. fudeu minha m\u00e3e acabou de chegar em casa e eu acabei de acordar tomei no cu Racism O coment\u00e1rio \u00e9 preconceituoso ou discriminat\u00f3rio com base na ra\u00e7a, cor ou etnia de uma pessoa ou grupo de pessoas. Exemplos: Essas filhas de pedreiro africano e foda N\u00e3o tenho tv colorida pra ficar olhando essa preta nao USER E quantos desses negros s\u00e3o inocentes e quantos s\u00e3o criminosos e bandidos? Te dou absoluta certeza que a maioria dos negros mortos n\u00e3o s\u00e3o inocentes, infelizmente muitas vezes inocentes acabam sendo mortos pela corrup\u00e7\u00e3o na pol\u00edcia USER Sai macaco Essa nega do c\u00e3o quer ser a dona da raz\u00e3o e da situa\u00e7\u00e3o smp \ud83d\ude02\ud83d\ude02\ud83d\ude02 Religious Intolerance O coment\u00e1rio \u00e9 preconceituoso ou discriminat\u00f3rio com base na religi\u00e3o, culto ou pr\u00e1tica religiosa. Exemplos: USER Um governo de Evangelicos. Um governo de Corruptos. Um governo de Criminosos. Uma macumbeira a menos Que diabo de Ogum, por isso que n\u00e3o vai pra frente Sexism O coment\u00e1rio \u00e9 preconceituoso ou discriminat\u00f3rio com base no g\u00eanero ou sexo de uma pessoa ou grupo de pessoas. Exemplos: Se eu fosse o Temer criava o Minist\u00e9rio da Cozinha e da Limpeza e colocava uma mulher, s\u00f3 pro pessoal chorar menos. hahahaha USER Uma calcinha dessa fio-dental dentro da bunda n\u00e3o tem que resistir uma tenta\u00e7\u00e3o dessa? Homem \u00e9 um bicho estranho ao mesmo tmp rid\u00edculo \ud83e\udd23 Resumindo\" Meteu gostoso na safada\" fim da historia! N\u00e3o tem dinheiro q essa mulher,ela \u00e9 terr\u00edvel n\u00e3o vai ter homem q a suporte D\u00e1 uma rola pras feminazi.quem sabe elas param de falar bosta. Xenophobia Discurso de \u00f3dio contra pessoas estrangeiras ou de outras culturas. Exemplos: Quem liga pra judeu kkkk odeio goiano e mineiro rt USER USER nao sei . pra mim todo japones que \u00e9 comunista \u00e9 burro... uma coisa q meu pai ensinou kk esse chinezinho falsificado e um pilantra. N\u00e3o se deixa enganar como ele enganou os que votaram nele. Esse tipo de jumento s\u00f3 se elege uma vez. USER O brasileiro merece o que t\u00e1 passando povo ignorante e sem a menor consci\u00eancia bando de fudido do caralho USER USER PUTAQUEPARIUUUUUU........ESSAS PORCARIAS S\u00d3 ACONTECE NO BRASIL.... RA\u00c7A MALDITA ESSES BRASILEIROS....EXTIN\u00c7AO Nordestino \u00e9 uma desgra\u00e7a cambada de dem\u00f4nio","title":"Which kind of toxicity it has?"},{"location":"pt/annotation/guidelines.html#theres-a-specific-target","text":"Essa pergunta procura identificar se o coment\u00e1rio t\u00f3xico \u00e9 direcionado a um indiv\u00edduo, um grupo ou a outros. Marque apenas se existir um alvo claro do coment\u00e1rio t\u00f3xico. Op\u00e7\u00f5es: Individual : O coment\u00e1rio t\u00f3xico \u00e9 direcionado a um indiv\u00edduo, uma pessoa espec\u00edfica. Group : O coment\u00e1rio t\u00f3xico \u00e9 direcionado a um grupo, uma comunidade. Other : O coment\u00e1rio t\u00f3xico \u00e9 direcionado, por\u00e9m n\u00e3o a um indiv\u00edduo ou grupo espec\u00edficos. Ex.: empresas, eventos, natureza, etc.","title":"There's a specific target?"},{"location":"pt/annotation/guidelines.html#which-words-make-this-text-toxicoffensive","text":"Os toxic spans s\u00e3o os trechos do texto que s\u00e3o identificados como ofensivas, profanas, insultantes, etc. Exemplo: Vai tomar no c@, seu arr0mb@d0 Na frase acima, temos dois grupos de toxic spans que devem ser marcados: vai tomar no c@ e arr0mb@d0 . Um outro exemplo: \"Que exemplo idiota! Voc\u00ea \u00e9 burro demais.\" Na frase acima, a palavra idiota e burro s\u00e3o exemplos de toxic spans . Tamb\u00e9m s\u00e3o consideradas toxic spans conjunto de palavras, por exemplo: vai a merda . Warning N\u00e3o selecione palavras como \"seu\", \"sua\", \"\u00e9\", etc.","title":"Which words make this text toxic/offensive?"},{"location":"pt/annotation/guidelines.html#perguntas-frequentes","text":"","title":"Perguntas frequentes"},{"location":"pt/annotation/guidelines.html#diferen\u00e7a-entre-uma-opini\u00e3o-negativa-e-um-coment\u00e1rio-t\u00f3xico","text":"\u00c9 importante entender a diferen\u00e7a entre uma opini\u00e3o negativa e um coment\u00e1rio t\u00f3xico. Uma opini\u00e3o negativa \u00e9 um texto que exp\u00f5em uma opini\u00e3o ou fato desagrad\u00e1vel com duras palavras, normalmente criticam o trabalho ou a\u00e7\u00e3o de algu\u00e9m, mas sem ferir a dignidade ou a honra de uma pessoa ou grupo. Exemplos: USER Agora \u00e9 \"estupro\" mesmo com a mulher dizendo que quis e gostou. Eu avisei que esse dia ia chegar. Moro conseguiu o que queria: eleger Bolsonaro em troca de um minist\u00e9rio. O que aconteceu depois foi \"briga de quadrilha\", na opini\u00e3o do advogado Kakay. Por tudo isso, ele considera o ex-juiz \"a pr\u00f3pria fake news\". Veja na \u00faltima HASHTAG do ano! HASHTAG URL USER Crime \u00e9 invadir a casa dos outros. USER perder faz parte do esporte. Agora insultar e trazer o racismo pra nossas vidas n\u00e3o, eu n\u00e3o estou de acordo. Um coment\u00e1rio t\u00f3xico extrapola a liberdade de express\u00e3o, normalmente cont\u00e9m palavras ofensivas ou insultantes. Procura denegrir a dignidade ou a honra de uma pessoa ou grupo. Exemplos: O presidente da empresa USER \u00e9 um idiota e n\u00e3o entende o que \u00e9 importante para a empresa. Como se d\u00e1 m\u00eddia pra um safado desses...merece cadeia... A mulher estava vuneravel...em surto... Ficam dando cartaz pra esse canalha... que mundo \u00e9 esse????? Esse cara n\u00e3o sabe jogar pqp","title":"Diferen\u00e7a entre uma opini\u00e3o negativa e um coment\u00e1rio t\u00f3xico"},{"location":"pt/annotation/guidelines.html#erros-ortogr\u00e1ficos-e-formas-de-evitar-a-detec\u00e7\u00e3o-de-toxicidade","text":"Os usu\u00e1rios podem digitar palavras err\u00f4neamente ou substituir caracteres para evitar a detec\u00e7\u00e3o de toxicidade. Neste caso, voc\u00ea deve interpretar as palavras como se fossem escritas corretamente. Exemplos: arr0mb@d0 > arrombado vai tomar no c@ > vai tomar no cu Sobre os toxic spans , voc\u00ea deve seguir com a marca\u00e7\u00e3o da mesma forma, como se estivessem corretas.","title":"Erros ortogr\u00e1ficos e formas de evitar a detec\u00e7\u00e3o de toxicidade"},{"location":"pt/annotation/guidelines.html#o-texto-\u00e9-ileg\u00edvel-o-que-fazer","text":"Se voc\u00ea n\u00e3o conseguir compreender o texto, voc\u00ea pode clicar no bot\u00e3o Skip e pular para o pr\u00f3ximo texto.","title":"O texto \u00e9 ileg\u00edvel, o que fazer?"},{"location":"pt/annotation/guidelines.html#\u00e9-poss\u00edvel-voltar-em-um-coment\u00e1rio-j\u00e1-anotado","text":"N\u00e3o \u00e9 poss\u00edvel voltar durante o processo de anota\u00e7\u00e3o, mas \u00e9 poss\u00edvel filtr\u00e1-lo na tabela inicial. Em caso de d\u00favidas, consulte a ajuda. Tenha cuidado ao submeter um coment\u00e1rio caso n\u00e3o tenha certeza, na d\u00favida clique no bot\u00e3o \"Skip\".","title":"\u00c9 poss\u00edvel voltar em um coment\u00e1rio j\u00e1 anotado?"},{"location":"pt/annotation/index.html","text":"Vis\u00e3o geral da anota\u00e7\u00e3o # Nesta se\u00e7\u00e3o, descreveremos em detalhes o processo de anota\u00e7\u00e3o desenvolvido para o conjunto de dados OLID-BR. O que \u00e9 rotulagem de dados? # A rotulagem de dados, ou anota\u00e7\u00e3o de dados, \u00e9 o processo de identifica\u00e7\u00e3o de dados brutos (imagens, arquivos de texto, v\u00eddeos etc.) ao desenvolver um modelo de aprendizado de m\u00e1quina (ML). Requer a identifica\u00e7\u00e3o de dados brutos com um ou mais r\u00f3tulos significativos e informativos que forne\u00e7am contexto para que um modelo de aprendizado de m\u00e1quina possa aprender com ele. Por exemplo, os r\u00f3tulos podem indicar se uma foto cont\u00e9m um p\u00e1ssaro ou um carro, quais palavras foram pronunciadas em uma grava\u00e7\u00e3o de \u00e1udio ou se um raio-x cont\u00e9m um tumor. A rotulagem de dados \u00e9 necess\u00e1ria para v\u00e1rios casos de uso, incluindo vis\u00e3o computacional, processamento de linguagem natural e reconhecimento de fala. 1 2 Abordagens de rotulagem de dados # A literatura apresenta v\u00e1rias abordagens para rotulagem de dados. No projeto OLID-BR, usamos a seguinte abordagem: Internal labeling : o uso de especialistas internos em ci\u00eancia de dados simplifica o rastreamento, oferece maior precis\u00e3o e aumenta a qualidade. No entanto, essa abordagem normalmente requer mais tempo e favorece grandes empresas com recursos extensos. Terceiriza\u00e7\u00e3o : Esta pode ser a escolha ideal para projetos tempor\u00e1rios de alto n\u00edvel, mas desenvolver e gerenciar um fluxo de trabalho orientado a freelance tamb\u00e9m pode ser demorado. Embora as plataformas de freelancers forne\u00e7am informa\u00e7\u00f5es abrangentes sobre os candidatos para facilitar o processo de verifica\u00e7\u00e3o, a contrata\u00e7\u00e3o de equipes de rotulagem de dados gerenciadas fornece uma equipe pr\u00e9-avaliada e ferramentas de rotulagem de dados pr\u00e9-criadas. Na primeira itera\u00e7\u00e3o do processo de anota\u00e7\u00e3o, usaremos a abordagem *internal labeling , ou seja, o autor do conjunto de dados anotou os dados. Tamb\u00e9m tivemos um volunt\u00e1rio que nos ajudou a rotular os dados. Nas pr\u00f3ximas itera\u00e7\u00f5es, usaremos a abordagem de outsourcing , tr\u00eas trabalhadores contratados rotular\u00e3o os dados. O que \u00e9 rotulagem de dados? - AWS \u21a9 O que \u00e9 rotulagem de dados? - IBM \u21a9","title":"Overview"},{"location":"pt/annotation/index.html#vis\u00e3o-geral-da-anota\u00e7\u00e3o","text":"Nesta se\u00e7\u00e3o, descreveremos em detalhes o processo de anota\u00e7\u00e3o desenvolvido para o conjunto de dados OLID-BR.","title":"Vis\u00e3o geral da anota\u00e7\u00e3o"},{"location":"pt/annotation/index.html#o-que-\u00e9-rotulagem-de-dados","text":"A rotulagem de dados, ou anota\u00e7\u00e3o de dados, \u00e9 o processo de identifica\u00e7\u00e3o de dados brutos (imagens, arquivos de texto, v\u00eddeos etc.) ao desenvolver um modelo de aprendizado de m\u00e1quina (ML). Requer a identifica\u00e7\u00e3o de dados brutos com um ou mais r\u00f3tulos significativos e informativos que forne\u00e7am contexto para que um modelo de aprendizado de m\u00e1quina possa aprender com ele. Por exemplo, os r\u00f3tulos podem indicar se uma foto cont\u00e9m um p\u00e1ssaro ou um carro, quais palavras foram pronunciadas em uma grava\u00e7\u00e3o de \u00e1udio ou se um raio-x cont\u00e9m um tumor. A rotulagem de dados \u00e9 necess\u00e1ria para v\u00e1rios casos de uso, incluindo vis\u00e3o computacional, processamento de linguagem natural e reconhecimento de fala. 1 2","title":"O que \u00e9 rotulagem de dados?"},{"location":"pt/annotation/index.html#abordagens-de-rotulagem-de-dados","text":"A literatura apresenta v\u00e1rias abordagens para rotulagem de dados. No projeto OLID-BR, usamos a seguinte abordagem: Internal labeling : o uso de especialistas internos em ci\u00eancia de dados simplifica o rastreamento, oferece maior precis\u00e3o e aumenta a qualidade. No entanto, essa abordagem normalmente requer mais tempo e favorece grandes empresas com recursos extensos. Terceiriza\u00e7\u00e3o : Esta pode ser a escolha ideal para projetos tempor\u00e1rios de alto n\u00edvel, mas desenvolver e gerenciar um fluxo de trabalho orientado a freelance tamb\u00e9m pode ser demorado. Embora as plataformas de freelancers forne\u00e7am informa\u00e7\u00f5es abrangentes sobre os candidatos para facilitar o processo de verifica\u00e7\u00e3o, a contrata\u00e7\u00e3o de equipes de rotulagem de dados gerenciadas fornece uma equipe pr\u00e9-avaliada e ferramentas de rotulagem de dados pr\u00e9-criadas. Na primeira itera\u00e7\u00e3o do processo de anota\u00e7\u00e3o, usaremos a abordagem *internal labeling , ou seja, o autor do conjunto de dados anotou os dados. Tamb\u00e9m tivemos um volunt\u00e1rio que nos ajudou a rotular os dados. Nas pr\u00f3ximas itera\u00e7\u00f5es, usaremos a abordagem de outsourcing , tr\u00eas trabalhadores contratados rotular\u00e3o os dados. O que \u00e9 rotulagem de dados? - AWS \u21a9 O que \u00e9 rotulagem de dados? - IBM \u21a9","title":"Abordagens de rotulagem de dados"},{"location":"pt/annotation/inter-rater-reliability.html","text":"Confiabilidade entre avaliadores # A confiabilidade entre avaliadores \u00e9 uma parte importante do processo de avalia\u00e7\u00e3o da qualidade das anota\u00e7\u00f5es. Nesta se\u00e7\u00e3o, apresentaremos as m\u00e9tricas e a metodologia utilizada neste processo. Cada coment\u00e1rio foi marcado por tr\u00eas avaliadores diferentes. Portanto, precisamos considerar m\u00e9tricas que suportem mais de dois avaliadores. Como definimos as m\u00e9tricas? # No Handbook of Inter-Rater Reliability 1 , Gwet, K.L. prop\u00f4s um diagrama que ajuda a escolher o coeficiente de concord\u00e2ncia correto para cada estudo de confiabilidade entre avaliadores. graph TD A[Which Agreement Coefficient Should you use?] --> B{Nominal Ratings?} B -->|No| D{Ratio Ratings?} B -->|Yes| C[Use Unweighted Coefficients] D -->|Yes| E{Predetermined<br>Rating Values?} D -->|No| F{Interval Ratings?} F -->|\"No (these are ordinal ratings)\"| H[Use Weighted Coefficients.<br>Ordinal Weights Only.] F -->|Yes| G{Predetermined<br>Rating Values?} E -->|Yes| I[Use Weighted Coefficients.<br>All Weights Can be Used.] E -->|No| J[Use Intraclass Correlation Coefficients] G -->|Yes| K[Use Weighted Coefficients.<br>Quadratic, Linear, and Radical Weights can be used] G -->|No| J[Use Intraclass Correlation Coefficients] Todas as nossas classifica\u00e7\u00f5es s\u00e3o do tipo nominal , ent\u00e3o veremos Coeficientes n\u00e3o ponderados propostos por Gwet, K.L. no livro. Percent Agreement ( \\(p_a\\) ): N\u00e3o corrigido para concord\u00e2ncia por acaso. Fleiss' Generalized Kappa ( \\(\\hat{K}_F\\) ): Bom \u00e0s vezes - Exposto a graves paradoxos. Conger's Generalized Kappa ( \\(\\hat{K}_C\\) ): Bom \u00e0s vezes - Exposto a paradoxos severos. Gwet's AC 1 ( \\(\\hat{K}_G\\) ): Mais resistente a paradoxos do que coeficientes alternativos. Brennan-Prediger ( \\(\\hat{K}_{BP}\\) ): Mais resistente a paradoxos do que coeficientes alternativos. Krippendorff's Alpha ( \\(\\hat{\\alpha}_K\\) ) Semelhante ao Kappa Generalizado de Fleiss - Diferen\u00e7as menores. Di Eugenio & Glass (2004) 7 argumentam que o uso de v\u00e1rias m\u00e9tricas de confiabilidade com diferentes m\u00e9todos para calcular \\(p_{(A_e)}\\) pode ser mais revelador do que uma \u00fanica m\u00e9trica. Assim, selecionaremos uma s\u00e9rie de m\u00e9tricas para usar em nossa an\u00e1lise. A simplicidade de Percent Agreement # Como a Percent Agreement \u00e9 calculada como uma m\u00e9dia entre as observa\u00e7\u00f5es, ela pode ocultar importantes desacordos. \"Averages over all categories of a variable\u2026 hide unreliable categories behind reliable ones\u201d - Krippendorff 5 \"when all coders use only one category, there is no variation and hence no evidence of reliability\" - Krippendorff 6 Para remediar isso, ele sugere que, em alguns casos, \u00e9 apropriado realizar v\u00e1rios testes dentro de uma \u00fanica vari\u00e1vel. \"All distinctions that matter should be tested for their reliability\" - Krippendorff 6 Os paradoxos do Kappa # Kappa geralmente produz coeficientes inesperadamente baixos quando comparados com a porcentagem de concord\u00e2ncia. Este problema tem sido referido na literatura como os paradoxos Kappa. Feinstein e Cicchetti (1990) 4 fornecem uma explica\u00e7\u00e3o detalhada sobre dois desses paradoxos. Esses autores fizeram as duas seguintes afirma\u00e7\u00f5es: \"O primeiro paradoxo de \\(k\\) (Kappa) \u00e9 que se \\(p_e\\) (a porcentagem de concord\u00e2ncia) for grande, o processo de corre\u00e7\u00e3o pode converter um valor relativamente alto de \\(p_0\\) em um valor relativamente baixo de \\(k\\) \" (Feinstein & Cicchetti, (1990, p. 544) 4 \"O segundo paradoxo ocorre quando totais marginais desbalanceados produzem valores maiores de \\(k\\) do que totais mais balanceados.\" (Feinstein & Cicchetti, (1990, p. 545) 4 Portanto, usaremos Percent Agreement , Gwet's AC 1 e Krippendorff's Alpha como coeficientes para avaliar a qualidade das anota\u00e7\u00f5es. Coeficientes selecionados # Percent agreement # O Percent agreement (percentual de acordo) \u00e9 uma medida do acordo entre os avaliadores. \u00c9 calculado dividindo o n\u00famero de coment\u00e1rios concordantes pelo n\u00famero total de coment\u00e1rios da seguinte forma: \\[ p_a = \\frac{n_{\\text{concordando}}}{n_{\\text{total}}} \\] Interpreta\u00e7\u00e3o Ruim Leve Moderado Substancial Quase perfeito 0,01 - 0,20 0,21 - 0,40 0,41 - 0,60 0,61 - 0,80 0,81 - 0,99 Gwet's AC 1 # Gwet 2 recomendou um coeficiente de concord\u00e2ncia chamado AC 1 , que foi desenvolvido para superar muitas das limita\u00e7\u00f5es associadas aos coeficientes de concord\u00e2ncia baseados em Kappa. A AC 1 de Gwet \u00e9 baseada na mesma equa\u00e7\u00e3o percentual de concord\u00e2ncia que Kappa, mas com um novo percentual de chance de concord\u00e2ncia como \\(p_e\\) . O Gwet's AC 1 coefficient, denotado aqui por \\(\\hat{K}_G\\) , \u00e9 formalmente definido da seguinte forma: \\[ \\widehat{\\kappa}_{\\mathrm{G}}=\\frac{p_{a}-p_{e}}{1-p_{e}}, \\text { onde } p_{e}=\\frac{ 1}{q(q-1)} \\sum_{k=1}^{q} \\hat{\\pi}_{k}\\left(1-\\hat{\\pi}_{k}\\right) \\] onde \\(\\hat{\\pi}_{k}\\) \u00e9 dado pela seguinte equa\u00e7\u00e3o: \\[ \\hat{\\pi}_{k}=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{r_{i k}}{r_{i}} \\] Interpreta\u00e7\u00e3o Ruim Leve Moderado Substancial Quase perfeito < 0,20 0,21 - 0,40 0,41 - 0,60 0,61 - 0,80 0,81 - 0,99 Krippendorff's Alpha # O Krippendorff's Alpha 3 \u00e9 uma estat\u00edstica vers\u00e1til que avalia a concord\u00e2ncia alcan\u00e7ada entre observadores que categorizam, avaliam ou medem um determinado conjunto de objetos em termos dos valores de uma vari\u00e1vel. Ele generaliza v\u00e1rios coeficientes de concord\u00e2ncia especializados aceitando qualquer n\u00famero de observadores, sendo aplic\u00e1vel a n\u00edveis de medi\u00e7\u00e3o nominais, ordinais, intervalares e de raz\u00e3o, sendo capaz de lidar com dados ausentes e sendo corrigido para pequenos tamanhos de amostra. O coeficiente de Krippendorff \u00e9 calculado da seguinte forma: \\[ \\widehat{\\alpha}_{\\mathrm{K}}=\\frac{p_{a}^{\\prime}-p_{e}}{1-p_{e}}, \\text { onde } p_{e }=\\sum_{k=1}^{q} \\hat{\\pi}_{k}^{2} \\] onde \\(p_{a}\\) \u00e9 dado por: \\[ p_{a}=\\frac{1}{n^{\\prime}} \\sum_{i=1}^{n^{\\prime}} \\sum_{k=1}^{q} \\frac{r_{ i k}\\left(r_{i k}-1\\right)}{r_{i}\\left(r_{i}-1\\right)} \\] e \\(p_{a}^{\\prime}\\) \u00e9 dado por: \\[ p_{a}^{\\prime}=\\left(1-\\varepsilon_{n}\\right) p_{a}+\\varepsilon_{n} \\] Interpreta\u00e7\u00e3o Ruim Leve Regular Moderado Substancial Quase perfeito <0 0,01 - 0,20 0,21 - 0,40 0,41 - 0,60 0,61 - 0,80 0,81 - 0,99 Gwet, Kilem L. Manual de confiabilidade entre avaliadores: O guia definitivo para medir a extens\u00e3o da concord\u00e2ncia entre os avaliadores. Advanced Analytics, LLC, 2014. \u21a9 Gwet, Kilem Li. \"Computando a confiabilidade entre avaliadores e sua varia\u00e7\u00e3o na presen\u00e7a de alta concord\u00e2ncia.\" British Journal of Mathematical and Statistical Psychology 61.1 (2008): 29-48. \u21a9 Hayes, Andrew F. e Klaus Krippendorff. \"Atendendo ao pedido de uma medida de confiabilidade padr\u00e3o para codifica\u00e7\u00e3o de dados.\" M\u00e9todos e medidas de comunica\u00e7\u00e3o 1.1 (2007): 77-89. \u21a9 Feinstein, Alvan R., and Domenic V. Cicchetti. \"High agreement but low kappa: I. The problems of two paradoxes.\" Journal of clinical epidemiology 43.6 (1990): 543-549. \u21a9 \u21a9 \u21a9 Krippendorff, Klaus. Content analysis: An introduction to its methodology. Sage publications, 2018. \u21a9 Krippendorff, K. \"Some Common Misconceptions and Recommendations.\" Human Communication Research 30 (2004): 411-433. \u21a9 \u21a9 Eugenio, Barbara Di, and Michael Glass. \"The kappa statistic: A second look.\" Computational linguistics 30.1 (2004): 95-101. \u21a9","title":"Inter-Rater Reliability"},{"location":"pt/annotation/inter-rater-reliability.html#confiabilidade-entre-avaliadores","text":"A confiabilidade entre avaliadores \u00e9 uma parte importante do processo de avalia\u00e7\u00e3o da qualidade das anota\u00e7\u00f5es. Nesta se\u00e7\u00e3o, apresentaremos as m\u00e9tricas e a metodologia utilizada neste processo. Cada coment\u00e1rio foi marcado por tr\u00eas avaliadores diferentes. Portanto, precisamos considerar m\u00e9tricas que suportem mais de dois avaliadores.","title":"Confiabilidade entre avaliadores"},{"location":"pt/annotation/inter-rater-reliability.html#como-definimos-as-m\u00e9tricas","text":"No Handbook of Inter-Rater Reliability 1 , Gwet, K.L. prop\u00f4s um diagrama que ajuda a escolher o coeficiente de concord\u00e2ncia correto para cada estudo de confiabilidade entre avaliadores. graph TD A[Which Agreement Coefficient Should you use?] --> B{Nominal Ratings?} B -->|No| D{Ratio Ratings?} B -->|Yes| C[Use Unweighted Coefficients] D -->|Yes| E{Predetermined<br>Rating Values?} D -->|No| F{Interval Ratings?} F -->|\"No (these are ordinal ratings)\"| H[Use Weighted Coefficients.<br>Ordinal Weights Only.] F -->|Yes| G{Predetermined<br>Rating Values?} E -->|Yes| I[Use Weighted Coefficients.<br>All Weights Can be Used.] E -->|No| J[Use Intraclass Correlation Coefficients] G -->|Yes| K[Use Weighted Coefficients.<br>Quadratic, Linear, and Radical Weights can be used] G -->|No| J[Use Intraclass Correlation Coefficients] Todas as nossas classifica\u00e7\u00f5es s\u00e3o do tipo nominal , ent\u00e3o veremos Coeficientes n\u00e3o ponderados propostos por Gwet, K.L. no livro. Percent Agreement ( \\(p_a\\) ): N\u00e3o corrigido para concord\u00e2ncia por acaso. Fleiss' Generalized Kappa ( \\(\\hat{K}_F\\) ): Bom \u00e0s vezes - Exposto a graves paradoxos. Conger's Generalized Kappa ( \\(\\hat{K}_C\\) ): Bom \u00e0s vezes - Exposto a paradoxos severos. Gwet's AC 1 ( \\(\\hat{K}_G\\) ): Mais resistente a paradoxos do que coeficientes alternativos. Brennan-Prediger ( \\(\\hat{K}_{BP}\\) ): Mais resistente a paradoxos do que coeficientes alternativos. Krippendorff's Alpha ( \\(\\hat{\\alpha}_K\\) ) Semelhante ao Kappa Generalizado de Fleiss - Diferen\u00e7as menores. Di Eugenio & Glass (2004) 7 argumentam que o uso de v\u00e1rias m\u00e9tricas de confiabilidade com diferentes m\u00e9todos para calcular \\(p_{(A_e)}\\) pode ser mais revelador do que uma \u00fanica m\u00e9trica. Assim, selecionaremos uma s\u00e9rie de m\u00e9tricas para usar em nossa an\u00e1lise.","title":"Como definimos as m\u00e9tricas?"},{"location":"pt/annotation/inter-rater-reliability.html#a-simplicidade-de-percent-agreement","text":"Como a Percent Agreement \u00e9 calculada como uma m\u00e9dia entre as observa\u00e7\u00f5es, ela pode ocultar importantes desacordos. \"Averages over all categories of a variable\u2026 hide unreliable categories behind reliable ones\u201d - Krippendorff 5 \"when all coders use only one category, there is no variation and hence no evidence of reliability\" - Krippendorff 6 Para remediar isso, ele sugere que, em alguns casos, \u00e9 apropriado realizar v\u00e1rios testes dentro de uma \u00fanica vari\u00e1vel. \"All distinctions that matter should be tested for their reliability\" - Krippendorff 6","title":"A simplicidade de Percent Agreement"},{"location":"pt/annotation/inter-rater-reliability.html#os-paradoxos-do-kappa","text":"Kappa geralmente produz coeficientes inesperadamente baixos quando comparados com a porcentagem de concord\u00e2ncia. Este problema tem sido referido na literatura como os paradoxos Kappa. Feinstein e Cicchetti (1990) 4 fornecem uma explica\u00e7\u00e3o detalhada sobre dois desses paradoxos. Esses autores fizeram as duas seguintes afirma\u00e7\u00f5es: \"O primeiro paradoxo de \\(k\\) (Kappa) \u00e9 que se \\(p_e\\) (a porcentagem de concord\u00e2ncia) for grande, o processo de corre\u00e7\u00e3o pode converter um valor relativamente alto de \\(p_0\\) em um valor relativamente baixo de \\(k\\) \" (Feinstein & Cicchetti, (1990, p. 544) 4 \"O segundo paradoxo ocorre quando totais marginais desbalanceados produzem valores maiores de \\(k\\) do que totais mais balanceados.\" (Feinstein & Cicchetti, (1990, p. 545) 4 Portanto, usaremos Percent Agreement , Gwet's AC 1 e Krippendorff's Alpha como coeficientes para avaliar a qualidade das anota\u00e7\u00f5es.","title":"Os paradoxos do Kappa"},{"location":"pt/annotation/inter-rater-reliability.html#coeficientes-selecionados","text":"","title":"Coeficientes selecionados"},{"location":"pt/annotation/inter-rater-reliability.html#percent-agreement","text":"O Percent agreement (percentual de acordo) \u00e9 uma medida do acordo entre os avaliadores. \u00c9 calculado dividindo o n\u00famero de coment\u00e1rios concordantes pelo n\u00famero total de coment\u00e1rios da seguinte forma: \\[ p_a = \\frac{n_{\\text{concordando}}}{n_{\\text{total}}} \\] Interpreta\u00e7\u00e3o Ruim Leve Moderado Substancial Quase perfeito 0,01 - 0,20 0,21 - 0,40 0,41 - 0,60 0,61 - 0,80 0,81 - 0,99","title":"Percent agreement"},{"location":"pt/annotation/inter-rater-reliability.html#gwets-ac1","text":"Gwet 2 recomendou um coeficiente de concord\u00e2ncia chamado AC 1 , que foi desenvolvido para superar muitas das limita\u00e7\u00f5es associadas aos coeficientes de concord\u00e2ncia baseados em Kappa. A AC 1 de Gwet \u00e9 baseada na mesma equa\u00e7\u00e3o percentual de concord\u00e2ncia que Kappa, mas com um novo percentual de chance de concord\u00e2ncia como \\(p_e\\) . O Gwet's AC 1 coefficient, denotado aqui por \\(\\hat{K}_G\\) , \u00e9 formalmente definido da seguinte forma: \\[ \\widehat{\\kappa}_{\\mathrm{G}}=\\frac{p_{a}-p_{e}}{1-p_{e}}, \\text { onde } p_{e}=\\frac{ 1}{q(q-1)} \\sum_{k=1}^{q} \\hat{\\pi}_{k}\\left(1-\\hat{\\pi}_{k}\\right) \\] onde \\(\\hat{\\pi}_{k}\\) \u00e9 dado pela seguinte equa\u00e7\u00e3o: \\[ \\hat{\\pi}_{k}=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{r_{i k}}{r_{i}} \\] Interpreta\u00e7\u00e3o Ruim Leve Moderado Substancial Quase perfeito < 0,20 0,21 - 0,40 0,41 - 0,60 0,61 - 0,80 0,81 - 0,99","title":"Gwet's AC1"},{"location":"pt/annotation/inter-rater-reliability.html#krippendorffs-alpha","text":"O Krippendorff's Alpha 3 \u00e9 uma estat\u00edstica vers\u00e1til que avalia a concord\u00e2ncia alcan\u00e7ada entre observadores que categorizam, avaliam ou medem um determinado conjunto de objetos em termos dos valores de uma vari\u00e1vel. Ele generaliza v\u00e1rios coeficientes de concord\u00e2ncia especializados aceitando qualquer n\u00famero de observadores, sendo aplic\u00e1vel a n\u00edveis de medi\u00e7\u00e3o nominais, ordinais, intervalares e de raz\u00e3o, sendo capaz de lidar com dados ausentes e sendo corrigido para pequenos tamanhos de amostra. O coeficiente de Krippendorff \u00e9 calculado da seguinte forma: \\[ \\widehat{\\alpha}_{\\mathrm{K}}=\\frac{p_{a}^{\\prime}-p_{e}}{1-p_{e}}, \\text { onde } p_{e }=\\sum_{k=1}^{q} \\hat{\\pi}_{k}^{2} \\] onde \\(p_{a}\\) \u00e9 dado por: \\[ p_{a}=\\frac{1}{n^{\\prime}} \\sum_{i=1}^{n^{\\prime}} \\sum_{k=1}^{q} \\frac{r_{ i k}\\left(r_{i k}-1\\right)}{r_{i}\\left(r_{i}-1\\right)} \\] e \\(p_{a}^{\\prime}\\) \u00e9 dado por: \\[ p_{a}^{\\prime}=\\left(1-\\varepsilon_{n}\\right) p_{a}+\\varepsilon_{n} \\] Interpreta\u00e7\u00e3o Ruim Leve Regular Moderado Substancial Quase perfeito <0 0,01 - 0,20 0,21 - 0,40 0,41 - 0,60 0,61 - 0,80 0,81 - 0,99 Gwet, Kilem L. Manual de confiabilidade entre avaliadores: O guia definitivo para medir a extens\u00e3o da concord\u00e2ncia entre os avaliadores. Advanced Analytics, LLC, 2014. \u21a9 Gwet, Kilem Li. \"Computando a confiabilidade entre avaliadores e sua varia\u00e7\u00e3o na presen\u00e7a de alta concord\u00e2ncia.\" British Journal of Mathematical and Statistical Psychology 61.1 (2008): 29-48. \u21a9 Hayes, Andrew F. e Klaus Krippendorff. \"Atendendo ao pedido de uma medida de confiabilidade padr\u00e3o para codifica\u00e7\u00e3o de dados.\" M\u00e9todos e medidas de comunica\u00e7\u00e3o 1.1 (2007): 77-89. \u21a9 Feinstein, Alvan R., and Domenic V. Cicchetti. \"High agreement but low kappa: I. The problems of two paradoxes.\" Journal of clinical epidemiology 43.6 (1990): 543-549. \u21a9 \u21a9 \u21a9 Krippendorff, Klaus. Content analysis: An introduction to its methodology. Sage publications, 2018. \u21a9 Krippendorff, K. \"Some Common Misconceptions and Recommendations.\" Human Communication Research 30 (2004): 411-433. \u21a9 \u21a9 Eugenio, Barbara Di, and Michael Glass. \"The kappa statistic: A second look.\" Computational linguistics 30.1 (2004): 95-101. \u21a9","title":"Krippendorff's Alpha"},{"location":"pt/annotation/iterations.html","text":"Itera\u00e7\u00f5es # Decidimos trabalhar em itera\u00e7\u00f5es porque nos permite validar e melhorar o processo de anota\u00e7\u00e3o e as diretrizes. Cada itera\u00e7\u00e3o tem suas pr\u00f3prias metas e objetivos. Itera\u00e7\u00e3o 1 # Nesta itera\u00e7\u00e3o, nosso objetivo foi validar e refinar nosso processo de anota\u00e7\u00e3o. Foi a primeira vez que aplicamos o processo de anota\u00e7\u00e3o. Dois anotadores rotularam os dados. O primeiro anotador era um volunt\u00e1rio, o segundo era o autor do conjunto de dados. O volunt\u00e1rio forneceu feedbacks construtivos para ajustar o processo de anota\u00e7\u00e3o. Os dados rotulados pelo pesquisador predominaram sob os r\u00f3tulos do volunt\u00e1rio, pois o pesquisador corrigiu alguns erros no processo de anota\u00e7\u00e3o. Confiabilidade entre avaliadores # Nesta itera\u00e7\u00e3o, n\u00e3o geramos a an\u00e1lise de confiabilidade entre avaliadores porque fizemos algumas altera\u00e7\u00f5es e alinhamentos durante a itera\u00e7\u00e3o. Profiling Report Itera\u00e7\u00e3o 2 # Na segunda itera\u00e7\u00e3o, introduzimos trabalhadores contratados para fazer as anota\u00e7\u00f5es. Os anotadores foram treinados pelo autor do conjunto de dados conforme descrito em Anotadores qualificados . Confiabilidade entre avaliadores # Conforme descrito na se\u00e7\u00e3o Inter-Rater Reliability , avaliamos a confiabilidade dos anotadores usando diferentes coeficientes. Tamb\u00e9m abordamos a an\u00e1lise considerando como um problema multi-label ou v\u00e1rios problemas bin\u00e1rios. Problem Multi-Label Para todos os nossos r\u00f3tulos de toxicidade calculamos o Krippendorff's alpha (usando MASI distance) e o Percent Agreement . Krippendorff's alpha : 0,1962 (pequena concord\u00e2ncia) Percent Agreement : 0,1877 Problema bin\u00e1rio Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0,7277 0,0595 0,7750 is_targeted 0,1610 -0,1348 -0,1029 [1] targeted_type 0,0641 0,2461 0,4978 [1] toxic_spans 0,1220 0,2709 N/A health 0,9760 0,0447 0,9837 ideology 0,7647 0,3019 0,7976 [3] insult 0,4713 0,0895 0,425 [3] lgbtqphobia 0,9453 0,5583 0,9603 other_lifestyle 0,9860 0,0824 0,9906 physical_aspects 0,9463 0,3272 0,9622 profanity_obscene 0,6837 0,0850 0,726 [3] racism 0,9750 0,2564 0,9829 religious_intolerance 1,0 1,0 1,0 [2] sexism 0,8753 0,1721 0,9076 xenophobia 0,9673 0,0732 0,9777 Coment\u00e1rios # [1] A pergunta que originou os recursos is_targeted e targeted_type s\u00e3o opcionais, devem ser marcadas somente se o texto for direcionado. Parece que o anotador 126 n\u00e3o entendeu e marcou tudo como direcionado. [2] N\u00e3o temos nenhum texto marcado com religious_intolerance por nossos anotadores. [3] Temos anota\u00e7\u00f5es mais inconsistentes nos r\u00f3tulos idelogy , insult e profanity_obscene (desconsiderando [1] [2]) Conclus\u00f5es # Tivemos um mal entendimento das diretrizes de anota\u00e7\u00e3o por um dos anotadores, o que acabou gerando inconsist\u00eancia nos r\u00f3tulos is_targeted e targeted_type . Sobre os r\u00f3tulos de toxicidade ( toxicity labels ), percebemos que s\u00e3o raros os casos em que todos os anotadores concordam com a anota\u00e7\u00e3o, levando a um alto \u00edndice de discord\u00e2ncia e consequentemente a um baixo valor de Krippendorff's alpha. Os r\u00f3tulos que apresentaram maior discord\u00e2ncia s\u00e3o insult , ideology e profanity_obscene . Iremos repassar as diretrizes de anota\u00e7\u00e3o com os anotadores para a pr\u00f3xima itera\u00e7\u00e3o. Profiling Report Itera\u00e7\u00e3o 3 # Na terceira itera\u00e7\u00e3o, n\u00f3s retreinamos os anotadores com base nas li\u00e7\u00f5es aprendidas na itera\u00e7\u00e3o anterior. Tamb\u00e9m substitu\u00edmos um dos anotadores contratados. Os anotadores foram solicitados a rotular mais 3.000 coment\u00e1rios. Inter-Rater Reliability # Como descrito na se\u00e7\u00e3o Inter-Rater Reliability , avaliamos a confiabilidade dos anotadores usando diferentes coeficientes. Para avaliar os r\u00f3tulos de toxicidade, temos duas poss\u00edveis abordagens: Multi-Label ou Binary. Multi-Label Problem Para todos os nossos r\u00f3tulos de toxicidade calculamos o Krippendorff's alpha (usando MASI distance) e o Percent Agreement . Krippendorff's alpha : 0,4653 (concord\u00e2ncia moderada) Percent Agreement : 0,2758 Binary Problem Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0.6509 0.1777 0.6754 is_targeted 0.3551 0.1072 0.1709 targeted_type 0.1975 0.4887 0.6300 toxic_spans 0.1757 0.4427 N/A health 0.9700 0.2641 0.9794 ideology 0.8670 0.4728 0.8934 insult 0.5488 0.3317 0.4531 lgbtqphobia 0.9613 0.6393 0.9722 other_lifestyle 0.9787 0.4683 0.9854 physical_aspects 0.9560 0.4160 0.9691 profanity_obscene 0.7089 0.4894 0.6870 racism 0.9913 0.3781 0.9942 religious_intolerance 1.0 1.0 1.0 1 sexism 0.9550 0.1566 0.9689 xenophobia 0.9847 0.2980 0.9896 Coment\u00e1rios # [1] N\u00e3o temos nenhum texto marcado com religious_intolerance por nossos anotadores. Conclus\u00f5es # In this iteration, we had more consistent annotations which led to a better agreement between the annotators. Krippendorff's alpha for toxicity labels increased from 0.1962 to 0.4653 . Nesta itera\u00e7\u00e3o, tivemos anota\u00e7\u00f5es mais consistentes que levaram a uma melhor concord\u00e2ncia entre os anotadores. O Krippendorff's alpha para r\u00f3tulos de toxicidade aumentou de 0,1962 para 0,4653 . Profiling Report Itera\u00e7\u00e3o 4 # Na quarta itera\u00e7\u00e3o, solicitamos aos anotadores que rotulassem um n\u00famero maior de textos seguindo as mesmas diretrizes das itera\u00e7\u00f5es anteriores. Fixamos o prazo para 4 de outubro de 2022 (+- um m\u00eas). Inter-Rater Reliability # Como descrito na se\u00e7\u00e3o Inter-Rater Reliability , avaliamos a confiabilidade dos anotadores usando diferentes coeficientes. Para avaliar os r\u00f3tulos de toxicidade, temos duas poss\u00edveis abordagens: Multi-Label ou Binary. Multi-Label Problem Para todos os nossos r\u00f3tulos de toxicidade calculamos o Krippendorff's alpha (usando MASI distance) e o Percent Agreement . Krippendorff's alpha : 0,4424 (concord\u00e2ncia moderada) Percent Agreement : 0,2769 Binary Problem Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0.5847 0.2174 0.5716 is_targeted 0.4253 0.1825 0.2790 targeted_type 0.2223 0.4840 0.5756 toxic_spans 0.2249 0.4760 (MASI distance) N/A health 0.9800 0.1424 0.9865 ideology 0.8531 0.2909 0.8863 insult 0.4938 0.2923 0.3549 lgbtqphobia 0.9550 0.4901 0.9681 other_lifestyle 0.9705 0.2239 0.9798 physical_aspects 0.9570 0.3623 0.9700 profanity_obscene 0.7436 0.5530 0.7233 racism 0.9940 0.2481 0.9960 religious_intolerance 1.0 1.0 1.0 1 sexism 0.9640 0.1880 0.9753 xenophobia 0.9905 0.3840 0.9936 Coment\u00e1rios # [1] N\u00e3o temos nenhum texto marcado com religious_intolerance por nossos anotadores. Conclus\u00f5es # Assim como na itera\u00e7\u00e3o anterior, tivemos anota\u00e7\u00f5es mais consistentes que levaram a uma melhor concord\u00e2ncia entre os anotadores. Profiling Report","title":"Iterations"},{"location":"pt/annotation/iterations.html#itera\u00e7\u00f5es","text":"Decidimos trabalhar em itera\u00e7\u00f5es porque nos permite validar e melhorar o processo de anota\u00e7\u00e3o e as diretrizes. Cada itera\u00e7\u00e3o tem suas pr\u00f3prias metas e objetivos.","title":"Itera\u00e7\u00f5es"},{"location":"pt/annotation/iterations.html#itera\u00e7\u00e3o-1","text":"Nesta itera\u00e7\u00e3o, nosso objetivo foi validar e refinar nosso processo de anota\u00e7\u00e3o. Foi a primeira vez que aplicamos o processo de anota\u00e7\u00e3o. Dois anotadores rotularam os dados. O primeiro anotador era um volunt\u00e1rio, o segundo era o autor do conjunto de dados. O volunt\u00e1rio forneceu feedbacks construtivos para ajustar o processo de anota\u00e7\u00e3o. Os dados rotulados pelo pesquisador predominaram sob os r\u00f3tulos do volunt\u00e1rio, pois o pesquisador corrigiu alguns erros no processo de anota\u00e7\u00e3o.","title":"Itera\u00e7\u00e3o 1"},{"location":"pt/annotation/iterations.html#confiabilidade-entre-avaliadores","text":"Nesta itera\u00e7\u00e3o, n\u00e3o geramos a an\u00e1lise de confiabilidade entre avaliadores porque fizemos algumas altera\u00e7\u00f5es e alinhamentos durante a itera\u00e7\u00e3o. Profiling Report","title":"Confiabilidade entre avaliadores"},{"location":"pt/annotation/iterations.html#itera\u00e7\u00e3o-2","text":"Na segunda itera\u00e7\u00e3o, introduzimos trabalhadores contratados para fazer as anota\u00e7\u00f5es. Os anotadores foram treinados pelo autor do conjunto de dados conforme descrito em Anotadores qualificados .","title":"Itera\u00e7\u00e3o 2"},{"location":"pt/annotation/iterations.html#confiabilidade-entre-avaliadores_1","text":"Conforme descrito na se\u00e7\u00e3o Inter-Rater Reliability , avaliamos a confiabilidade dos anotadores usando diferentes coeficientes. Tamb\u00e9m abordamos a an\u00e1lise considerando como um problema multi-label ou v\u00e1rios problemas bin\u00e1rios. Problem Multi-Label Para todos os nossos r\u00f3tulos de toxicidade calculamos o Krippendorff's alpha (usando MASI distance) e o Percent Agreement . Krippendorff's alpha : 0,1962 (pequena concord\u00e2ncia) Percent Agreement : 0,1877 Problema bin\u00e1rio Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0,7277 0,0595 0,7750 is_targeted 0,1610 -0,1348 -0,1029 [1] targeted_type 0,0641 0,2461 0,4978 [1] toxic_spans 0,1220 0,2709 N/A health 0,9760 0,0447 0,9837 ideology 0,7647 0,3019 0,7976 [3] insult 0,4713 0,0895 0,425 [3] lgbtqphobia 0,9453 0,5583 0,9603 other_lifestyle 0,9860 0,0824 0,9906 physical_aspects 0,9463 0,3272 0,9622 profanity_obscene 0,6837 0,0850 0,726 [3] racism 0,9750 0,2564 0,9829 religious_intolerance 1,0 1,0 1,0 [2] sexism 0,8753 0,1721 0,9076 xenophobia 0,9673 0,0732 0,9777","title":"Confiabilidade entre avaliadores"},{"location":"pt/annotation/iterations.html#coment\u00e1rios","text":"[1] A pergunta que originou os recursos is_targeted e targeted_type s\u00e3o opcionais, devem ser marcadas somente se o texto for direcionado. Parece que o anotador 126 n\u00e3o entendeu e marcou tudo como direcionado. [2] N\u00e3o temos nenhum texto marcado com religious_intolerance por nossos anotadores. [3] Temos anota\u00e7\u00f5es mais inconsistentes nos r\u00f3tulos idelogy , insult e profanity_obscene (desconsiderando [1] [2])","title":"Coment\u00e1rios"},{"location":"pt/annotation/iterations.html#conclus\u00f5es","text":"Tivemos um mal entendimento das diretrizes de anota\u00e7\u00e3o por um dos anotadores, o que acabou gerando inconsist\u00eancia nos r\u00f3tulos is_targeted e targeted_type . Sobre os r\u00f3tulos de toxicidade ( toxicity labels ), percebemos que s\u00e3o raros os casos em que todos os anotadores concordam com a anota\u00e7\u00e3o, levando a um alto \u00edndice de discord\u00e2ncia e consequentemente a um baixo valor de Krippendorff's alpha. Os r\u00f3tulos que apresentaram maior discord\u00e2ncia s\u00e3o insult , ideology e profanity_obscene . Iremos repassar as diretrizes de anota\u00e7\u00e3o com os anotadores para a pr\u00f3xima itera\u00e7\u00e3o. Profiling Report","title":"Conclus\u00f5es"},{"location":"pt/annotation/iterations.html#itera\u00e7\u00e3o-3","text":"Na terceira itera\u00e7\u00e3o, n\u00f3s retreinamos os anotadores com base nas li\u00e7\u00f5es aprendidas na itera\u00e7\u00e3o anterior. Tamb\u00e9m substitu\u00edmos um dos anotadores contratados. Os anotadores foram solicitados a rotular mais 3.000 coment\u00e1rios.","title":"Itera\u00e7\u00e3o 3"},{"location":"pt/annotation/iterations.html#inter-rater-reliability","text":"Como descrito na se\u00e7\u00e3o Inter-Rater Reliability , avaliamos a confiabilidade dos anotadores usando diferentes coeficientes. Para avaliar os r\u00f3tulos de toxicidade, temos duas poss\u00edveis abordagens: Multi-Label ou Binary. Multi-Label Problem Para todos os nossos r\u00f3tulos de toxicidade calculamos o Krippendorff's alpha (usando MASI distance) e o Percent Agreement . Krippendorff's alpha : 0,4653 (concord\u00e2ncia moderada) Percent Agreement : 0,2758 Binary Problem Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0.6509 0.1777 0.6754 is_targeted 0.3551 0.1072 0.1709 targeted_type 0.1975 0.4887 0.6300 toxic_spans 0.1757 0.4427 N/A health 0.9700 0.2641 0.9794 ideology 0.8670 0.4728 0.8934 insult 0.5488 0.3317 0.4531 lgbtqphobia 0.9613 0.6393 0.9722 other_lifestyle 0.9787 0.4683 0.9854 physical_aspects 0.9560 0.4160 0.9691 profanity_obscene 0.7089 0.4894 0.6870 racism 0.9913 0.3781 0.9942 religious_intolerance 1.0 1.0 1.0 1 sexism 0.9550 0.1566 0.9689 xenophobia 0.9847 0.2980 0.9896","title":"Inter-Rater Reliability"},{"location":"pt/annotation/iterations.html#coment\u00e1rios_1","text":"[1] N\u00e3o temos nenhum texto marcado com religious_intolerance por nossos anotadores.","title":"Coment\u00e1rios"},{"location":"pt/annotation/iterations.html#conclus\u00f5es_1","text":"In this iteration, we had more consistent annotations which led to a better agreement between the annotators. Krippendorff's alpha for toxicity labels increased from 0.1962 to 0.4653 . Nesta itera\u00e7\u00e3o, tivemos anota\u00e7\u00f5es mais consistentes que levaram a uma melhor concord\u00e2ncia entre os anotadores. O Krippendorff's alpha para r\u00f3tulos de toxicidade aumentou de 0,1962 para 0,4653 . Profiling Report","title":"Conclus\u00f5es"},{"location":"pt/annotation/iterations.html#itera\u00e7\u00e3o-4","text":"Na quarta itera\u00e7\u00e3o, solicitamos aos anotadores que rotulassem um n\u00famero maior de textos seguindo as mesmas diretrizes das itera\u00e7\u00f5es anteriores. Fixamos o prazo para 4 de outubro de 2022 (+- um m\u00eas).","title":"Itera\u00e7\u00e3o 4"},{"location":"pt/annotation/iterations.html#inter-rater-reliability_1","text":"Como descrito na se\u00e7\u00e3o Inter-Rater Reliability , avaliamos a confiabilidade dos anotadores usando diferentes coeficientes. Para avaliar os r\u00f3tulos de toxicidade, temos duas poss\u00edveis abordagens: Multi-Label ou Binary. Multi-Label Problem Para todos os nossos r\u00f3tulos de toxicidade calculamos o Krippendorff's alpha (usando MASI distance) e o Percent Agreement . Krippendorff's alpha : 0,4424 (concord\u00e2ncia moderada) Percent Agreement : 0,2769 Binary Problem Feature / metrics Percent Agreement Krippendorff's alpha Gwet's AC 1 Comments is_offensive 0.5847 0.2174 0.5716 is_targeted 0.4253 0.1825 0.2790 targeted_type 0.2223 0.4840 0.5756 toxic_spans 0.2249 0.4760 (MASI distance) N/A health 0.9800 0.1424 0.9865 ideology 0.8531 0.2909 0.8863 insult 0.4938 0.2923 0.3549 lgbtqphobia 0.9550 0.4901 0.9681 other_lifestyle 0.9705 0.2239 0.9798 physical_aspects 0.9570 0.3623 0.9700 profanity_obscene 0.7436 0.5530 0.7233 racism 0.9940 0.2481 0.9960 religious_intolerance 1.0 1.0 1.0 1 sexism 0.9640 0.1880 0.9753 xenophobia 0.9905 0.3840 0.9936","title":"Inter-Rater Reliability"},{"location":"pt/annotation/iterations.html#coment\u00e1rios_2","text":"[1] N\u00e3o temos nenhum texto marcado com religious_intolerance por nossos anotadores.","title":"Coment\u00e1rios"},{"location":"pt/annotation/iterations.html#conclus\u00f5es_2","text":"Assim como na itera\u00e7\u00e3o anterior, tivemos anota\u00e7\u00f5es mais consistentes que levaram a uma melhor concord\u00e2ncia entre os anotadores. Profiling Report","title":"Conclus\u00f5es"},{"location":"pt/annotation/qualified-annotators.html","text":"Anotadores qualificados # Durante nossa pesquisa, identificamos v\u00e1rios trabalhos relacionados que descreveram as diverg\u00eancias entre anotadores como a parte mais dif\u00edcil do processo de anota\u00e7\u00e3o. Para mitigar esse problema, introduzimos um processo de treinamento que ser\u00e1 usado para treinar nossos anotadores. Um anotador qualificado deve ter as seguintes habilidades: Ingl\u00eas b\u00e1sico , pois a ferramenta utilizada no processo de anota\u00e7\u00e3o \u00e9 apresentada em ingl\u00eas. Portugu\u00eas nativo , pois os textos apresentados no conjunto de dados est\u00e3o em Portugu\u00eas do Brasil. Uma boa compreens\u00e3o da linguagem ofensiva (em portugu\u00eas) e como detect\u00e1-la. Os conceitos ser\u00e3o explicados em Diretrizes para anota\u00e7\u00e3o Adicionalmente, os anotadores ser\u00e3o treinados pelo curso Comunica\u00e7\u00e3o N\u00e3o Violenta - FECAP com o seguinte conte\u00fado program\u00e1tico: Diferen\u00e7as entre negatividade e toxicidade na comunica\u00e7\u00e3o e no comportamento; Pessoas e comportamentos t\u00f3xicos; Comportamento assertivo e comunica\u00e7\u00e3o; Comunica\u00e7\u00e3o n\u00e3o violenta, conscientiza\u00e7\u00e3o e n\u00e3o julgamento.","title":"Qualified Annotators"},{"location":"pt/annotation/qualified-annotators.html#anotadores-qualificados","text":"Durante nossa pesquisa, identificamos v\u00e1rios trabalhos relacionados que descreveram as diverg\u00eancias entre anotadores como a parte mais dif\u00edcil do processo de anota\u00e7\u00e3o. Para mitigar esse problema, introduzimos um processo de treinamento que ser\u00e1 usado para treinar nossos anotadores. Um anotador qualificado deve ter as seguintes habilidades: Ingl\u00eas b\u00e1sico , pois a ferramenta utilizada no processo de anota\u00e7\u00e3o \u00e9 apresentada em ingl\u00eas. Portugu\u00eas nativo , pois os textos apresentados no conjunto de dados est\u00e3o em Portugu\u00eas do Brasil. Uma boa compreens\u00e3o da linguagem ofensiva (em portugu\u00eas) e como detect\u00e1-la. Os conceitos ser\u00e3o explicados em Diretrizes para anota\u00e7\u00e3o Adicionalmente, os anotadores ser\u00e3o treinados pelo curso Comunica\u00e7\u00e3o N\u00e3o Violenta - FECAP com o seguinte conte\u00fado program\u00e1tico: Diferen\u00e7as entre negatividade e toxicidade na comunica\u00e7\u00e3o e no comportamento; Pessoas e comportamentos t\u00f3xicos; Comportamento assertivo e comunica\u00e7\u00e3o; Comunica\u00e7\u00e3o n\u00e3o violenta, conscientiza\u00e7\u00e3o e n\u00e3o julgamento.","title":"Anotadores qualificados"},{"location":"pt/annotation/schema.html","text":"Esquema de anota\u00e7\u00e3o # Desenvolvemos o esquema de anota\u00e7\u00e3o para maximizar a efici\u00eancia do anotador. O OLID-BR cont\u00e9m uma cole\u00e7\u00e3o de frases anotadas em portugu\u00eas brasileiro usando um modelo de anota\u00e7\u00e3o que abrange os seguintes n\u00edveis: Offensive content detection Offense target identification Offensive spans identification Taxonomia hier\u00e1rquica para categorizar linguagem ofensiva, proposta pelo autor. Para isso, definimos 4 perguntas que nossos anotadores qualificados responder\u00e3o a cada frase. Este texto \u00e9 t\u00f3xico? Que tipo de toxicidade tem? H\u00e1 um alvo espec\u00edfico? Quais palavras tornam este texto t\u00f3xico/ofensivo? A imagem a seguir mostra a tela de anota\u00e7\u00e3o que nossos anotadores utilizar\u00e3o. Interface de rotulagem - Label Studio","title":"Schema"},{"location":"pt/annotation/schema.html#esquema-de-anota\u00e7\u00e3o","text":"Desenvolvemos o esquema de anota\u00e7\u00e3o para maximizar a efici\u00eancia do anotador. O OLID-BR cont\u00e9m uma cole\u00e7\u00e3o de frases anotadas em portugu\u00eas brasileiro usando um modelo de anota\u00e7\u00e3o que abrange os seguintes n\u00edveis: Offensive content detection Offense target identification Offensive spans identification Taxonomia hier\u00e1rquica para categorizar linguagem ofensiva, proposta pelo autor. Para isso, definimos 4 perguntas que nossos anotadores qualificados responder\u00e3o a cada frase. Este texto \u00e9 t\u00f3xico? Que tipo de toxicidade tem? H\u00e1 um alvo espec\u00edfico? Quais palavras tornam este texto t\u00f3xico/ofensivo? A imagem a seguir mostra a tela de anota\u00e7\u00e3o que nossos anotadores utilizar\u00e3o. Interface de rotulagem - Label Studio","title":"Esquema de anota\u00e7\u00e3o"}]}